[{"categories":["Nacos"],"contents":"Distro 介绍 Distro 协议是一个 AP 协议，只能保证数据的最终一致性，用于 Nacos 中的临时服务。\nDistro 协议的设计思想：\n每个节点只负责部分数据， 定时发送自己负责数据的校验值到其他节点来保持数据⼀致性。 RPC 模式下，Client 直连的节点，则负责此 Client HTTP 模式下，通过 instance 的 IP:PORT 计算 hash 取模，来确定负责的节点 Nacos 每个节点是“平等”的都可以处理写请求， 同时把新数据同步到其他节点。 全量数据同步：Distro 节点启动时，会从所有节点拉取 snapshot 全量数据（该节点负责的数据），更新本地数据 增量数据同步： 心跳机制：通过心跳来校验所有 Client 的数据 hash 是否和其他节点一致，如果不一致，则拉取 实时推送：如果有服务注册或注销，Distro 节点会主动给其他节点推送变更数据 每个节点独立处理所有读请求， 返回本地缓存的数据 本地缓存的数据可能会有延时，当本地缓存更新时，会主动推送最新数据给 Client，达到最终一致性 提高服务可用性 特点：\nDistro 协议是一个 AP 协议，只能保证数据的最终一致性 Distro 节点之间进行数据验证时，需要将本地所有数据计算成 hash 值，所以 Distro 协议不适用于大量数据的场景 Distro 初始化 DistroProtocol 类在初始化的时候，会：\nstartVerifyTask() ：定时任务，每隔 5 秒和其他节点校验每个 Client 数据是否一致 ，如果发现数据不一致，会推送本地数据给其他节点； startLoadTask()：从其他 Distro 节点拉取数据 @Component public class DistroProtocol { // 维护了集群所有节点的信息 private final ServerMemberManager memberManager; // 维护了 Distro 事件处理器 private final DistroComponentHolder distroComponentHolder; // 负责执行定时任务 private final DistroTaskEngineHolder distroTaskEngineHolder; public DistroProtocol(ServerMemberManager memberManager, DistroComponentHolder distroComponentHolder, DistroTaskEngineHolder distroTaskEngineHolder) { this.memberManager = memberManager; this.distroComponentHolder = distroComponentHolder; this.distroTaskEngineHolder = distroTaskEngineHolder; // 启动 Distro 任务 startDistroTask(); } private void startDistroTask() { if (EnvUtil.getStandaloneMode()) { // 单机模式无需使用Distro协议 isInitialized = true; return; } // 定时任务，每隔 5 秒和其他节点校验每个 Client 数据是否一致 startVerifyTask(); // 从其他 Distro 节点拉取数据 startLoadTask(); } } 初始化时候，当前节点会从其他的节点拉取所有的服务 snapshot 数据，当所有的 snapshot 数据拉取完成，当前 Distro 节点初始化完成，通过回调函数设置 isInitialized 为 true：\nprivate void startLoadTask() { // 回调函数 DistroCallback loadCallback = new DistroCallback() { @Override public void onSuccess() { // Distro 节点初始化完成 isInitialized = true; } @Override public void onFailed(Throwable throwable) { isInitialized = false; } }; // 从其他节点拉取 snapshot 数据 GlobalExecutor.submitLoadDataTask( new DistroLoadDataTask(memberManager, distroComponentHolder, DistroConfig.getInstance(), loadCallback)); } DistroLoadDataTask 是一个线程类，只需要关注 run 方法的逻辑即可，其核心逻辑在 load() 方法中：\n@Override public void run() { try { load(); if (!checkCompleted()) { // 如果加载数据失败，会再次执行加载任务，30秒后继续重试 GlobalExecutor.submitLoadDataTask(this, distroConfig.getLoadDataRetryDelayMillis()); } else { loadCallback.onSuccess(); Loggers.DISTRO.info(\u0026#34;[DISTRO-INIT] load snapshot data success\u0026#34;); } } catch (Exception e) { loadCallback.onFailed(e); Loggers.DISTRO.error(\u0026#34;[DISTRO-INIT] load snapshot data failed. \u0026#34;, e); } } private void load() throws Exception { // 若出自身之外没有其他节点，则休眠1秒，可能其他节点还未启动完毕 // 注意：如果有新的节点进来，通过心跳来同步数据 while (memberManager.allMembersWithoutSelf().isEmpty()) { Loggers.DISTRO.info(\u0026#34;[DISTRO-INIT] waiting server list init...\u0026#34;); TimeUnit.SECONDS.sleep(1); } // 若数据类型为空，说明distroComponentHolder的组件注册器还未初始化完毕 while (distroComponentHolder.getDataStorageTypes().isEmpty()) { Loggers.DISTRO.info(\u0026#34;[DISTRO-INIT] waiting distro data storage register...\u0026#34;); TimeUnit.SECONDS.sleep(1); } // 加载每个类型的数据 for (String each : distroComponentHolder.getDataStorageTypes()) { if (!loadCompletedMap.containsKey(each) || !loadCompletedMap.get(each)) { // 调用加载方法，并标记已处理 loadCompletedMap.put(each, loadAllDataSnapshotFromRemote(each)); } } } 最终会调用 loadAllDataSnapshotFromRemote 方法同步数据：\n从远端拉取 snapshot 数据； 将 snapshot 数据应用到本地内存； 标记数据初始化成功。 private boolean loadAllDataSnapshotFromRemote(String resourceType) { // 获取数据传输对象 DistroTransportAgent transportAgent = distroComponentHolder.findTransportAgent(resourceType); // 获取数据处理器 DistroDataProcessor dataProcessor = distroComponentHolder.findDataProcessor(resourceType); if (null == transportAgent || null == dataProcessor) { Loggers.DISTRO.warn(\u0026#34;[DISTRO-INIT] Can\u0026#39;t find component for type {}, transportAgent: {}, dataProcessor: {}\u0026#34;, resourceType, transportAgent, dataProcessor); return false; } // 向每个节点请求数据 for (Member each : memberManager.allMembersWithoutSelf()) { long startTime = System.currentTimeMillis(); try { Loggers.DISTRO.info(\u0026#34;[DISTRO-INIT] load snapshot {} from {}\u0026#34;, resourceType, each.getAddress()); /** * 发送请求拉取 snapshot 数据 * @see com.alibaba.nacos.naming.consistency.ephemeral.distro.v2.DistroClientTransportAgent#getDatumSnapshot(String) */ DistroData distroData = transportAgent.getDatumSnapshot(each.getAddress()); Loggers.DISTRO.info(\u0026#34;[DISTRO-INIT] it took {} ms to load snapshot {} from {} and snapshot size is {}.\u0026#34;, System.currentTimeMillis() - startTime, resourceType, each.getAddress(), getDistroDataLength(distroData)); /** * 解析数据 * @see com.alibaba.nacos.naming.consistency.ephemeral.distro.v2.DistroClientDataProcessor#processSnapshot(DistroData) */ boolean result = dataProcessor.processSnapshot(distroData); Loggers.DISTRO .info(\u0026#34;[DISTRO-INIT] load snapshot {} from {} result: {}\u0026#34;, resourceType, each.getAddress(), result); // 若解析成功，标记此类型数据已加载完毕 if (result) { distroComponentHolder.findDataStorage(resourceType).finishInitial(); return true; } } catch (Exception e) { e.printStackTrace(); Loggers.DISTRO.error(\u0026#34;[DISTRO-INIT] load snapshot {} from {} failed.\u0026#34;, resourceType, each.getAddress(), e); } } return false; } getDatumSnapshot 最终会调用 DistroClientTransportAgent#getDatumSnapshot ：\n判断目标节点的连接状态是否正常； 构建 DistroDataRequest 请求，类型为 DataOperation.SNAPSHOT，并给目标节点发送该请求； 如果期间有其他情况，皆抛出 DistroException 异常； public class DistroClientTransportAgent implements DistroTransportAgent { // 负责发送 RPC 请求 private final ClusterRpcClientProxy clusterRpcClientProxy; // 管理 Distro 节点信息 private final ServerMemberManager memberManager; public DistroData getDatumSnapshot(String targetServer) { // 从节点管理器获取目标节点信息 Member member = memberManager.find(targetServer); // 判断目标服务器是否健康 if (checkTargetServerStatusUnhealthy(member)) { throw new DistroException( String.format(\u0026#34;[DISTRO] Cancel get snapshot caused by target server %s unhealthy\u0026#34;, targetServer)); } // 构建请求参数 DistroDataRequest request = new DistroDataRequest(); // 设置请求的操作类型为DataOperation.SNAPSHOT request.setDataOperation(DataOperation.SNAPSHOT); try { // 使用Rpc代理对象发送同步rpc请求 Response response = clusterRpcClientProxy .sendRequest(member, request, DistroConfig.getInstance().getLoadDataTimeoutMillis()); if (checkResponse(response)) { return ((DistroDataResponse) response).getDistroData(); } else { throw new DistroException( String.format(\u0026#34;[DISTRO-FAILED] Get snapshot request to %s failed, code: %d, message: %s\u0026#34;, targetServer, response.getErrorCode(), response.getMessage())); } } catch (NacosException e) { e.printStackTrace(); throw new DistroException(\u0026#34;[DISTRO-FAILED] Get distro snapshot failed! \u0026#34;, e); } } } processSnapshot 会调用 DistroClientDataProcessor#processSnapshot() 方法来处理拉取到的 snapshot 数据：\n将获取的 snapshot 数据反序列化成 ClientSyncDatumSnapshot 类型； 创建 IpPortBasedClient 对象，放到 ClientManager 中，并启动心跳检测任务； 调用 upgradeClient 更新 ServiceManager、ClientServiceIndexesManager、Push 给订阅者等操作； public class DistroClientDataProcessor extends SmartSubscriber implements DistroDataStorage, DistroDataProcessor { public static final String TYPE = \u0026#34;Nacos:Naming:v2:ClientData\u0026#34;; /** * @see ClientManagerDelegate * 里面包含了 EphemeralIpPortClientManager 和 PersistentIpPortClientManager */ private final ClientManager clientManager; private final DistroProtocol distroProtocol; @Override public boolean processSnapshot(DistroData distroData) { // 反序列化获取的DistroData为ClientSyncDatumSnapshot ClientSyncDatumSnapshot snapshot = ApplicationUtils.getBean(Serializer.class) .deserialize(distroData.getContent(), ClientSyncDatumSnapshot.class); // 处理结果集，这里将返回远程节点负责的所有client以及client下面的service、instance信息 for (ClientSyncData each : snapshot.getClientSyncDataList()) { // 每次处理一个client handlerClientSyncData(each); } return true; } // 备注：这里只需要维护 publisher 的关系，不需要维护 subscriber 的关系 private void handlerClientSyncData(ClientSyncData clientSyncData) { Loggers.DISTRO.info(\u0026#34;[Client-Add] Received distro client sync data {}, revision={}\u0026#34;, clientSyncData.getClientId(), clientSyncData.getAttributes().getClientAttribute(ClientConstants.REVISION, 0L)); // 因为是同步数据，因此创建IpPortBasedClient，并缓存 clientManager.syncClientConnected(clientSyncData.getClientId(), clientSyncData.getAttributes()); Client client = clientManager.getClient(clientSyncData.getClientId()); // 升级此客户端的服务信息 upgradeClient(client, clientSyncData); } } ClientSyncData 中包含了其他节点 namespace、service、instance 等信息，要注意，这里的数据，是以每个 Client （即，发布者）为单位的：\npublic class ClientSyncData implements Serializable { private static final long serialVersionUID = -5141768777704539562L; private String clientId; private ClientAttributes attributes; private List\u0026lt;String\u0026gt; namespaces; private List\u0026lt;String\u0026gt; groupNames; private List\u0026lt;String\u0026gt; serviceNames; private List\u0026lt;InstancePublishInfo\u0026gt; instancePublishInfos; private BatchInstanceData batchInstanceData; } upgradeClient 是将远程数据应用到当前节点本地的核心流程:\n更新 ServiceManager 下的数据 更新 ClientServiceIndexesManager 发布 ServiceEvent.ServiceChangedEvent 事件 给订阅者 Push PushDelayTask，通知订阅者更新自己的 instance 数据 private void upgradeClient(Client client, ClientSyncData clientSyncData) { // 已同步的服务集合 Set\u0026lt;Service\u0026gt; syncedService = new HashSet\u0026lt;\u0026gt;(); // process batch instance sync logic // 0、更新 ServiceManager 下的数据 // 1、更新 ClientServiceIndexesManager // 2、发布 ServiceEvent.ServiceChangedEvent 事件 // 3、给订阅者 Push PushDelayTask，通知订阅者更新自己的 instance 数据 processBatchInstanceDistroData(syncedService, client, clientSyncData); List\u0026lt;String\u0026gt; namespaces = clientSyncData.getNamespaces(); List\u0026lt;String\u0026gt; groupNames = clientSyncData.getGroupNames(); List\u0026lt;String\u0026gt; serviceNames = clientSyncData.getServiceNames(); List\u0026lt;InstancePublishInfo\u0026gt; instances = clientSyncData.getInstancePublishInfos(); // TODO 这段逻辑，和 processBatchInstanceDistroData 里面逻辑差不多，为啥这里要在执行一遍？？？？ for (int i = 0; i \u0026lt; namespaces.size(); i\u0026#43;\u0026#43;) { Service service = Service.newService(namespaces.get(i), groupNames.get(i), serviceNames.get(i)); Service singleton = ServiceManager.getInstance().getSingleton(service); // 标记该 Service 已经被处理 syncedService.add(singleton); InstancePublishInfo instancePublishInfo = instances.get(i); // TODO 如果一个 Service 有多个 instance，该怎么处理呢 // 当前 instance 不存在本地的 client 中，视为从 其他节点获取的新服务，新服务需要 Push 给订阅者 if (!instancePublishInfo.equals(client.getInstancePublishInfo(singleton))) { // 添加到 ClientInfo 中 client.addServiceInstance(singleton, instancePublishInfo); // 当前节点发布服务注册事件 NotifyCenter.publishEvent( new ClientOperationEvent.ClientRegisterServiceEvent(singleton, client.getClientId())); NotifyCenter.publishEvent( new MetadataEvent.InstanceMetadataEvent(singleton, instancePublishInfo.getMetadataId(), false)); } } // 若当前client内部已发布的service不在本次同步的列表内，说明已经过时了，要删掉 // TODO 为啥这么判断？如果两个 Node 数据不一致，以远程数据为准？这样好像会出问题？ for (Service each : client.getAllPublishedService()) { // 如果 client 有多余的 Service，从 client 中移除 if (!syncedService.contains(each)) { client.removeServiceInstance(each); NotifyCenter.publishEvent( new ClientOperationEvent.ClientDeregisterServiceEvent(each, client.getClientId())); } } client.setRevision( clientSyncData.getAttributes().\u0026lt;Integer\u0026gt;getClientAttribute(ClientConstants.REVISION, 0)); } 增量数据同步 startLoadTask 用来同步全量数据（Nacos 初始化过程中），Nacos 通过发布 Event 的机制，来同步增量数据（Nacos 运行过程中）。\nDistroClientDataProcessor 继承了 Subscriber 事件订阅类，他在初始化的时候，会订阅这几种事件：\n@Override public List\u0026lt;Class\u0026lt;? extends Event\u0026gt;\u0026gt; subscribeTypes() { List\u0026lt;Class\u0026lt;? extends Event\u0026gt;\u0026gt; result = new LinkedList\u0026lt;\u0026gt;(); result.add(ClientEvent.ClientChangedEvent.class); result.add(ClientEvent.ClientDisconnectEvent.class); result.add(ClientEvent.ClientVerifyFailedEvent.class); return result; } 当有服务注册时，会发送 ClientEvent.ClientChangedEvent 事件；当有服务下线时，会发送 ClientEvent.ClientDisconnectEvent 事件，这俩事件会被此类处理。\nprivate void syncToAllServer(ClientEvent event) { Client client = event.getClient(); // Only ephemeral data sync by Distro, persist client should sync by raft. // distro 协议下，每个 node 只负责部分服务的数据同步 // TODO isResponsibleClient 的逻辑解析 if (null == client || !client.isEphemeral() || !clientManager.isResponsibleClient(client)) { return; } if (event instanceof ClientEvent.ClientDisconnectEvent) { DistroKey distroKey = new DistroKey(client.getClientId(), TYPE); // 删除事件 distroProtocol.sync(distroKey, DataOperation.DELETE); } else if (event instanceof ClientEvent.ClientChangedEvent) { // 可以看到，增量数据同步是以 client 发布的数据为单位进行的 DistroKey distroKey = new DistroKey(client.getClientId(), TYPE); // 节点变更事件，即增量数据的同步方法 distroProtocol.sync(distroKey, DataOperation.CHANGE); } } 可以看到， Distro 节点会通过 distroProtocol.sync 给其他节点发送 RPC 请求，请求的 Type 分别是 DELETE 和 CHANGE：\npublic void sync(DistroKey distroKey, DataOperation action, long delay) { for (Member each : memberManager.allMembersWithoutSelf()) { syncToTarget(distroKey, action, each.getAddress(), delay); } } public void syncToTarget(DistroKey distroKey, DataOperation action, String targetServer, long delay) { DistroKey distroKeyWithTarget = new DistroKey(distroKey.getResourceKey(), distroKey.getResourceType(), targetServer); DistroDelayTask distroDelayTask = new DistroDelayTask(distroKeyWithTarget, action, delay); /** * 发布任务 DistroDelayTask * @see DistroDelayTaskProcessor#process(NacosTask) */ distroTaskEngineHolder.getDelayTaskExecuteEngine().addTask(distroKeyWithTarget, distroDelayTask); if (Loggers.DISTRO.isDebugEnabled()) { Loggers.DISTRO.debug(\u0026#34;[DISTRO-SCHEDULE] {} to {}\u0026#34;, distroKey, targetServer); } } 会走到 DistroDelayTaskProcessor 的 process 方法，分别转换成 DistroSyncDeleteTask 和 DistroSyncChangeTask 进行任务投递：\npublic boolean process(NacosTask task) { if (!(task instanceof DistroDelayTask)) { return true; } DistroDelayTask distroDelayTask = (DistroDelayTask) task; DistroKey distroKey = distroDelayTask.getDistroKey(); switch (distroDelayTask.getAction()) { case DELETE: DistroSyncDeleteTask syncDeleteTask = new DistroSyncDeleteTask(distroKey, distroComponentHolder); distroTaskEngineHolder.getExecuteWorkersManager().addTask(distroKey, syncDeleteTask); return true; case CHANGE: case ADD: DistroSyncChangeTask syncChangeTask = new DistroSyncChangeTask(distroKey, distroComponentHolder); distroTaskEngineHolder.getExecuteWorkersManager().addTask(distroKey, syncChangeTask); return true; default: return false; } } 在 DistroClientDataProcessor 中，他会生成，他会调用 client.generateSyncData() 生成要同步的数据，病序列化放到 Request 中，发送给对方节点：\nDistroClientDataProcessorpublic DistroData getDistroData(DistroKey distroKey) { Client client = clientManager.getClient(distroKey.getResourceKey()); if (null == client) { return null; } byte[] data = ApplicationUtils.getBean(Serializer.class).serialize(client.generateSyncData()); return new DistroData(distroKey, data); } 可以看到 client 生成这个 client 的同步数据的流程，他会将所有的 namespace、service、instance 等信息进行序列化：\npublic abstract class AbstractClient implements Client { @Override public ClientSyncData generateSyncData() { List\u0026lt;String\u0026gt; namespaces = new LinkedList\u0026lt;\u0026gt;(); List\u0026lt;String\u0026gt; groupNames = new LinkedList\u0026lt;\u0026gt;(); List\u0026lt;String\u0026gt; serviceNames = new LinkedList\u0026lt;\u0026gt;(); List\u0026lt;String\u0026gt; batchNamespaces = new LinkedList\u0026lt;\u0026gt;(); List\u0026lt;String\u0026gt; batchGroupNames = new LinkedList\u0026lt;\u0026gt;(); List\u0026lt;String\u0026gt; batchServiceNames = new LinkedList\u0026lt;\u0026gt;(); List\u0026lt;InstancePublishInfo\u0026gt; instances = new LinkedList\u0026lt;\u0026gt;(); List\u0026lt;BatchInstancePublishInfo\u0026gt; batchInstancePublishInfos = new LinkedList\u0026lt;\u0026gt;(); BatchInstanceData batchInstanceData = new BatchInstanceData(); for (Map.Entry\u0026lt;Service, InstancePublishInfo\u0026gt; entry : publishers.entrySet()) { InstancePublishInfo instancePublishInfo = entry.getValue(); if (instancePublishInfo instanceof BatchInstancePublishInfo) { BatchInstancePublishInfo batchInstance = (BatchInstancePublishInfo) instancePublishInfo; batchInstancePublishInfos.add(batchInstance); buildBatchInstanceData(batchInstanceData, batchNamespaces, batchGroupNames, batchServiceNames, entry); batchInstanceData.setBatchInstancePublishInfos(batchInstancePublishInfos); } else { namespaces.add(entry.getKey().getNamespace()); groupNames.add(entry.getKey().getGroup()); serviceNames.add(entry.getKey().getName()); instances.add(entry.getValue()); } } ClientSyncData data = new ClientSyncData(getClientId(), namespaces, groupNames, serviceNames, instances, batchInstanceData); data.getAttributes().addClientAttribute(REVISION, getRevision()); return data; } } 最终会走到 DistroClientTransportAgent 发送一个 RPC 请求给对方：\npublic boolean syncData(DistroData data, String targetServer) { // 目标服务不存在 if (isNoExistTarget(targetServer)) { return true; } // 构造distro协议数据的请求 DistroDataRequest request = new DistroDataRequest(data, data.getType()); // 找到对应的ip,端口等属性信息 Member member = memberManager.find(targetServer); // 检查服务节点是否在线 if (checkTargetServerStatusUnhealthy(member)) { Loggers.DISTRO .warn(\u0026#34;[DISTRO] Cancel distro sync caused by target server {} unhealthy, key: {}\u0026#34;, targetServer, data.getDistroKey()); return false; } try { // 在线的话，发送grpc的请求 Response response = clusterRpcClientProxy.sendRequest(member, request); // 检查结果是否成功 return checkResponse(response); } catch (NacosException e) { Loggers.DISTRO.error(\u0026#34;[DISTRO-FAILED] Sync distro data failed! key: {}\u0026#34;, data.getDistroKey(), e); } return false; } 对方节点收到 RPC 请求，会调用 DistroDataRequestHandler 进行处理。他会根据 Request 的 Type 来选择处理逻辑：\npublic class DistroDataRequestHandler extends RequestHandler\u0026lt;DistroDataRequest, DistroDataResponse\u0026gt; { private final DistroProtocol distroProtocol; @Override public DistroDataResponse handle(DistroDataRequest request, RequestMeta meta) throws NacosException { try { switch (request.getDataOperation()) { case VERIFY: // 心跳请求，每隔 5 秒发送一次 return handleVerify(request.getDistroData(), meta); case SNAPSHOT: // 处理快照请求 // 全量数据同步 return handleSnapshot(); case ADD: case CHANGE: case DELETE: // 增量数据同步 return handleSyncData(request.getDistroData()); case QUERY: // 处理查询数据的请求 return handleQueryData(request.getDistroData()); default: // 默认的返回 return new DistroDataResponse(); } } catch (Exception e) { Loggers.DISTRO.error(\u0026#34;[DISTRO-FAILED] distro handle with exception\u0026#34;, e); DistroDataResponse result = new DistroDataResponse(); result.setErrorCode(ResponseCode.FAIL.getCode()); result.setMessage(\u0026#34;handle distro request with exception\u0026#34;); return result; } } } handleSyncData 最终会走到 DistroClientDataProcessor 进行处理：\n@Override public boolean processData(DistroData distroData) { switch (distroData.getType()) { case ADD: case CHANGE: // 反序列化获取的DistroData为ClientSyncDatumSnapshot // TODO 发送事件的逻辑：@see com.alibaba.nacos.core.distributed.distro.DistroProtocol.syncToTarget 方法 ClientSyncData clientSyncData = ApplicationUtils.getBean(Serializer.class) .deserialize(distroData.getContent(), ClientSyncData.class); // 处理 client 变更的事件 handlerClientSyncData(clientSyncData); return true; case DELETE: String deleteClientId = distroData.getDistroKey().getResourceKey(); Loggers.DISTRO.info(\u0026#34;[Client-Delete] Received distro client sync data {}\u0026#34;, deleteClientId); // 处理 client 下线（删除）的事件 clientManager.clientDisconnected(deleteClientId); return true; default: return false; } } handlerClientSyncData 的逻辑和 Distro 初始化逻辑类似，核心都在 upgradeClient 中：\n创建一个 IpPortBasedClient 对象，放到 clientManager 中 更新 ServiceManager 下的数据 更新 ClientServiceIndexesManager 发布 ServiceEvent.ServiceChangedEvent 事件 给订阅者 Push PushDelayTask，通知订阅者更新自己的 instance 数据 // 备注：这里只需要维护 publisher 的关系，不需要维护 subscriber 的关系 private void handlerClientSyncData(ClientSyncData clientSyncData) { Loggers.DISTRO.info(\u0026#34;[Client-Add] Received distro client sync data {}, revision={}\u0026#34;, clientSyncData.getClientId(), clientSyncData.getAttributes().getClientAttribute(ClientConstants.REVISION, 0L)); // 因为是同步数据，因此创建IpPortBasedClient，并缓存 clientManager.syncClientConnected(clientSyncData.getClientId(), clientSyncData.getAttributes()); Client client = clientManager.getClient(clientSyncData.getClientId()); // 升级此客户端的服务信息 upgradeClient(client, clientSyncData); } 在 clientDisconnected 方法中，会进行：\n将 client 从 ClientManager 中移除； 发布 ClientEvent.ClientDisconnectEvent 事件 更新 ClientServiceIndexesManager 更新 NamingMetadataManager 通知订阅者修改自己的服务 @Override public boolean clientDisconnected(String clientId) { Loggers.SRV_LOG.info(\u0026#34;Client connection {} disconnect, remove instances and subscribers\u0026#34;, clientId); IpPortBasedClient client = clients.remove(clientId); if (null == client) { return true; } NotifyCenter.publishEvent(new ClientEvent.ClientDisconnectEvent(client, isResponsibleClient(client))); client.release(); return true; } 至此，流程完成。\n心跳机制（元数据校验） 上面我们提到，DistroProtocol 初始化完成后，会启动一个 VerifyTask 任务，这个任务会每隔 5 秒给其他节点发送当前节点负责的 Client 的数据信息（revision hash 值），来对比两个节点数据是否一致，如果不一致会触发两者之间进行数据同步。\nprivate void startVerifyTask() { // 每隔 5 秒给其他 member 发送验证请求 /** * @see DistroVerifyTimedTask#run() */ GlobalExecutor.schedulePartitionDataTimedSync(new DistroVerifyTimedTask(memberManager, distroComponentHolder, distroTaskEngineHolder.getExecuteWorkersManager()), DistroConfig.getInstance().getVerifyIntervalMillis()); // 间隔 5 秒一次 } DistroVerifyTimedTask 也是一个线程类，所以只关心他的 run 方法逻辑即可：\npublic class DistroVerifyTimedTask implements Runnable { // 管理所有的服务节点 private final ServerMemberManager serverMemberManager; // Distro 组件持有器 private final DistroComponentHolder distroComponentHolder; // 执行定时任务 private final DistroExecuteTaskExecuteEngine executeTaskExecuteEngine; @Override public void run() { try { // 获取所有的服务节点 List\u0026lt;Member\u0026gt; targetServer = serverMemberManager.allMembersWithoutSelf(); if (Loggers.DISTRO.isDebugEnabled()) { Loggers.DISTRO.debug(\u0026#34;server list is: {}\u0026#34;, targetServer); } for (String each : distroComponentHolder.getDataStorageTypes()) { /** * 这里我们注关注 Nacos:Naming:v2:ClientData 类型 * @see DistroVerifyTimedTask#verifyForDataStorage(String, List) */ verifyForDataStorage(each, targetServer); } } catch (Exception e) { Loggers.DISTRO.error(\u0026#34;[DISTRO-FAILED] verify task failed.\u0026#34;, e); } } } verifyForDataStorage 获取到本地的数据，然后将数据发送给其他的节点：\nprivate void verifyForDataStorage(String type, List\u0026lt;Member\u0026gt; targetServer) { // 获取处理存储类 DistroDataStorage dataStorage = distroComponentHolder.findDataStorage(type); if (!dataStorage.isFinishInitial()) { Loggers.DISTRO.warn(\u0026#34;data storage {} has not finished initial step, do not send verify data\u0026#34;, dataStorage.getClass().getSimpleName()); return; } // 拿到验证的数据 List\u0026lt;DistroData\u0026gt; verifyData = dataStorage.getVerifyData(); if (null == verifyData || verifyData.isEmpty()) { return; } for (Member member : targetServer) { DistroTransportAgent agent = distroComponentHolder.findTransportAgent(type); if (null == agent) { continue; } // 通过执行器执行 /** * @see DistroVerifyExecuteTask#run() */ executeTaskExecuteEngine.addTask(member.getAddress() \u0026#43; type, new DistroVerifyExecuteTask(agent, verifyData, member.getAddress(), type)); } } getVerifyData 可以看到 Distro 要验证的数据内容：\n遍历所有的 client，即发布者； 将 client 的 clientId 和 revision 作为此服务当前的状态。 public class DistroClientDataProcessor extends SmartSubscriber implements DistroDataStorage, DistroDataProcessor { @Override public List\u0026lt;DistroData\u0026gt; getVerifyData() { List\u0026lt;DistroData\u0026gt; result = null; // 数据验证的单位是每个 Client 的数据 for (String each : clientManager.allClientId()) { // 对每个本机所管理的注册客户端进行处理 Client client = clientManager.getClient(each); if (null == client || !client.isEphemeral()) { // 空的或者是非临时性的节点，不处理 continue; } // 如果是自己管理的客户端 // TODO 待分析这块流程 if (clientManager.isResponsibleClient(client)) { // 需要验证的数据就是每个节点的clientId和revision // revision 是用 client 里面所有的 service、instance 等信息通过计算 hash 来获取的 // 可以看到，是通过 client 为单位来进行数据校验的 DistroClientVerifyInfo verifyData = new DistroClientVerifyInfo(client.getClientId(), client.getRevision()); DistroKey distroKey = new DistroKey(client.getClientId(), TYPE); DistroData data = new DistroData(distroKey, ApplicationUtils.getBean(Serializer.class).serialize(verifyData)); data.setType(DataOperation.VERIFY); if (result == null) { result = new LinkedList\u0026lt;\u0026gt;(); } result.add(data); } } return result; } } 上篇文章，我们提到了 revision 的计算逻辑：将 client 拥有的 namespace、group、ip、port、instance、metadata 等所有的状态信息计算一个 hash 值：\n// client.recalculateRevision() 会调用如下方法，计算该 client 当前服务的状态 public static int hash(Client client) { if (!(client instanceof IpPortBasedClient)) { return 0; } return Objects.hash(client.getClientId(), client.getAllPublishedService().stream() .map(s -\u0026gt; { InstancePublishInfo ip = client.getInstancePublishInfo(s); double weight = getWeight(ip); Boolean enabled = getEnabled(ip); String cluster = StringUtils.defaultIfBlank(ip.getCluster(), DEFAULT_CLUSTER_NAME); return Objects.hash( s.getNamespace(), s.getGroup(), s.getName(), s.isEphemeral(), ip.getIp(), ip.getPort(), weight, ip.isHealthy(), enabled, cluster, ip.getExtendDatum() ); }) .collect(Collectors.toSet())); } DistroVerifyExecuteTask 最终会调用 DistroClientTransportAgent 给其他 Node 发送一个 DistroDataRequest 请求，请求的 type 为 DataOperation.VERIFY。如果对方校验成功或失败，会触发回调：\npublic class DistroClientTransportAgent implements DistroTransportAgent { @Override public void syncVerifyData(DistroData verifyData, String targetServer, DistroCallback callback) { if (isNoExistTarget(targetServer)) { callback.onSuccess(); return; } DistroDataRequest request = new DistroDataRequest(verifyData, DataOperation.VERIFY); Member member = memberManager.find(targetServer); if (checkTargetServerStatusUnhealthy(member)) { Loggers.DISTRO .warn(\u0026#34;[DISTRO] Cancel distro verify caused by target server {} unhealthy, key: {}\u0026#34;, targetServer, verifyData.getDistroKey()); callback.onFailed(null); return; } try { DistroVerifyCallbackWrapper wrapper = new DistroVerifyCallbackWrapper(targetServer, verifyData.getDistroKey().getResourceKey(), callback, member); clusterRpcClientProxy.asyncRequest(member, request, wrapper); } catch (NacosException nacosException) { callback.onFailed(nacosException); } } } 对方节点收到 RPC 请求，会调用 DistroDataRequestHandler 进行处理。他会根据 Request 的 Type 来选择处理逻辑：\npublic class DistroDataRequestHandler extends RequestHandler\u0026lt;DistroDataRequest, DistroDataResponse\u0026gt; { private final DistroProtocol distroProtocol; @Override public DistroDataResponse handle(DistroDataRequest request, RequestMeta meta) throws NacosException { try { switch (request.getDataOperation()) { case VERIFY: // 心跳请求，每隔 5 秒发送一次 return handleVerify(request.getDistroData(), meta); case SNAPSHOT: // 处理快照请求 // 全量数据同步 return handleSnapshot(); case ADD: case CHANGE: case DELETE: // 增量数据同步 return handleSyncData(request.getDistroData()); case QUERY: // 处理查询数据的请求 return handleQueryData(request.getDistroData()); default: // 默认的返回 return new DistroDataResponse(); } } catch (Exception e) { Loggers.DISTRO.error(\u0026#34;[DISTRO-FAILED] distro handle with exception\u0026#34;, e); DistroDataResponse result = new DistroDataResponse(); result.setErrorCode(ResponseCode.FAIL.getCode()); result.setMessage(\u0026#34;handle distro request with exception\u0026#34;); return result; } } } handleVerify 方法最终会调用 ConnectionBasedClientManager 的 verifyClient 进行校验：\nprivate DistroDataResponse handleVerify(DistroData distroData, RequestMeta meta) { DistroDataResponse result = new DistroDataResponse(); // 如果返回 false， RPC 的 Response 会带上错误标识 if (!distroProtocol.onVerify(distroData, meta.getClientIp())) { result.setErrorInfo(ResponseCode.FAIL.getCode(), \u0026#34;[DISTRO-FAILED] distro data verify failed\u0026#34;); } return result; } public class ConnectionBasedClientManager extends ClientConnectionEventListener implements ClientManager { @Override public boolean verifyClient(DistroClientVerifyInfo verifyData) { ConnectionBasedClient client = clients.get(verifyData.getClientId()); if (null != client) { // remote node of old version will always verify with zero revision // 如果本地 client 的 revision 和远端传来的一致，说明数据一致，返回 true if (0 == verifyData.getRevision() || client.getRevision() == verifyData.getRevision()) { // 更新该 client 的最新更新时间 // TODO 这个字段的含义 client.setLastRenewTime(); return true; } else { Loggers.DISTRO.info(\u0026#34;[DISTRO-VERIFY-FAILED] ConnectionBasedClient[{}] revision local={}, remote={}\u0026#34;, client.getClientId(), client.getRevision(), verifyData.getRevision()); } } // 数据不一致，校验失败 return false; } } Distro 收到 Response 之后，会触发回调函数，如果数据同步失败，会发布 ClientVerifyFailedEvent 事件：\npublic class DistroClientTransportAgent implements DistroTransportAgent { @Override public void onResponse(Response response) { if (checkResponse(response)) { NamingTpsMonitor.distroVerifySuccess(member.getAddress(), member.getIp()); // 输出日志 distroCallback.onSuccess(); } else { // 触发时机：对方返回了失败的响应 // 校验失败发布ClientVerifyFailedEvent事件 Loggers.DISTRO.info(\u0026#34;Target {} verify client {} failed, sync new client\u0026#34;, targetServer, clientId); NotifyCenter.publishEvent(new ClientEvent.ClientVerifyFailedEvent(clientId, targetServer)); NamingTpsMonitor.distroVerifyFail(member.getAddress(), member.getIp()); distroCallback.onFailed(null); } } } ClientVerifyFailedEvent 的处理逻辑在 DistroClientDataProcessor 类中：\n@Override public void onEvent(Event event) { if (EnvUtil.getStandaloneMode()) { return; } if (!upgradeJudgement.isUseGrpcFeatures()) { return; } // 本地数据和远端数据不一致，将本地数据发送给远端 if (event instanceof ClientEvent.ClientVerifyFailedEvent) { syncToVerifyFailedServer((ClientEvent.ClientVerifyFailedEvent) event); } else { // ClientEvent.ClientChangedEvent 和 ClientEvent.ClientDisconnectEvent 事件逻辑 syncToAllServer((ClientEvent) event); } } // 将本地这个 client 数据发送给远端 private void syncToVerifyFailedServer(ClientEvent.ClientVerifyFailedEvent event) { Client client = clientManager.getClient(event.getClientId()); if (null == client || !client.isEphemeral() || !clientManager.isResponsibleClient(client)) { return; } // TYPE 为 \u0026#34;Nacos:Naming:v2:ClientData\u0026#34; DistroKey distroKey = new DistroKey(client.getClientId(), TYPE); // Verify failed data should be sync directly. // 将 client 数据发送给远方的节点，类型为 ADD distroProtocol.syncToTarget(distroKey, DataOperation.ADD, event.getTargetServer(), 0L); } Distro 节点收到 ADD 请求后，处理逻辑和上述 snapshot 逻辑类似，不再赘述。\n注册服务/写入新服务 如果使用 Nacos client 注册临时服务，那么默认会发送一个 InstanceRequest 的 RPC 请求到 Nacos server 端，并交由 InstanceRequestHandler 进行处理（详细流程，可以参考上篇文章）：\n但是，如果通过 HTTP 方式调用 URL 路由来注册，则会经过前置的拦截器 Filter，判断该请求 IP:PORT 所属的节点，并负责请求转发：\npublic void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { try { Method method = controllerMethodsCache.getMethod(req); String path = new URI(req.getRequestURI()).getPath(); if (method == null) { throw new NoSuchMethodException(req.getMethod() \u0026#43; \u0026#34; \u0026#34; \u0026#43; path); } // 带了 @CanDistro 注解的方法才需要处理 if (!method.isAnnotationPresent(CanDistro.class)) { filterChain.doFilter(req, resp); return; } //根据请求获取路径，格式为IP:PORT // 测试发现，他是 instance 实例的 IP:PORT，也就是说，所属关系是以 instance 级别来划分的 String distroTag = distroTagGenerator.getResponsibleTag(req); //判断是否为本节点负责，如果不是就进行下面的逻辑进行请求转发 if (distroMapper.responsible(distroTag)) { filterChain.doFilter(req, resp); return; } ...... //通过distroTag计算其所属的 Distro 责任节点 final String targetServer = distroMapper.mapSrv(distroTag); List\u0026lt;String\u0026gt; headerList = new ArrayList\u0026lt;\u0026gt;(16); Enumeration\u0026lt;String\u0026gt; headers = req.getHeaderNames(); while (headers.hasMoreElements()) { String headerName = headers.nextElement(); headerList.add(headerName); headerList.add(req.getHeader(headerName)); } final String body = IoUtils.toString(req.getInputStream(), StandardCharsets.UTF_8.name()); final Map\u0026lt;String, String\u0026gt; paramsValue = HttpClient.translateParameterMap(req.getParameterMap()); //转发请求 RestResult\u0026lt;String\u0026gt; result = HttpClient .request(HTTP_PREFIX \u0026#43; targetServer \u0026#43; req.getRequestURI(), headerList, paramsValue, body, PROXY_CONNECT_TIMEOUT, PROXY_READ_TIMEOUT, StandardCharsets.UTF_8.name(), req.getMethod()); String data = result.ok() ? result.getData() : result.getMessage(); try { WebUtils.response(resp, data, result.getCode()); } catch (Exception ignore) { Loggers.SRV_LOG.warn(\u0026#34;[DISTRO-FILTER] request failed: \u0026#34; \u0026#43; distroMapper.mapSrv(distroTag) \u0026#43; urlString); } ..... } distroMapper.responsible 会将 tag 计算 hash 值，然后与 servers.size() 取模，来判断该 instance 是否由当前服务负责：\npublic boolean responsible(String responsibleTag) { final List\u0026lt;String\u0026gt; servers = healthyList; if (!switchDomain.isDistroEnabled() || EnvUtil.getStandaloneMode()) { return true; } if (CollectionUtils.isEmpty(servers)) { // means distro config is not ready yet return false; } // TODO 为啥要计算两次？ String localAddress = EnvUtil.getLocalAddress(); int index = servers.indexOf(localAddress); int lastIndex = servers.lastIndexOf(localAddress); if (lastIndex \u0026lt; 0 || index \u0026lt; 0) { return true; } // clientID 的 # 之前的内容 取 hash，然后和 node size 取模。 int target = distroHash(responsibleTag) % servers.size(); // 判断是否包含 return target \u0026gt;= index \u0026amp;\u0026amp; target \u0026lt;= lastIndex; } 如果上述通过 hash 计算发现不是本节点负责，distroMapper.mapSrv 会计算出哪个节点负责此 instance 的更新：\npublic String mapSrv(String responsibleTag) { // 所有健康的节点 final List\u0026lt;String\u0026gt; servers = healthyList; if (CollectionUtils.isEmpty(servers) || !switchDomain.isDistroEnabled()) { return EnvUtil.getLocalAddress(); } try { // hash 取模选择一个 server int index = distroHash(responsibleTag) % servers.size(); return servers.get(index); } catch (Throwable e) { Loggers.SRV_LOG .warn(\u0026#34;[NACOS-DISTRO] distro mapper failed, return localhost: \u0026#34; \u0026#43; EnvUtil.getLocalAddress(), e); return EnvUtil.getLocalAddress(); } } 总结 为什么 gRpc 注册服务，不需要判断负责节点并进行路由转发，而 Http 的方式需要做这些事情呢？\ngrpc是长链接，只有直接接收连接的节点可以和client直接通信，后面client的每次请求都会到当前节点（段开重新链接后由新的收到节点管理）；另外长链接可以用长链接心跳来判断这个链接注册的服务实例是否过期。所以用接收节点管理对应的信息，不需要再转发。\nhttp是无状态的，需要心跳判断实例是否过期。因为不是长链接每次请求到的节点可能是不同的，需要把所有心跳都转发到同一个节点处理，其心跳长能维护正确。同理其它写操作和心跳操作一样转发到同一个节点，统一只由一个节点操作，可以尽量避免冲突，保证数据正确。所以http请求时，集群需要根据分区规则转发到同一个节点管理操作。\n读取服务 Distro 节点之间会定期同步全量数据，所以当有读请求进来，Distro 节点会直接从本地的缓存中拉取数据。此时可能数据会有延时，但是 Distro 的心跳机制（5秒），会感知并拉取到对方最新数据，然后再 Push 给用户，实现最终一致性。具体可以参考上周分享的流程：\n参考资料 [1] 5000 字 | 揭秘 Nacos 的 AP 架构 「Distro 一致性协议」（一）\nhttps://ost.51cto.com/posts/13166\n[2] Nacos 2.0原理解析（一）：Distro协议\nhttps://blog.csdn.net/zcrzcrzcrzcrzcr/article/details/122260705\n[3] Nacos 2.0源码分析-Distro协议详解\nhttps://www.cnblogs.com/lukama/p/14918667.html\n[4] Nacos 的 Distro 一致性协议\nhttps://nacos.io/blog/article-nacos-distro-mechanism/\n","date":"2024-11-03T20:09:00+08:00","permalink":"https://luky116.github.io/post/20241103.nacos%E7%B3%BB%E5%88%97distro%E5%8D%8F%E8%AE%AE/","tags":["Nacos","Distro"],"title":"【Nacos系列】Distro协议"},{"categories":[],"contents":"一个混迹于帝都的程序猿，主要从事Java、Python和Golang相关的开发工作，欢迎互相交流!\n编程领域 Java，日常编程主要使用的语言，吃饭的家伙 Python，主要用它进行网络爬虫开发和web开发 Golang,个人业余爱好，希望在此领域长期发展 MySQL、MongoDB HTML、Javascript、jQuery、CSS 个人信息 教育信息 中国矿业大学 (2006.9-2010.6) 计算机科学与技术 (本科) 自我评价 热爱学习和使用新技术； 有着十分强烈的代码洁癖； 喜欢重构代码，善于分析和解决问题； 个人爱好 编程 英语 学习 联系方式 Email: lucumt@gmail.com,cumtlu@126.com Skype: lu.rosen QQ: 317801876 领英: 卢运强 友情链接 Frantic log#1048 cold\u0026rsquo;s world 邪恶二进制 Javmain\u0026rsquo;s Blog 小林Coding 云原生实验室 ","date":"2023-02-27T18:44:29+08:00","permalink":"https://luky116.github.io/about/","tags":[],"title":"关于我"},{"categories":[],"contents":"","date":"2022-11-15T11:49:21+08:00","permalink":"https://luky116.github.io/search/","tags":[],"title":"搜索结果展示"},{"categories":["Arana","源码系列"],"contents":"关于Arana Arana(https://github.com/dubbogo/arana) 项目刚启动不到两个月，各个功能都还在规划和刚开始开发的阶段。刚接触这个项目也不久，还在熟悉代码中。这个项目0.1版本的规划包括：\nSQL 透传 SQL 语法解析 分片算法 sharding功能 动态配置中心 分布式事务支持 总结来说，Arana项目是作为数据库的一个代理层，来实现分库分表和动态路由等功能的一个Proxy数据库插件。我们由原先直接访问数据库，转变为先访问Arana代理，再由Arana将我们的请求进行加工后，打到数据库服务器上去，如下图：​\n​Arana 的内部主要有这几个部分组成：\n监听器（Listener）：监听外部请求的一个TCP服务，用来监听和接收外部请求的SQL命令 过滤器（Filter）：分为前置过滤器(PreFilter)和后置过滤器(PostFilter)，在执行SQL前，对SQL进行特殊处理；获取到SQL执行结果后，对结果进行加工再返回给请求方 执行器（Executor）：负责将SQL命令打到合适的目标数据库服务器上 数据源（DataSourceCluster）:实际执行SQL的数据库服务器 Arana 内部的执行流程如下：\n如何本地启动项目 Arana的源码地址在：https://github.com/dubbogo/arana，为了防止master分支的源码更新太快导致对不上本文的流程，可以拉取这个版本的代码对着本文阅读：https://github.com/dubbogo/arana/tree/eedc576fdcea8de70910f43e0a8bf21dbb9c9295。\n​源码拉取下来后，看到Arana的目录结构：\ncmd：Arana的启动入口方法 dist：编译后的文件 docker：docker相关的配置 pkg：Arana的业务逻辑 test：存放继承测试文件 third_party：第三方依赖 ​\n目前有两种方式来启动Arana：\n1、通过docker启动。\n在根目录下执行以下命令，构建Arana的docker镜像 make build \u0026amp;\u0026amp; make build-docker\n进入docker/目录，执行如下命令启动arana的docker镜像 cd docker/ docker-compose -f docker-compose.yaml up -d arana\n执行test/integration_test.go里的集成测试，即可看到结果输出 2、通过main函数启动，方便调试代码\n进入docker/目录，在根目录下执行以下命令，启动MySQL的docker镜像 cd docker/ docker-compose -f docker-compose.yaml up -d mysql\n配置cmd/cmd.go中main函数的启动参数 start -c docker/conf/config.yaml\n将 docker/conf/config.yaml 文件的dsn配置的域名由arana-mysql改为127.0.0.1 启动 cmd/cmd.go文件的main函数，即可启动服务 执行test/integration_test.go里的集成测试，即可看到结果输出 项目启动流程 为了了解Arana的启动流程，我们打开cmd/cmd.go文件。可以看到，cmd.go文件使用了cobra库。cobra库是golang开源的命令行库，详情可以参考源码地址：https://github.com/spf13/cobra。startCommand.Run 方法里面的逻辑，就是程序初始化的整个流程。\n在init方法中，我们看到程序启动时接收了一个c参数，并把值赋给了configPath（配置文件的位置）变量。上面我们配置main函数的启动参数start -c docker/conf/config.yaml，可以找到配置文件所在的位置。在配置文件中可以看到Listener、Executor和DataSourceCluster的相关配置（此时Filter功能尚未实现，所以没有Filter的配置）。\nstartCommand中Run方法中，第一步是加载配置文件，组装成一个Configuration对象：\nconf := config.Load(configPath) 初始化Filter的逻辑先忽略，先看下初始化Executor的流程。从配置文件可以看到，一个Executor可以绑定多个数据源（DataSource）：\nexecutors: - name: redirect mode: singledb # 一个Executor可以绑定多个dataSource data_sources: - master: employees 一个Executor同时可以绑定多个前置过滤器和后置过滤器：\nfor _, executorConf := range conf.Executors { executor := executor.NewRedirectExecutor(executorConf) for i := 0; i \u0026lt; len(executorConf.Filters); i\u0026#43;\u0026#43; { filterName := executorConf.Filters[i] f := filter.GetFilter(filterName) if f != nil { preFilter, ok := f.(proto.PreFilter) if ok { // 一个Executor绑定多个前置过滤器 executor.AddPreFilter(preFilter) } postFilter, ok := f.(proto.PostFilter) if ok { // 一个Executor绑定多个后置过滤器 executor.AddPostFilter(postFilter) } } } executors[executorConf.Name] = executor } 接下来是初始化数据源（DataSource）的流程，这里是将数据源Factory方法作为InitDataSourceManager的一个参数：\nresource.InitDataSourceManager(conf.DataSources, func(config json.RawMessage) pools.Factory { collector, err := mysql.NewConnector(config) if err != nil { panic(err) } return collector.NewBackendConnection }) 进入到InitDataSourceManager方法，看到调用 据源Factory 传的参数是 dataSourceConfig.Conf：\n// factory(dataSourceConfig.Conf) 看到传参 initResourcePool := func(dataSourceConfig *config.DataSource) *pools.ResourcePool { resourcePool := pools.NewResourcePool(factory(dataSourceConfig.Conf), dataSourceConfig.Capacity, dataSourceConfig.MaxCapacity, dataSourceConfig.IdleTimeout, 1, nil) return resourcePool } 打开配置文件，可以看到这个参数对应的是conf.dsn配置：\ndata_source_cluster: - role: master type: mysql name: employees capacity: 10 max_capacity: 20 idle_timeout: 60s # factory接收的是这个参数 conf: dsn: root:123456@tcp(arana-mysql:3306)/employees?timeout=1s\u0026amp;readTimeout=1s\u0026amp;writeTimeout=1s\u0026amp;parseTime=true\u0026amp;loc=Local\u0026amp;charset=utf8mb4,utf8 回到cmd.go文件，进入 mysql.NewConnector(config) 方法中，看下是如何初始化Collector�的：\nfunc NewConnector(config json.RawMessage) (*Connector, error) { v := \u0026amp;struct { # 从配置文件可以看到dsn的值 DSN string `json:\u0026#34;dsn\u0026#34;` }{} if err := json.Unmarshal(config, v); err != nil { log.Errorf(\u0026#34;unmarshal mysql Listener config failed, %s\u0026#34;, err) return nil, err } // ParseDSN 解析MySQL的连接信息，包括host、port、username、db、password、编码方式等等 cfg, err := ParseDSN(v.DSN) if err != nil { return nil, err } return \u0026amp;Connector{cfg}, nil } 得到Connector对象后，cmd.go中返回了 collector.NewBackendConnection 方法，我们进到这个方法里面：\nfunc (c *Connector) NewBackendConnection(ctx context.Context) (pools.Resource, error) { conn := \u0026amp;BackendConnection{conf: c.conf} // 本地启动TCP的监听MySQL的端口服务 err := conn.connect() return conn, err } 再打开��conn.connect() 方法，就可以看到真正连接MySQL服务器的逻辑\nfunc (conn *BackendConnection) connect() error { // 省略部分代码 ...... // 这里连接MySQL服务器 netConn, err := net.Dial(typ, conn.conf.Addr) if err != nil { return err } tcpConn := netConn.(*net.TCPConn) // SetNoDelay controls whether the operating system should delay packet transmission // in hopes of sending fewer packets (Nagle\u0026#39;s algorithm). // The default is true (no delay), // meaning that Content is sent as soon as possible after a Write. tcpConn.SetNoDelay(true) tcpConn.SetKeepAlive(true) conn.c = newConn(tcpConn) // 等待TCP握手成功，即建立和MySQL的连接，即可返回 return conn.clientHandshake() } 再次回到 InitDataSourceManager方法中，我们看下 collector.NewBackendConnection 方法是如何被调用的：\nfunc InitDataSourceManager(dataSources []*config.DataSource, factory func(config json.RawMessage) pools.Factory) { // 省略部分代码 ...... // 对数据源分进行了分类，放到不同的连接池map总存储: // master：主库 // slave：从库 // meta：目前暂未用到，未来会用来存储分布式事务相关的配置数据 for i := 0; i \u0026lt; len(dataSources); i\u0026#43;\u0026#43; { switch dataSources[i].Role { case config.Master: resourcePool := initResourcePool(dataSources[i]) masterResourcePool[dataSources[i].Name] = resourcePool case config.Slave: resourcePool := initResourcePool(dataSources[i]) slaveResourcePool[dataSources[i].Name] = resourcePool case config.Meta: resourcePool := initResourcePool(dataSources[i]) metaResourcePool[dataSources[i].Name] = resourcePool default: panic(fmt.Errorf(\u0026#34;unsupported data source type: %d\u0026#34;, dataSources[i].Role)) } } } 至此，数据库数据源的初始化就完成了。\n接下来是初始化监听器Listener，我们进入 mysql.NewListener(listenerConf) 方法中，可以看到其实就是启动了一个服务监听一个TCP服务的端口：\nfunc NewListener(conf *config.Listener) (proto.Listener, error) { // 省略部分代码...... // 定义一个连接对象，监听指定的端口 l, err := net.Listen(\u0026#34;tcp\u0026#34;, fmt.Sprintf(\u0026#34;%s:%d\u0026#34;, conf.SocketAddress.Address, conf.SocketAddress.Port)) if err != nil { log.Errorf(\u0026#34;listen %s:%d error, %s\u0026#34;, conf.SocketAddress.Address, conf.SocketAddress.Port, err) return nil, err } listener := \u0026amp;Listener{ conf: cfg, listener: l, stmts: make(map[uint32]*proto.Stmt, 0), } return listener, nil } 接下来是给每个Listener指定一个执行器Executor：\n// 指定执行器 listener.SetExecutor(executor) // 将监听器暂存起来 propeller.AddListener(listener) �接下来调用 propeller.Start() 启动所有的监听器，监听外部服务。进入Start方法，发现是调用了listener.Listener() 方法。打开这个方法：\nfunc (l *Listener) Listen() { log.Infof(\u0026#34;start mysql Listener %s\u0026#34;, l.listener.Addr()) for { // 接收外部的请求 conn, err := l.listener.Accept() if err != nil { return } connectionID := l.connectionID l.connectionID\u0026#43;\u0026#43; // 调用handle方法处理请求并返回给调用方 go l.handle(conn, connectionID) } } �进入handle方法，调用了ExecuteCommand方法执行SQL，并返回处理结果。ExecuteCommand方法的执行细节有机会单独出一篇文章解析下。\nfunc (l *Listener) handle(conn net.Conn, connectionID uint32) { // 省略部分代码...... // 建立连接 err := l.handshake(c) if err != nil { werr := c.writeErrorPacketFromError(err) if werr != nil { log.Errorf(\u0026#34;Cannot write error packet to %s: %v\u0026#34;, c, werr) return } return } // 省略部分代码...... for { c.sequence = 0 // 读取请求的数据（SQL） data, err := c.readEphemeralPacket() if err != nil { c.recycleReadPacket() return } ctx := \u0026amp;proto.Context{ Context: context.Background(), ConnectionID: l.connectionID, Data: data, } // 执行SQL，并返回执行结果 err = l.ExecuteCommand(c, ctx) if err != nil { return } } } 至此，Arana的启动和处理流程的源码都梳理完了。从目前来看，Arana做的事情就是透传SQL，没有做其他的事情，比如Filtrer功能都还没支持。从这个简单的框架可以很好的了解Arana的原理，正是通过阅读源码了解Arana的好机会！\n​\n","date":"2021-12-16T15:22:17+08:00","permalink":"https://luky116.github.io/post/arana-%E5%90%AF%E5%8A%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","tags":["Arana"],"title":"Arana 启动源码分析"},{"categories":["Mockito","单元测试"],"contents":"Mockito是一个模拟测试框架，可以让你用优雅，简洁的接口写出漂亮的单元测试。Mockito可以让单元测试易于可读，产生简洁的校验错误。\n1、如何使用Mockito 引入mavne依赖\nCopy\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mockito\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mockito-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.23.4\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 有三种方法可以配置使用 Mockito ：\nMockitoJUnitRunner 注解 接下来主要用这种方法来介绍\nCopyimport org.junit.runner.RunWith; import org.mockito.junit.MockitoJUnitRunner; import org.mockito.Mock; // 测试类加上 @RunWith(MockitoJUnitRunner.class) 注解 @RunWith(MockitoJUnitRunner.class) public class MockByRunnerTest { @Mock private AccountDao accountDao; } MockitoAnnotations 方式 Copyimport org.mockito.MockitoAnnotations; import org.mockito.Mock; import org.junit.Before; public class MockByAnnotationTest { @Mock private AccountDao accountDao; @Before public void init(){ // 初始化 MockitoAnnotations.initMocks(this); } } @Rule 注解 Copyimport org.junit.Rule; import org.mockito.Mock; public class MockByRuleTest { // 初始化 @Rule public MockitoRule mockitoRule = MockitoJUnit.rule(); @Mock AccountDao accountDao; } 2、什么是Mock测试 mock测试就是在测试过程中，对于某些不容易构造或者不容易获取的对象，用一个虚拟的对象来创建以便测试的测试方法。\n比如一个类A，有B、C、D等多个复杂类的成员变量。如果我们测试时候通过new A()的方式来创建A对象，就需要同时手动创建B、C、D三个对象，并和A关联，提高了测试的复杂性。Mock可以自动生成一个虚拟的A对象，就是帮我们省去了这些复杂的创建流程。\nMockito提供了两种Mock的方式:\nCopyimport org.mockito.Mock; import static org.mockito.Mockito.mock; @RunWith(MockitoJUnitRunner.class) public class MockByRunnerTest2 { // 使用@Mock注解 @Mock private AccountDao accountDao; @Test public void test1() { Account account = accountDao.findById(1); // 返回null System.out.println(account; // 输出 class com.sanyue.learn.mockito.mockitodemo.domain.Account$MockitoMock$1675715420 System.out.println(account.getClass()); } public void test2() { // 使用mock方法 AccountDao accountDao = mock(AccountDao.class, Mockito.RETURNS_SMART_NULLS); Account account = accountDao.findById(1); // 返回null System.out.println(accoun; } } Mock生成的是一个代理对象，默认情况下，执行对象的所有的方法都返回该方法的返回类型的默认值，不会真正去执行该对象的方法。既然这样，那我们在测试中如何使用这个mock出来的对象，来执行方法进行测试呢？这就需要使用到Mockito的Stub(测试桩)来设置Mock对象方法的返回值了。\n3、Stub(测试桩) 介绍 上面介绍了Mock生成的对象，其实是一个代理对象，不会真正去执行类里面的方法。为了便于我们测试，我们需要用到Stub来设置我们期望的方法返回值，可以理解为创建测试用例。\nCopy// 你可以mock具体的类型,不仅只是接口 LinkedList mockedList = mock(LinkedList.class); // 开始设置测试桩 // 当get(0)被调用时，返回\u0026#34;first\u0026#34; when(mockedList.get(0)).thenReturn(\u0026#34;first\u0026#34;); // 方法get(1)被调用时，抛异常。 when(mockedList.get(1)).thenThrow(new RuntimeException()); // 输出 \u0026#34;first\u0026#34; System.out.println(mockedList.get(0)); // 抛出异常 System.out.println(mockedList.get(1)); // 输出 null，因为get(999)的调用没有被设置过 System.out.println(mockedList.get(999)); 由上面例子可以看到，Stub就是人为指定 当使用该参数调用该方法时，方法返回什么值。下面介绍一些其他的Stud方式：\nCopy // 使用doReturn语句和when语句一样的效果 doReturn(1).when(mockedList).get(1); // 输出 1 System.out.println(mockedList.get(1)); // 使用doNothing来设置void返回值的方法 doNothing().when(mockedList).clear(); // 设置执行clear方法抛出异常 doThrow(new RuntimeException()).when(mockedList).clear(); mockedList.clear(); // 以下断言表示，mockedList的clear方法被调用了1次 verify(mockedList, times(1)).clear(); 设置每次调用返回不同的值# 如果希望每次调用的返回值都不一样可以这样设置：\nCopy// 第1次调用返回2，第2次返回2，以后再调用返回3 when(mockedList.size()).thenReturn(1, 2, 3); // 等价写法 // when(mockedList.size()).thenReturn(1).thenReturn(2).thenReturn(3).thenReturn(4); // 1 System.out.println(mockedList.size()); // 2 System.out.println(mockedList.size()); // 3 System.out.println(mockedList.size()); // 超过3次后调用，也返回3 System.out.println(mockedList.size()); 也可以通过thenAnswer方式来设置不同调用次数返回不同的值：\nCopy// 设置返回值是 参数值*10 when(list.get(anyInt())).thenAnswer(new Answer(){ @Override public Object answer(InvocationOnMock invocationOnMock) throws Throwable { int arguments = invocationOnMock.getArgument(0); return 10*arguments; } }); 参数匹配器# 设置用参数匹配器根据不同类型参数，返回不同的值：\nCopy public class TestService { // 定义一个方法 public String say(String param1, Integer param2, String param3) { return \u0026#34;hello\u0026#34;; } } @Test public void test3(){ TestService testService = mock(TestService.class); // anyString() 表示任何字符串参数，anyInt() 表示任何int类型参数 when(testService.say(anyString(), anyInt(), anyString())).thenReturn(\u0026#34;world\u0026#34;); // 输出 world System.out.println(testService.say(\u0026#34;x\u0026#34;, 1, \u0026#34;x\u0026#34;)); // 如果参数列表包含参数匹配器，则必能出现具体参数值，要使用eq() 方法代替 // when(testService.say(anyString(), 1, anyString())).thenReturn(\u0026#34;world2\u0026#34;); when(testService.say(anyString(), eq(1), anyString())).thenReturn(\u0026#34;world2\u0026#34;); // 输出 world2 System.out.println(testService.say(\u0026#34;x\u0026#34;, 1, \u0026#34;x\u0026#34;)); } 设置执行真实的方法 可以使用thenCallRealMethod来设置执行对象真正的方法\nCopy List list = mock(LinkedList.class); when(list.size()).thenCallRealMethod(); 重置Mock对象 使用reset方法可以重置Mock对象Stub的设置\nCopyList mock = mock(List.class); when(mock.size()).thenReturn(10); mock.add(1); reset(mock); do系列方法的运用 当你调用doThrow(), doAnswer(), doNothing(), doReturn() and doCallRealMethod() 这些函数时可以在适当的位置调用when()函数. 当你需要下面这些功能时这是必须的:\n测试void函数 在受监控的对象上测试函数 不知一次的测试为同一个函数，在测试过程中改变mock对象的行为，比如为Spy对象进行Stub 像anyObject(), eq()这样的匹配器函数不会返回匹配器。它们会在内部将匹配器记录到一个栈当中，并且返回一个假的值，通常为null。这样的实现是由于被Java编译器强加的静态类型安全。结果就是你不能在验证或者测试桩函数之外使用anyObject(), eq()函数。\n如果一个方法没有被Stub设置，会返回该方法返回类型的默认值，比如int类型返回0，boolean返回false，对象类型返回null。\n需要记住的是 mock对象会覆盖整个被mock的对象，因此没有stub的方法只能返回默认值，并且类的方法不会真正的执行。\n4、Spy 介绍 Mock出来的对象（代理对象），默认不会去真正执行类的方法。而用Spy声明的对象（真实对象），则会默认执行真正的方法。\nCopy/** * 也可以使用@Spy注解方式初始化spy对象 * @Spy * List\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); **/ List\u0026lt;Integer\u0026gt; realList = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;Integer\u0026gt; list = spy(realList); list.add(1); list.add(2); // 分别输出1和2，说明真正执行了add和get方法 System.out.println(list.get(0)); System.out.println(list.get(1)); // 进行部分mock when(list.isEmpty()).thenReturn(true); // 输出true，说明isEmpty方法被mock了 System.out.println(list.isEmpty()); // 分别输出1和2，说明get方法不受mock影响 System.out.println(list.get(0)); System.out.println(list.get(1)); 需要注意的是，如果为Spy出来的对象进行Stub，有时候不能使用when，因为Spy对象调用方法时，会调用真实的方法。比如以下例子：\nCopyList list = new LinkedList(); List spy = spy(list); // 不可能 : 因为当调用spy.get(0)时会调用真实对象的get(0)函数,此时会发生IndexOutOfBoundsException异常，因为真实List对象是空的 when(spy.get(0)).thenReturn(\u0026#34;foo\u0026#34;); System.out.println(spy.get(0)); // 你需要使用doReturn()来打桩 doReturn(\u0026#34;foo\u0026#34;).when(spy).get(0); System.out.println(spy.get(0)); Spy和Mock的相同点和区别：\n得到的对象同样可以进行“监管”，即验证和打桩。 如果不对spy对象的methodA打桩，那么调用spy对象的methodA时，会调用真实方法。 如果不对mock对象的methodA打桩，将doNothing，且返回默认值（null,0,false）。 5、断言# Mockito中断言的使用和Junit的一样，这里举几个例子，不详细描述：\nCopyList\u0026lt;Integer\u0026gt; list = mock(List.class); // 断言list.get(0)值等于1 assertThat(list.get(0), equalTo(1)); // 断言大于50 assertThat(list.get(0), greaterThan(20)); // 断言小于等于50 assertThat(list.get(0), lessThanOrEqualTo(50)); // 断言 必须大于20 并且 小于等于50（所有条件成立） assertThat(list.get(0), allOf(greaterThan(20), lessThanOrEqualTo(50))); // 断言 必须大于20 或 小于等于50（其中至少一个条件成立） assertThat(list.get(0), oneOf(greaterThan(20), lessThanOrEqualTo(50))); // 断言任何条件都成立 assertThat(list.get(0), anything()); // 断言等于1 assertThat(list.get(0), is(1)); // 断言不等于-1 assertThat(list.get(0), not(-1)); // 断言返回的字符串包含1 assertThat(list.get(0), containsString(\u0026#34;1\u0026#34;)); // 断言返回的字符串以1开头 assertThat(list.get(0), startsWith(\u0026#34;1\u0026#34;)); // 断言该异常属于RuntimeException assertThat(e, instanceOf(RuntimeException.class)); 可以这样断言异常\nCopytry { list.clear(); // 如果执行到这一步，返回失败 fail(); } catch (Exception e) { assertThat(e, instanceOf(RuntimeException.class)); } 6、验证函数的调用次数 Mockito可以对函数的执行过程进行断言，通过断言函数的执行次数，要对方法执行逻辑进行判断。\nCopyList\u0026lt;Integer\u0026gt; mockedList = mock(List.class); mockedList.add(\u0026#34;once\u0026#34;); mockedList.add(\u0026#34;twice\u0026#34;); mockedList.add(\u0026#34;twice\u0026#34;); mockedList.add(\u0026#34;three times\u0026#34;); mockedList.add(\u0026#34;three times\u0026#34;); mockedList.add(\u0026#34;three times\u0026#34;); // 下面的两个验证函数效果一样,期望mockedList的add(\u0026#34;once\u0026#34;)方法执行了1次 verify(mockedList).add(\u0026#34;once\u0026#34;); verify(mockedList, times(1)).add(\u0026#34;once\u0026#34;); // 验证具体的执行次数，分别希望是2次和3次 verify(mockedList, times(2)).add(\u0026#34;twice\u0026#34;); verify(mockedList, times(3)).add(\u0026#34;three times\u0026#34;); // 使用never()进行验证,never相当于times(0)，即没有执行过 verify(mockedList, never()).add(\u0026#34;never happened\u0026#34;); // 使用atLeast()至少执行次数/atMost()最多执行次数 verify(mockedList, atLeastOnce()).add(\u0026#34;three times\u0026#34;); verify(mockedList, atLeast(2)).add(\u0026#34;five times\u0026#34;); verify(mockedList, atMost(5)).add(\u0026#34;three times\u0026#34;); 7、验证方法的执行顺序 可以使用InOrder来对方法的执行顺序进行验证\nCopy // 进行mock List singleMock = mock(List.class); singleMock.add(\u0026#34;was added first\u0026#34;); singleMock.add(\u0026#34;was added second\u0026#34;); // 为该mock对象创建一个inOrder对象 InOrder inOrder = inOrder(singleMock); // 确保add函数首先执行的是add(\u0026#34;was added first\u0026#34;),然后才是add(\u0026#34;was added second\u0026#34;) inOrder.verify(singleMock).add(\u0026#34;was added first\u0026#34;); inOrder.verify(singleMock).add(\u0026#34;was added second\u0026#34;); ","date":"2020-07-25T16:27:22+08:00","permalink":"https://luky116.github.io/post/2020-07-25.-mockito-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","tags":["Mockito","单元测试"],"title":"Mockito 快速入门"},{"categories":["Guava"],"contents":" Guava工程包含了若干被Google的 Java项目广泛依赖 的核心库，例如：集合 [collections] 、缓存 [caching] 、原生类型支持 [primitives support] 、并发库 [concurrency libraries] 、通用注解 [common annotations] 、字符串处理 [string processing] 、I/O 等等。\nGuava 是Java的工具集，提供了一些常用的便利的操作工具类，减少因为 空指针、异步操作等引起的问题BUG，提高开发效率。\n本文主要介绍了Guava常用的工具方法，快速入门Guava。\n1、基本工具（Base utils） 1. Optional null 值出现在代码中，有如下缺点：\n语义模糊，引起歧义。例如，Map.get(key)返回Null时，可能表示map中的值是null，亦或map中没有key对应的值。 在应用层面可能造成混乱，出现令人意外的错误。 为了尽量避免程序中的null值，guava提供了Optional对数据进行封装。如果值为空则立即抛出异常，并且提供了Absent和Present两个子类分别表示值缺失和值存在的情形，来增强null的语义。\n常用方法如下：\nisPresent()：如果Optional包含非null的引用（引用存在），返回true\nget() ：如果Optional为NULL将触发异常\npublic static void test(){ Optional\u0026lt;Integer\u0026gt; possible = Optional.fromNullable(5); //创建允许null值的Optional if(possible.isPresent()){//包含的引用非null的（引用存在），返回true System.out.println(possible.get()); }else{ System.out.println(\u0026#34;possible is null\u0026#34;); } } or(defaultvalue) ：包含的引用缺失(null)，返回默认的值，否则返回本身\norNull()：包含的引用缺失，返回null\nasSet()：如果引用存在，返回只有单一元素的集合；若为NULl返回空集合\n2. 先决条件 Preconditions Preconditions 提供了判断条件是否合法的静态方法，如果不符合要求会抛出异常。类似断言。\n方法声明（不包括额外参数） 描述 检查失败时抛出的异常 checkArgument(boolean) 检查boolean是否为true，用来检查传递给方法的参数 IllegalArgumentException checkNotNull(T) 检查value是否为null，该方法直接返回value，因此可以内嵌使用checkNotNull NullPointerException checkState(boolean) 用来检查对象的某些状态。 IllegalStateException checkElementIndex(int index, int size) 检查index作为索引值对某个列表、字符串或数组是否有效。index\u0026gt;=0 \u0026amp;\u0026amp; index\u0026lt;size IndexOutOfBoundsException checkPositionIndex(int index, int size) 检查index作为位置值对某个列表、字符串或数组是否有效。index\u0026gt;=0 \u0026amp;\u0026amp; index\u0026lt;=size IndexOutOfBoundsException checkPositionIndexes(int start, int end, int size) 检查[start, end]表示的位置范围对某个列表、字符串或数组是否有效 IndexOutOfBoundsException 每个判断方法都有三个多态方法：\n没有额外参数：抛出的异常中没有错误消息；\n有一个Object对象作为额外参数：抛出的异常使用Object.toString() 作为错误消息；\n有一个String对象作为额外参数，并且有一组任意数量的附加Object对象：这个变种处理异常消息的方式有点类似printf，但考虑GWT的兼容性和效率，只支持%s指示符。例如：\ncheckArgument(i \u0026gt;= 0); checkArgument(i \u0026gt;= 0, \u0026#34;Argument was expected nonnegative\u0026#34;); checkArgument(i \u0026lt; j, \u0026#34;Expected i \u0026lt; j, but %s \u0026gt; %s\u0026#34;, i, j); 3. 连接器 Joiner 用分隔符将多个**字符串（或数组元素）**连接成一个字符串。\n常用方法如下：\non(String)：静态工厂方法，生成一个新的 Joiner 对象，参数为连接符 skipNulls()：如果元素为空，则跳过 useForNull(String)：如果元素为空，则用这个字符串代替 join(数组/链表)：要连接的数组/链表 appendTo(String,数组/链表)：在第一个参数后面新加上 拼接后的字符串 withKeyValueSeparator(String)：得到 MapJoiner，连接Map的键、值 @Test public void test(){ List\u0026lt;String\u0026gt; list1 = Arrays.asList(\u0026#34;aa\u0026#34;, \u0026#34;bb\u0026#34;, \u0026#34;cc\u0026#34;); System.out.println(Joiner.on(\u0026#34;-\u0026#34;).join(list1)); List\u0026lt;String\u0026gt; list2 = Arrays.asList(\u0026#34;aa\u0026#34;, \u0026#34;bb\u0026#34;, \u0026#34;cc\u0026#34;, null, \u0026#34;dd\u0026#34;); System.out.println(Joiner.on(\u0026#34;-\u0026#34;).skipNulls().join(list2)); System.out.println(Joiner.on(\u0026#34;-\u0026#34;).useForNull(\u0026#34;nulla\u0026#34;).join(list2)); Map map = ImmutableMap.of(\u0026#34;k1\u0026#34;, \u0026#34;v1\u0026#34;, \u0026#34;k2\u0026#34;, \u0026#34;v2\u0026#34;); System.out.println(Joiner.on(\u0026#34;-\u0026#34;).withKeyValueSeparator(\u0026#34;=\u0026#34;).join(map)); } 输出：\naa-bb-cc aa-bb-cc-dd aa-bb-cc-null-dd k1=v1-k2=v2 注意：joiner实例总是不可变的。用来定义joiner目标语义的配置方法总会返回一个新的joiner实例。这使得joiner实例都是线程安全的，你可以将其定义为static final常量。\n4. 拆分器 Splitter Splitter 能将一个字符串按照分隔符生成字符串集合，是 Joiner的反向操作。\n常用方法如下：\non(String)：静态工厂方法，生成一个新的 Splitter 对象，参数为连接符\ntrimResults()：结果去除子串中的空格\nomitEmptyStrings()：去除null的子串\nsplit(String)：拆分字符串\nwithKeyValueSeparator(String)：得到 MapSplitter，拆分成Map的键、值。注意，这个对被拆分字符串格式有严格要求，否则会抛出异常\n@Test public void test1(){ String string = \u0026#34; ,a,b,\u0026#34;; System.out.println(Splitter.on(\u0026#34;,\u0026#34;).split(string)); System.out.println(Splitter.on(\u0026#34;,\u0026#34;).trimResults().split(string)); System.out.println(Splitter.on(\u0026#34;,\u0026#34;).omitEmptyStrings().split(string)); System.out.println(Splitter.on(\u0026#34;,\u0026#34;).trimResults().omitEmptyStrings().split(string)); // 根据长度拆分 string = \u0026#34;12345678\u0026#34;; System.out.println(Splitter.fixedLength(2).split(string)); // 拆分成Map System.out.println(Splitter.on(\u0026#34;#\u0026#34;).withKeyValueSeparator(\u0026#34;:\u0026#34;).split(\u0026#34;1:2#3:4\u0026#34;)); } 输出如下：\n[ , a, b, ] [, a, b, ] [ , a, b] [a, b] [12, 34, 56, 78] {1=2, 3=4} 5. 字符串处理 Strings Strings 类主要提供了对字符串的一些操作。主要方法如下：\nnullToEmpty(String string) ：null字符串转空字符串\nemptyToNull(String string)：空字符串转null字符串\nisNullOrEmpty(String string)：判断字符串为null或空字符串\npadStart(String string, int minLength, char padChar)：如果string的长度小于minLeng，在string前添加padChar，直到字符串长度为minLeng。\n@Test public void test(){ String aa = \u0026#34;12345\u0026#34;; // A12345 System.out.println(Strings.padStart(aa, 6, \u0026#39;A\u0026#39;)); // 12345 System.out.println(Strings.padStart(aa, 5, \u0026#39;A\u0026#39;)); } String padEnd(String string, int minLength, char padChar)：和padStart类似，不过是在尾部添加新字符串\ncommonPrefix(CharSequence a, CharSequence b)：返回共同的前缀\ncommonSuffix(CharSequence a, CharSequence b)：返回共同的后缀\n@Test public void test2(){ String aa = \u0026#34;abc123def\u0026#34;; String bb = \u0026#34;abc789def\u0026#34;; System.out.println(Strings.commonPrefix(aa, bb)); System.out.println(Strings.commonSuffix(aa, bb)); } 输出如下：\nabc def 2、集合工具（Collections） 1. 不可变集合 不可变集合，即创建后就只可读，不可修改的集合。为什么要使用不可变集合呢？主要有如下优点（摘自官方文档）：\n当对象被不可信的库调用时，不可变形式是安全的； 不可变对象被多个线程调用时，不存在竞态条件问题 不可变集合不需要考虑变化，因此可以节省时间和空间。所有不可变的集合都比它们的可变形式有更好的内存利用率（分析和测试细节）； 不可变对象因为有固定不变，可以作为常量来安全使用。 JDK也提供了Collections.unmodifiableXXX方法把集合包装为不可变形式，但我们认为不够好：\n笨重而且累赘：不能舒适地用在所有想做防御性拷贝的场景；\n不安全：要保证没人通过原集合的引用进行修改，返回的集合才是事实上不可变的；\n@Test public void test3(){ List\u0026lt;Integer\u0026gt; list = Lists.newArrayList(1,2,3); List\u0026lt;Integer\u0026gt; list1 = Collections.unmodifiableList(list); // [1, 2, 3] System.out.println(list); // [1, 2, 3] System.out.println(list1); // list修改，list1也会被修改 list.add(4); // [1, 2, 3, 4] System.out.println(list1); } 低效：包装过的集合仍然保有可变集合的开销，比如并发修改的检查、散列表的额外空间，等等。\n注意：所有Guava不可变集合的实现都不接受null值。因为谷歌内部调查代码发现，只有5%的情况需要在集合中允许null元素。如果要存储null值，请使用JDK的Collections.unmodifiable方法\n创建不可变集合的几个方法：\ncopyOf 方法，如ImmutableSet.copyOf(set);\nof方法，如ImmutableSet.of(“a”, “b”, “c”)或 ImmutableMap.of(“a”, 1, “b”, 2);\nBuilder工具，如\npublic static final ImmutableSet\u0026lt;Color\u0026gt; GOOGLE_COLORS = ImmutableSet.\u0026lt;Color\u0026gt;builder() .addAll(WEBSAFE_COLORS) .add(new Color(0, 191, 255)) .build(); copyOf 是很智能和高效的，在特定会避免线性拷贝。下期有机会来分析下它的实现原理。\n关联可变集合和不可变集合\n可变集合接口 属于JDK还是Guava 不可变版本 Collection JDK ImmutableCollection List JDK ImmutableList Set JDK ImmutableSet SortedSet/NavigableSet JDK ImmutableSortedSet Map JDK ImmutableMap SortedMap JDK ImmutableSortedMap Multiset Guava ImmutableMultiset SortedMultiset Guava ImmutableSortedMultiset Multimap Guava ImmutableMultimap ListMultimap Guava ImmutableListMultimap SetMultimap Guava ImmutableSetMultimap BiMap Guava ImmutableBiMap ClassToInstanceMap Guava ImmutableClassToInstanceMap Table Guava ImmutableTable 2. Multiset 定义摘自维基百科：\n”集合[set]概念的延伸，它的元素可以重复出现…与集合[set]相同而与元组[tuple]相反的是，Multiset元素的顺序是无关紧要的：Multiset {a, a, b}和{a, b, a}是相等的”\nMultiset继承自JDK中的Collection接口，而不是Set接口，所以可以包含重复元素。可以从以下角度理解：\n没有元素顺序限制的ArrayList Map\u0026lt;E, Integer\u0026gt;，键为元素，值为计数 Multiset提供像无序的ArrayList的基本操作：\nadd(E)添加单个给定元素 iterator()返回一个迭代器，包含Multiset的所有元素（包括重复的元素） size()返回所有元素的总个数（包括重复的元素） 当把Multiset看作Map\u0026lt;E, Integer\u0026gt;时，它也提供了Map的查询操作：\ncount(Object)返回给定元素的计数。 entrySet()返回Set\u0026lt;Multiset.Entry\u0026gt;，和Map的entrySet类似。 elementSet()返回所有不重复元素的Set，和Map的keySet()类似。 常用方法如下：\n方法 描述 count(E) 给定元素在Multiset中的计数 elementSet() Multiset中不重复元素的集合，类型为Set entrySet() 和Map的entrySet类似，返回Set\u0026lt;Multiset.Entry\u0026gt;，\n其中包含的Entry支持getElement()和getCount()方法 add(E, int) 增加给定元素在Multiset中的计数 remove(E, int) 减少给定元素在Multiset中的计数 setCount(E, int) 设置给定元素在Multiset中的计数，不可以为负数 size() 返回集合元素的总个数（包括重复的元素） 应用：统计一个词在文档中出现了多少次。\n传统的做法是这样的\nMap\u0026lt;String, Integer\u0026gt; counts = new HashMap\u0026lt;String, Integer\u0026gt;(); for (String word : words) { Integer count = counts.get(word); if (count == null) { counts.put(word, 1); } else { counts.put(word, count \u0026#43; 1); } } 使用Multiset操作：\nMultiset\u0026lt;String\u0026gt; multiset = HashMultiset.create(); for (String word : words) { multiset.add(word); } int count = multiset.count(\u0026#34;today\u0026#34;); 3. Multimap 通俗来讲，Multimap 是一键对多值的HashMap，类似于 Map\u0026lt;K, List\u0026gt; 的数据结构。\n@Test public void test2() { Multimap\u0026lt;String, String\u0026gt; multimap = ArrayListMultimap.create(); multimap.put(\u0026#34;name\u0026#34;, \u0026#34;Jack\u0026#34;); multimap.put(\u0026#34;name\u0026#34;, \u0026#34;Jack\u0026#34;); multimap.put(\u0026#34;name\u0026#34;, \u0026#34;Tom\u0026#34;); multimap.put(\u0026#34;age\u0026#34;, \u0026#34;10\u0026#34;); multimap.put(\u0026#34;age\u0026#34;, \u0026#34;12\u0026#34;); System.out.println(multimap); System.out.println(multimap.get(\u0026#34;name\u0026#34;).size()); } 输出：\n{name=[Jack, Jack, Tom], age=[10, 12]} 3 常用操作如下：\n方法签名 描述 等价于 put(K, V) 添加键到单个值的映射 multimap.get(key).add(value) putAll(K, Iterable) 依次添加键到多个值的映射 Iterables.addAll(multimap.get(key), values) remove(K, V) 移除键到值的映射；如果有这样的键值并成功移除，返回true。 multimap.get(key).remove(value) removeAll(K) 清除键对应的所有值，返回的集合包含所有之前映射到K的值，但修改这个集合就不会影响Multimap了。 multimap.get(key).clear() replaceValues(K, Iterable) 清除键对应的所有值，并重新把key关联到Iterable中的每个元素。返回的集合包含所有之前映射到K的值。 multimap.get(key).clear(); Iterables.addAll(multimap.get(key), values) 主要操作：\nasMap：为Multimap\u0026lt;K, V\u0026gt;提供Map\u0026lt;K,Collection\u0026gt;形式的视图 entries：返回所有”键-单个值映射”，包括重复键。Collection\u0026lt;Map.Entry\u0026lt;K, V\u0026raquo;类型 keySet：返回所有不同的键，Set类型 keys：用Multiset表示Multimap中的所有键，每个键重复出现的次数等于它映射的值的个数。可以从这个Multiset中移除元素，但不能做添加操作；移除操作会反映到底层的Multimap values：用一个”扁平”的Collection包含Multimap中的所有值，包括重复键 4. BiMap 一般的Map只提供”键-值“的映射，而BiMap则同时提供了”键-值“和”值-键“的映射关系。常用方法：\nput(K key, V value)：添加新的键、值。如果值和已有键重复，会抛出异常\nforcePut(K key, V value)：添加新的键、值。如果值和已有键重复，会覆盖原来的键、值\ninverse()：得到**”值-键“的BitMap**对象\n@Test public void test4(){ BiMap\u0026lt;String,String\u0026gt; biMap= HashBiMap.create(); biMap.put(\u0026#34;sina\u0026#34;,\u0026#34;sina.com\u0026#34;); biMap.put(\u0026#34;qq\u0026#34;,\u0026#34;qq.com\u0026#34;); biMap.put(\u0026#34;sina\u0026#34;,\u0026#34;sina.cn\u0026#34;); //会覆盖原来的value System.out.println(biMap.inverse().get(\u0026#34;qq.com\u0026#34;)); //biMap.put(\u0026#34;tecent\u0026#34;,\u0026#34;qq.com\u0026#34;); //抛出异常 biMap.forcePut(\u0026#34;tecent\u0026#34;,\u0026#34;qq.com\u0026#34;); //强制替换key System.out.println(biMap.get(\u0026#34;qq\u0026#34;)); //通过value找key System.out.println(biMap.inverse().get(\u0026#34;qq.com\u0026#34;)); System.out.println(biMap.inverse().get(\u0026#34;sina.com\u0026#34;)); System.out.println(biMap.inverse().inverse()==biMap); } 输出：\nqq null tecent null true 5. Table Table类似多个索引的表，类似 Map\u0026lt;R, Map\u0026lt;C, V\u0026raquo; 的数据结构。它有两个支持所有类型的键：”行”和”列”，可以通过以下方法获取多个视图：\nrowMap()：用Map\u0026lt;R, Map\u0026lt;C, V\u0026raquo;表现Table\u0026lt;R, C, V\u0026gt;。同样的， **rowKeySet()**返回”行”的集合Set。 row(r)：用Map\u0026lt;C, V\u0026gt;返回给定”行”的所有列，对这个map进行的写操作也将写入Table中。 cellSet()：用元素类型为Table.Cell的Set表现Table\u0026lt;R, C, V\u0026gt;。Cell类似于Map.Entry，但它是用行和列两个键区分的。 ","date":"2020-06-05T17:00:17+08:00","permalink":"https://luky116.github.io/post/guava%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","tags":["Guava"],"title":"Guava 快速入门"},{"categories":["设计模式"],"contents":"23种设计模式(13) - 责任链模式 1、定义 使多个对象都有机会处理请求，从而避免请求的发送者和接受者质检的耦合关系。将这个接收对象连成一条链，并沿着这条链传递请求，直到有一个对象处理他为止。\n2、UML 图 3、组成 抽象处理器（Handler）：主要包含了处理方法handlerRequest和转交对象nextHandler，他的思想是，如果自己能处理则自己处理，否则交给转交对象处理 处理器实现类（FirstHandler）：处理器的实现类，每个实现类自己定义处理逻辑 4、代码 先来看一个反面例子代码，使用大量的if判断来选择执行逻辑：\npublic Response handleRequest(Request request) { Level level = request.getLevel(); if (1 == level) { Handler1.handleRequest(request); } else if (2 == level) { Handler2.handleRequest(request); } else if (3 == level) { Handler3.handleRequest(request); } throw new RuntimeException(\u0026#34;无法处理 ......\u0026#34;) } 这样的代码有以下缺点：\n代码臃肿：如果判断条件不是简单的 1==level，而是更复杂的计算，那代码可读性会很不好； 耦合性高：如果新加一种情况，需要新加 if else语句，改变了原来代码，违反了 封闭-开放 原则。 以下是使用责任链模式的代码：\n// 抽象处理类 public abstract class Handler { // 下一个处理器处理 protected Handler nextHandler; void setNextHandler(Handler nextHandler){ this.nextHandler = nextHandler; } final Response handleRequest(Request request){ // 如果自己能处理，则自己处理 if(request.getLevel() == getHandlerLevel()){ return this.doHandler(request); } System.out.println(\u0026#34;本处理器:\u0026#34;\u0026#43;getHandlerLevel()\u0026#43;\u0026#34; 无法处理，开始转交 ......\u0026#34;); if(null != this.nextHandler){ // 如果不能处理，转交给下一个处理器处理 return this.nextHandler.handleRequest(request); } else { System.out.println(\u0026#34;无合适的处理器，处理失败 ......\u0026#34;); } return null; } // 自己处理的任务标识 abstract Level getHandlerLevel(); // 实际处理逻辑，子类自己定义 abstract Response doHandler(Request request); } // 任务标识，用于区分用哪个处理器处理 public enum Level { FIRST_LEVEL, SECOND_LEVEL, THIRD_LEVEL; } //请求类 public class Request { private Level level; public Request(Level level){ this.level = level; } public Level getLevel() { return level; } } // 处理结果类 public class Response { } // 第一个处理器 public class FirstConcreteHandler extends Handler { @Override Level getHandlerLevel() { return Level.FIRST_LEVEL; } @Override Response doHandler(Request request) { System.out.println(\u0026#34;本处理器:\u0026#34;\u0026#43;getHandlerLevel()\u0026#43;\u0026#34; 开始处理 .....\u0026#34;); return null; } } // 第二个处理器 public class SecondConcreteHandler extends Handler { @Override Level getHandlerLevel() { return Level.SECOND_LEVEL; } @Override Response doHandler(Request request) { System.out.println(\u0026#34;本处理器:\u0026#34;\u0026#43;getHandlerLevel()\u0026#43;\u0026#34; 开始处理 .....\u0026#34;); return null; } } // 第三个处理器 public class ThirdConcreteHandler extends Handler { @Override Level getHandlerLevel() { return Level.THIRD_LEVEL; } @Override Response doHandler(Request request) { System.out.println(\u0026#34;本处理器:\u0026#34;\u0026#43;getHandlerLevel()\u0026#43;\u0026#34; 开始处理 .....\u0026#34;); return null; } } //调用者 public class Main { public static void main(String[] args) { Handler firstHandler = new FirstConcreteHandler(); Handler secondHandler = new SecondConcreteHandler(); Handler thirdHandler = new ThirdConcreteHandler(); firstHandler.setNextHandler(secondHandler); secondHandler.setNextHandler(thirdHandler); // 需要第三个处理类处理 Request request = new Request(Level.THIRD_LEVEL); firstHandler.handleRequest(request); } } 输出结果如下：\n本处理器:FIRST_LEVEL 无法处理，开始转交 ...... 本处理器:SECOND_LEVEL 无法处理，开始转交 ...... 本处理器:THIRD_LEVEL 开始处理 ..... 5、优缺点 只需要在代码中将各中情况链式创起来，使用者只需要知道一个入口，而不用管具体的执行逻辑； 责任链模式是变相版的if else语句，如果链过长，会过量消耗性能； 责任链的链不能出现循引用的情况，否则会出现死循环 6、适用场景 责任链模式其实就是一个灵活版的if…else…语句，只不过它把判断条件放在每个链的节点类中。如觉得代码中if…else…语句使得程序可读性不好，可以考虑责任链模式。\n","date":"2020-05-24T10:22:17+08:00","permalink":"https://luky116.github.io/post/23%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F13---%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F-/","tags":["设计模式"],"title":"23种设计模式(13) - 责任链模式"},{"categories":["设计模式"],"contents":"1、定义 将一个接口转换成客户希望的另一个接口。Adapter 模式使得原本由于接口不兼容而不能一起工作的那些类，可以一起工作。\n2、UML图 3、组成 目标类（Target）：客户端（Client）直接调用的类 被适配类（Adaptee）：实际上执行逻辑的类，但是不能直接被客户端调用 适配器类（Adapter）：将目标类和被适配类 进行适配，是客户端能使用被适配类的功能 4、代码 // 直接调用的类 public class Target { public void request(){ System.out.println(\u0026#34;普通请求！\u0026#34;); } } // 被适配类，实际执行功能的类 public class Adaptee { public void specialRequest(){ System.out.println(\u0026#34;特殊请求！\u0026#34;); } } // 适配器类 public class Adapter extends Target { private Adaptee adaptee = new Adaptee(); @Override public void request() { // 执行被适配类功能 adaptee.specialRequest(); } } // 客户端 public class Main { public static void main(String[] args) { // 执行适配器类的逻辑 Target target = new Adapter(); target.request(); } } 执行结果\n特殊请求！ 5、优缺点 6、适用场景 ","date":"2020-05-22T10:22:17+08:00","permalink":"https://luky116.github.io/post/23%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F4---%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F-/","tags":["设计模式"],"title":"23种设计模式(4) - 适配器模式"},{"categories":["设计模式"],"contents":"1、定义 将一个复杂对象的创建和他的表示分离，使用同样的创建过程可以创建不同的表示（类的不同属性的实例）。\n2、UML 图 3、组成 产品类（Product）：一般是比较复杂的类，即创建该类实例的过程比较复杂 抽象创建者类（IProductBuilder）：创建者的抽象接口类，定义了创建对象的步骤，不同的产品创建类可以实现该接口，设计自己的实现 创建者（ProductABuilder、ProductBBuilder）：负责创建具体的对象实例，封装了创建类的过程。一般有两步分组成，分别是 创建产品的步骤，和返回创建好的对象 导演类（Director）：负责调用适当的创建者来创建产品，一般直接和创建者交互，不会直接和产品类交互 4、代码 // 复杂的对象，产品类 public class Product { private List\u0026lt;String\u0026gt; parts = new ArrayList\u0026lt;\u0026gt;(); // 需要添加多个组件才能创建产品 public void addPart(String part) { this.parts.add(part); } public void show() { System.out.println(\u0026#34;本产品所有组件有：\u0026#34; \u0026#43; parts.toString()); } } // 抽象创建者 public interface IProductBuilder { // 创建步骤 void buildPart1(); void buildPart2(); // 获得创建好的产品 Product getProduct(); } // A产品的创建者 public class ProductABuilder implements IProductBuilder { private Product product = new Product(); // 创建A产品的步骤1 @Override public void buildPart1() { product.addPart(\u0026#34;产品A-部件1\u0026#34;); } // 创建A产品的步骤2 @Override public void buildPart2() { product.addPart(\u0026#34;产品A-部件2\u0026#34;); } @Override public Product getProduct() { return product; } } // B产品的创建者 public class ProductBBuilder implements IProductBuilder { private Product product = new Product(); // 创建产品B的步骤1 @Override public void buildPart1() { product.addPart(\u0026#34;产品B-部件1\u0026#34;); } // 创建产品B的步骤2 @Override public void buildPart2() { product.addPart(\u0026#34;产品B-部件2\u0026#34;); } @Override public Product getProduct() { return product; } } // 导演类，负责调用创建者生成对象 public class Director { public Product getProduct(IProductBuilder builder){ builder.buildPart1(); builder.buildPart2(); return builder.getProduct(); } } // 调用者 public class Main { public static void main(String[] args) { Director director = new Director(); Product productA = director.getProduct(new ProductABuilder()); Product productB = director.getProduct(new ProductBBuilder()); productA.show(); productB.show(); } } 运行结果：\n本产品所有组件有：[产品A-部件1, 产品A-部件2] 本产品所有组件有：[产品B-部件1, 产品B-部件2] 5、优点 封装性好。将复杂对象的创建过程封装，调用者不需要关心创建的过程 拓展性好。如果有新的产品，只需要增加一个产品创建者，而不用修改已有的代码 6、和工厂模式的区别 可以发现，创建者模式和工厂模式很相似，都是用来创建对象实例，区别是 创建者模式多了个 导演类 。\n与工厂模式相比，创建者模式主要用来创建 比较复杂的对象。因为创建的对象比较复杂，所以需要独立出一个单独的类，即 导演类，来负责这个创建的流程；而工厂类则直接创建对象。\n7、适用场景 主要用于创建一些比较复杂的对象，这些对象的内部构建顺序通常比较稳定，但是对象构造的 参数/属性 会有区别。所以，如果一个对象的创建比较复杂，使用工厂模式；如果一个对象的创建特别负责，使用创建者模式。\n","date":"2020-05-18T10:22:17+08:00","permalink":"https://luky116.github.io/post/23%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F3---%E5%88%9B%E5%BB%BA%E8%80%85%E6%A8%A1%E5%BC%8F-/","tags":["设计模式"],"title":"23种设计模式(3) - 创建者模式"},{"categories":["设计模式"],"contents":"1、定义 定义一个用于创建对象的接口，让子类决定实例化哪一个类。工厂方法使一个类的实例化延迟到其子类。\n2、举例 有一个Animal接口，有两个类Dog和Cat分别继承了该接口。我们通过一个叫AnimalDactory的工厂类接口，再定义DogFactory和CatFactory类来分别创建Dog和Cat实例，由调用端来决定使用哪个工厂来创建对象。\n3、代码 // 创建 动物 接口 public interface Animal { void sayName(); } // 创建 猫和狗 类 public class Cat implements Animal { @Override public void sayName() { System.out.println(\u0026#34;我是猫！\u0026#34;); } } public class Dog implements Animal { @Override public void sayName() { System.out.println(\u0026#34;我是狗！\u0026#34;); } } // 创建工厂接口类 public interface IAnimalFactory { Animal createAnimal(); } // 分别创建生成猫和狗 的工厂类 public class CatFactory implements IAnimalFactory{ @Override public Animal createAnimal() { return new Cat(); } } public class DogFactory implements IAnimalFactory{ @Override public Animal createAnimal() { return new Dog(); } } // 客户端使用工厂类来创建动物对象 public class Main { public static void main(String[] args) { // 分别获得生产猫和狗的工厂类 IAnimalFactory catFacroty = new CatFactory(); IAnimalFactory dogFacroty = new DogFactory(); Animal cat = catFacroty.createAnimal(); Animal dog = dogFacroty.createAnimal(); cat.sayName(); dog.sayName(); } } 下面是运行的结果：\n我是猫！ 我是狗！ 4、优点 工厂模式分为 简单工厂模式和工厂方法模式。简单方法模式中的工厂方法一般是静态的，不会有接口，而且一个工厂可以创建多个实例，代码如下：\n// 简单工厂模式的工厂 public class AnimalFactory implements IAnimalFactory{ @Override public Animal createAnimal(String name) { // 通过 if 判断，生成多中不同的实例 if(\u0026#34;cat\u0026#34;.equals(name)){ return new Cat(); } if(\u0026#34;dog\u0026#34;.equals(name)){ return new Dog(); } throw new RuntimeException(\u0026#34;无此类动物：\u0026#34; \u0026#43; name); } } 而在工厂方法模式中，会有工厂接口，而且针对不同的实例，会有多个工厂类。\n大家看到这里会发现，简单工厂模式比起工厂方法模式来说，简洁的多（因为没有多个工厂类）。但是，在简单工厂模式中，工厂类包含了判断逻辑，如果我们要添加一个新的Animal类，需要修改原来工厂类的方法，这样我们不但对拓展开放了，对修改也开放了，违背了 开放-封闭原则。而如果使用工厂方法模式，我们只需要增加一个新的工厂就能实现功能拓展，而不要去修改原来的代码。\n从根本上说，这两种模式都存在判断的问题。简单工厂模式是把判断逻辑放到了工厂的方法中，工厂方法模式则把判断逻辑放在调用端，由调用端来判断该使用哪个工厂类，这样想要加新功能时，只需要修改调用端就行，而不是工厂类。\n5、适用场景 工厂模式屏蔽了创建类的内部细节，降低了调用类之间的耦合度。 如果一个类的创建流程比较复杂，使用工厂类可以有效的降低系统复杂度。 工厂模式依靠抽象架构，具有较好的拓展性。 ","date":"2020-05-12T10:22:17+08:00","permalink":"https://luky116.github.io/post/23%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F1---%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/","tags":["设计模式"],"title":"23种设计模式(1) - 工厂方法模式"},{"categories":["设计模式"],"contents":"1、单一职责原则 就一个类而言，应该只有一个引起它变化的原因。意思是，一个类应该实现单一的职责，如果功能太多就应该将类拆分。\n2、开放-封闭原则（Open Close Principle） 软件实体（比如类、模块、函数等），对于扩展是开放的，对于更改的封闭的。意思是，如果软件要进行拓展时，不能去修改原代码，而应该去拓展原代码。这样能保证程序有较好的拓展性，易于维护和更新升级。为了实现这个功能，需要遵循“依赖倒转原则”。\n3、依赖倒转原则（Dependence Inversion Principle） 即要面向接口编程，而不应该面向实现类编程。\n4、里氏替换原则（Liskov Substitution Principle） 如果程序中使用的是父类的话，那一定能替换成子类，并且察觉不出父类和子类对象的区别。\n换个说法，即类B继承类A时，除添加新的方法完成新增功能外，尽量不要重写父类A的方法，也尽量不要重载父类A的方法。即子类可以拓展父类的功能，但尽量不要修改父类的功能。\n5、迪米特法则（最少知识原则）（Demeter Principle） 一个类对自己依赖的类的内部结构了解的越少越好，即减小类之间的耦合性。所以我们在设计类的时候，尽量降低成员变量的访问权限（private类型），所有逻辑都应该通过方法对外暴露。这样当这个类发生修改时，可以最小限度的影响其他类。\n迪米特法则还有一个更简单的定义：只与直接的朋友通信。首先来解释一下什么是直接的朋友：每个对象都会与其他对象有耦合关系，只要两个对象之间有耦合关系，我们就说这两个对象之间是朋友关系。耦合的方式很多，依赖、关联、组合、聚合等。其中，我们称出现成员变量、方法参数、方法返回值中的类为直接的朋友，而出现在局部变量中的类则不是直接的朋友。也就是说，陌生的类最好不要作为局部变量的形式出现在类的内部。\n6、合成复用原则（Composite Reuse Principle） 原则是尽量首先使用合成/聚合的方式，而不是使用继承。\n","date":"2020-05-10T10:22:17+08:00","permalink":"https://luky116.github.io/post/23%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F0---%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%85%AD%E5%A4%A7%E5%8E%9F%E5%88%99/","tags":["设计模式"],"title":"23种设计模式(0) - 设计模式六大原则"},{"categories":null,"contents":"设计模式（Design pattern）`代表了最佳的实践，通常被有经验的面向对象的软件开发人员所采用。使用设计模式可以帮助我们重用代码，让我们的代码更好的被他人理解。\n设计模式可以分为以下几类：\n1、创建型模式（Creational Patterns） 这些设计模式提供了一种在创建对象的同时隐藏创建逻辑的方式，而不是使用 new 运算符直接实例化对象。\n工厂方法模式（Factory Pattern） 抽象工厂模式（Abstract Factory Pattern） 单例模式（Singleton Pattern） 建造者模式（Builder Pattern） 原型模式（Prototype Pattern） 2、 结构型模式（Structural Patterns） 这些设计模式关注类和对象的组合。继承的概念被用来组合接口和定义组合对象获得新功能的方式。\n适配器模式（Adapter Pattern） 桥接模式（Bridge Pattern） 过滤器模式（Filter、Criteria Pattern） 组合模式（Composite Pattern） 装饰器模式（Decorator/Wrapper Pattern） 外观模式（Facade Pattern） 享元模式（Flyweight Pattern） 代理模式（Proxy Pattern） 3、行为型模式（Behavioral Patterns） 这些设计模式特别关注对象之间的通信。\n责任链模式（Chain of Responsibility Pattern） 命令模式（Command Pattern） 解释器模式（Interpreter Pattern） 迭代器模式（Iterator Pattern） 中介者模式（Mediator Pattern） 备忘录模式（Memento Pattern） 观察者模式（Observer Pattern） 状态模式（State Pattern） 空对象模式（Null Object Pattern） 策略模式（Strategy Pattern） 模板模式（Template Pattern） 访问者模式（Visitor Pattern） 参考资料：\n网址：菜鸟教程-设计模式\n书籍：《大话设计模式》\n","date":"2020-05-08T10:22:17+08:00","permalink":"https://luky116.github.io/post/0%E5%85%B3%E4%BA%8E%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","tags":null,"title":"关于设计模式"},{"categories":["代码规范"],"contents":"1、命名篇 避免使用误导性的命名，比如是List类型变量才会命名为accountList；不使用小写的字母L和大写的字母O来命名变量，因为他们会和数字1和0混淆 变量的命名使用有区分意义的词。比如，ProductInfo和ProductData就没区分；Info和Data就像the、a、an一样是混淆的废话；变量名不出现Variable，表名不出现Table 类名不出现Manager、Processor、Data、Info这类类名；类名必须是名词 使用工厂来新建对象比new对象要好，可以将构造函数private化，比如Complex.fromRealNameNumber(23.0)比new Complex(23.0)要好 每个概念只使用一个词。比如，fetch、retrive和get表示一个意思，尽量别同时出现多个 2、函数篇 函数应该短小，20行封顶最佳 函数应该只做一件事情，如果一个函数可以继续拆分，则说明该函数不止做了一件事 switch 语句如果太长，可以考虑使用 多态 来替代 函数名不要怕长，最好使用描述性的名称，能表达出函数的意义就好 函数参数： 函数的参数越少越好，最好别超过三个，三个或三个以上可以封装成一个对象 对于传入单个参数的函数，一种普遍的作用是使用该参数做别的事，另一种是操作该参数本身。这种情况参数名最好能区分这两种形式，比如String transform(StringBuffer in)，告诉读者期望的输入和输出类型。 如果需要向函数传入布尔值，可能考虑将函数分为两个函数使用 函数名最好由动词加名词组成，比如write(name)就不如writeFiled(name)好，后者清楚知道name是个filed 函数名要明确描述函数所做的所有事情，避免给调用者带来意外的混乱 使用异常代替返回错误码。错误码是在要求调用者立即处理错误，异常可以在后面统一处理 使用了try...catch的代码块最好单独抽离出来一个函数，再调用他，避免把主流程混乱 消除重复的代码 3、注释篇 注释的作用是弥补我们在用代码表达意图时遭遇的失败，所以说，注释是一种失败！\n如果遇到需要写注释的情况，可以优先考虑是否能用变量名或方法名来表达，比如下面，第二种表达会更好：\n// 判断员工是否合法，并且年龄大于65岁 if(employee.flag \u0026amp;\u0026amp; employee.age \u0026gt; 65) if(employee.isEligibleForFullBenefits()) 好的注释使用范围：\n表明法律、作者信息 提供有用的信息，比如对抽象函数注释、对一个正则表达式期望匹配的格式注释等 阐释，对一个比较难懂的参数或返回值进行说明 警示，对一些重要代码进行警示，防止别人修改该代码 // TODO对未完成的工作进行注释 公共API的Javadoc 坏的注释实例：\n多余的注释，比如有无注释意图都很明显的代码\n误导性注释，注释和代码实际行为不符合\n循规式注释，比如要求所有函数都要有Javadoc注释\n能用函数或是变量名时，就别用注释\n括号后后面的注释，本意是好的，但是根本解决方法应该是缩短函数篇幅\nwhile(xxxx){ ....... if(xxx){ ...... } // if } // while 注释掉的不用的代码直接删除，别怕找不回\n4、格式篇 封包声明、导入声明和每个函数之间使用 空行 隔开，提高代码的视觉效果\n质检关系“亲密”的概念应该相互 靠近，而不是空行隔开\n变量的声明应该在 靠近 使用的位置\n类成员变量应该声明在类的顶部，循环中变量应该在括号内声明\n相关函数，比如A函数调用了B函数，则A和B最好放在一起，而且A放在B上面\n每行代码长度最好不要太长，比如最好80个字符，或是100~120个字符内\n5、对象和数据结构篇 类的私有变量如果提供了取值器和赋值器，那么它仍然是 暴露 了\n墨忒尔定律：模块不该去了解它所操作对象的内部情形。就是说，对象不改通过存取器暴露其内部变量。更准确的说，墨忒尔定律认为，类C的方法f只能调用以下对象的方法：\nC 由f创建的对象 作为参数传递给f的对象 C的成员变量的对象 即，方法不该调用任何函数返回的对象的方法，只跟朋友对话，不与陌生人对话\n6、其他 函数不要返回控制，避免使用时检查 函数参数不要传递空值 第三方API如果抛出大量异常，可以考虑封装下再使用 说明：本文整理了部分书中观点，有些观点个人感觉有点苛刻不太实用，还有些章节直接略过了。想更详细了解请参考原著。\n","date":"2019-08-18T14:00:07+08:00","permalink":"https://luky116.github.io/post/%E4%BB%A3%E7%A0%81%E6%95%B4%E6%B4%81%E4%B9%8B%E9%81%93%E6%95%B4%E7%90%86/","tags":["代码整洁之道"],"title":"《代码整洁之道》整理"},{"categories":["MySQL"],"contents":"1. 关联查询执行流程 MySQL执行关联查询的策略很简单，他会从一个表中循环取出单条数据，然后用该条数据到下一个表中寻找匹配的行，然后回溯到上一个表，到所有的数据匹配完成为止。因此也被称为“嵌套循环关联”。\n来看下面这个SQL：\nselect tb1.col1, tb2,col2 from tb1 inner join tb2 using(col3) where tb1.col1 in (5,6) 他的执行顺序为（伪代码）：\nList outerDataList = \u0026#34;select * from tb1 where col1 in (5,6)\u0026#34; for(outerData in outerDataList){ List innerDataList = \u0026#34;select * from tb2 where col3 = outerData.col3\u0026#34; for(innerData : innerDataList){ output(outterData,innerData) } } MySQL认为所有的查询都是一次关联查询，所以如果查询一个表，上述过程也适合，不过只需要完成上面外层的基本操作。\n再来看看left outter join查询的过程，SQL如下：\nselect tb1.col1, tb2,col2 from tb1 left outer join tb2 using(col3) where tb1.col1 in (5,6) 伪代码如下：\nList outerDataList = \u0026#34;select * from tb1 where col1 in (5,6)\u0026#34; for(outerData in outerDataList){ List innerDataList = \u0026#34;select * from tb2 where col3 = outerData.col3\u0026#34; if(innerDataList != null){ for(innerData : innerDataList){ output(outterData,innerData) } }else{ // inner表无对应数据，以outter数据为准 output(outterData,null) } } 但是这种遍历的查询方式不能满足所有的联合查询，比如**“全外连接”查询（full outer join）**不能使用该方法来实现，这可能是MySQL不支持全外接查询的原因 ~~~\n2. 优化 MySQL会将查询命令生成一颗指令树，比如四表联合查询的指令树如下： ​\nMySQL在生成指令树之前会先对SQL语句的执行效率进行评估，然后选择他认为效率最高的关联顺序执行。对于如下SQL：\nEXPLAIN SELECT actor.NAME, film.title FROM actor actor INNER JOIN film_actor USING ( actor_id ) INNER JOIN film USING ( film_id ) 从执行计划可以看出，MySQL选择将film作为第一个关联表，拿到数据后再依次扫描film_actor、actor表取数据。MySQL的选择策略是，尽量让查询执行更少的嵌套循环和回溯操作，因此，他会尽量将外层查询的数据量更少。因为film表只有4条记录，actor表有6条记录，因此他认为选择将film作为第一个表开始查询有更高的执行效率。\n但是MySQL的优化策略会比这复杂的多，MySQL会计算所有执行顺序的代价，然后选择他认为的最佳执行计划。但是，如果联合查询的表比较多，他不一定能穷举所有的执行情况选择最佳的执行策略，所以这种默认的优化方式却不一定总是最佳的。还是以上条SQL为例子，假设在film表的film_id字段上建立了索引，那么即使film上的字段少于actor，可能使用actor表作为第一个表进行查询，效率会更高（里层嵌套查询film表数据时可以使用索引）。如果你认为有更佳的执行顺序，可以使用STRAIGHT_JOIN关键字强行执行查询顺序：\nEXPLAIN SELECT actor.NAME, film.title FROM actor actor STRAIGHT_JOIN film_actor USING ( actor_id ) STRAIGHT_JOIN film USING ( film_id ) 注意：绝大多数时候，MySQL做出的判断都比人类要准确，绝大多数时候，不推荐强制执行顺序。\n","date":"2019-08-10T14:04:09+08:00","permalink":"https://luky116.github.io/post/mysql%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96-%E5%85%B3%E8%81%94%E6%9F%A5%E8%AF%A2/","tags":["MySQL优化"],"title":"MySQL查询优化 关联查询"},{"categories":["Java多线程","Java源码"],"contents":"0、概述 ThreadLocal，即线程本地变量。它是将变量绑定到特定的线程上的“入口“，使每个线程都拥有改变量的一个拷贝，各线程相同变量间互不影响，是实现共享资源的轻量级同步。\n下面是个ThreadLocal使用的实例，两个任务共享同一个变量，并且两个任务都把该变量设置为了线程私有变量，这样，虽然两个任务都”持有“同一变量，但各自持有该变量的拷贝。因此，当一个线程修改该变量时，不会影响另一线程该变量的值。\npublic class LocalTest1 implements Runnable { // 一般会把 ThreadLocal 设置为static 。它只是个为线程设置局部变量的入口，多个线程只需要一个入口 private static ThreadLocal\u0026lt;Student\u0026gt; localStudent = new ThreadLocal() { // 一般会重写初始化方法，一会分析源码时候会解释为什么 @Override public Student initialValue() { return new Student(); } }; private Student student = null; @Override public void run() { String threadName = Thread.currentThread().getName(); System.out.println(\u0026#34;【\u0026#34; \u0026#43; threadName \u0026#43; \u0026#34;】：is running !\u0026#34;); Random ramdom = new Random(); //随机生成一个变量 int age = ramdom.nextInt(100); System.out.println(\u0026#34;【\u0026#34; \u0026#43; threadName \u0026#43; \u0026#34;】：set age to :\u0026#34; \u0026#43; age); // 获得线程局部变量，改变属性值 Student stu = getStudent(); stu.setAge(age); System.out.println(\u0026#34;【\u0026#34; \u0026#43; threadName \u0026#43; \u0026#34;】：第一次读到的age值为 :\u0026#34; \u0026#43; stu.getAge()); try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\u0026#34;【\u0026#34; \u0026#43; threadName \u0026#43; \u0026#34;】：第二次读到的age值为 :\u0026#34; \u0026#43; stu.getAge()); } public Student getStudent() { student = localStudent.get(); // 如果不重写初始化方法，则需要判断是否为空，然后手动为ThreadLocal赋值 // if(student == null){ // student = new Student(); // localStudent.set(student); // } return student; } public static void main(String[] args) { LocalTest1 ll = new LocalTest1(); Thread t1 = new Thread(ll, \u0026#34;线程1\u0026#34;); Thread t2 = new Thread(ll, \u0026#34;线程2\u0026#34;); t1.start(); t2.start(); } } public class Student{ private int age; public Student(){ } public Student(int age){ this.age = age; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } } 运行结果：\n【线程1】：is running ! 【线程2】：is running ! 【线程2】：set age to :45 【线程1】：set age to :25 【线程1】：第一次读到的age值为 :25 【线程2】：第一次读到的age值为 :45 【线程1】：第二次读到的age值为 :25 【线程2】：第二次读到的age值为 :45 1、ThreadLocal 源码分析 ThreadLocal 源码有很多方法，但是暴露出来的公共接口只有三个：\npublic ThreadLocal{ public T get() {} public void set(T value) {} public void remove() {} } set(T value) 是设置局部变量的方法，源码如下：\npublic void set(T value) { // 获得当前线程 Thread t = Thread.currentThread(); // 获得当前线程的 ThreadLocalMap 引用，详细见下 ThreadLocalMap map = getMap(t); // 如果不为空，则更新局部变量的值 if (map != null) map.set(this, value); //如果不是第一次使用，先进行初始化 else createMap(t, value); } getMap(t) 源码如下，每一个Thread变量都自带了一个ThreadLocalMap类型的成员变量，用于保存该线程的成员变量。\nThreadLocalMap getMap(Thread t) { //返回该线程Thread的成员变量threadLocals return t.threadLocals; } 但是，Thread 默认把threadLocals设置为了null，因此第一次使用局部变量时候需要先初始化。\nThreadLocal.ThreadLocalMap threadLocals = null; ThreadLocalMap 是定义在ThreadLocal 类里的内部类，它的作用是存储线程的局部变量。ThreadLocalMap 以ThreadLocal的引用作为键，以局部变量作为值，存储在ThreadLocalMap.Entry （一种存储键值的数据结构）里。关于ThreadLocalMap 的源码，后文会详细介绍，这里只要知道大概原理即可。\n由此我们可以总结ThreadLocal 的设计思想如下：\nThreadLocal 只是个访问局部变量的入口。 局部变量的值存在线程Thread 类本地，默认为null，只有通过ThreadLocal 访问时才会进行初始化。 [ThreadLocalMap 的设计思路在后文介绍ThreadLocalMap 源码时候会分析] get() 是获得线程本地变量，源码如下：\npublic T get() { //获得当前线程 Thread t = Thread.currentThread(); //得到当前线程的一个threadLocals 变量 ThreadLocalMap map = getMap(t); if (map != null) { // 如果不为空，以当前ThreadLocal为主键获得对应的Entry ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) { @SuppressWarnings(\u0026#34;unchecked\u0026#34;) T result = (T)e.value; return result; } } //如果值为空，则进行初始化 return setInitialValue(); } 再来看看初始化函数setInitialValue() 所进行的操作：\nprivate T setInitialValue() { //获得初始默认值 T value = initialValue(); //得到当前线程 Thread t = Thread.currentThread(); // 获得该线程的ThreadLocalMap引用 ThreadLocalMap map = getMap(t); //不为空则覆盖 if (map != null) map.set(this, value); else //若是为空，则进行初始化，键为本ThreadLocal变量，值为默认值 createMap(t, value); } // 默认初始化返回null值，这也是为什么需要重写该方法的原因。如果没有重写，第一次get()操作获得的线程本地变量为null，需要进行判断并手动调用set()进行初始化 protected T initialValue() { return null; } 2、ThreadLocalMap 源码分析 Thread类中包含一个ThreadLocalMap 类型的成员变量threadLocals，这是直接存储线程局部变量的数据结构。ThreadLocal 只是一个入口，通过ThreadLocal操作threadLocals，进行局部变量的查改操作。这也是为什么ThreadLocal 暴露的公有接口才三个的原因吧。同时，由于ThreadLocalMap 中的键是ThreadLocal类，也说明了，如果想为一个线程设置多个本地局部变量，需要设置多个 ThreadLocal。下面来分析下ThreadLocalMap 的源码。\nThreadLocalMap 里有几个核心的属性，和HashMap相似：\n// table 默认大小，大小为2的次方，用于hash定位 private static final int INITIAL_CAPACITY = 16; // 存放键值对的数组 private Entry[] table; // 扩容的临界值，当table元素大到这个值，会进行扩容 private int threshold; 在调用ThreadLocal 中的set(T) 方法时，调用了ThreadLocalMap 的set(ThreadLocal, T) 方法，\nprivate void set(ThreadLocal\u0026lt;?\u0026gt; key, Object value) { Entry[] tab = table; int len = tab.length; // Hash 寻址，与table数组长度减1（二进制全是1）相与，所以数组长度必须为2的次方，减小hash重复的可能性 int i = key.threadLocalHashCode \u0026amp; (len-1); //从hash值计算出的下标开始遍历 for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) { //获得该Entry的键 ThreadLocal\u0026lt;?\u0026gt; k = e.get(); //如果键和传过来的相同，覆盖原值，也说明，一个ThreadLocal变量只能为一个线程保存一个局部变量 if (k == key) { e.value = value; return; } // 键为空，则替换该节点 if (k == null) { replaceStaleEntry(key, value, i); return; } } tab[i] = new Entry(key, value); int sz = \u0026#43;\u0026#43;size; //是否需要扩容 if (!cleanSomeSlots(i, sz) \u0026amp;\u0026amp; sz \u0026gt;= threshold) rehash(); } 为什么说数组长度为2的次方有利于hash计算不重复呢？我们来看下，显然，和一个二进制全是1的数相于，能最大限度的保证原数的所有位数，因而重复几率会变小。\n可以看出ThreadLocalMap 采用线性探测再散列解决Hash冲突的问题。即，如果一次Hash计算出来的数组下标被占用，即hash值重复了，则在该下标的基础上加1测试下一个下标，直到找到空值。比如说，Hash计算出来下标i为6，table[6] 已经有值了，那么就尝试table[7]是否被占用，依次类推，直到找到空值。以上，就是保存线程本地变量的方法。\n再来分析下ThreadLocal 中的get() 方法，其中调用了ThreadLocalMap 的map.getEntry(this) 方法，并把本ThreadLocal作为参数传入，返回一个ThreadLocalMap.Entry对象（以后简称Entry），源码如下：\nprivate Entry getEntry(ThreadLocal\u0026lt;?\u0026gt; key) { //Hash计算数组下标 int i = key.threadLocalHashCode \u0026amp; (table.length - 1); //得到该下标的节点 Entry e = table[i]; //如果该节点存在，并且键和传过来的ThreadLocal对象相同，则返回该节点（说明该节点没有进行Hash冲突处理） if (e != null \u0026amp;\u0026amp; e.get() == key) return e; //如果该节点不直接满足需求，可能进行了Hash冲突处理，则另外处理 else return getEntryAfterMiss(key, i, e); } 再来分析下getEntryAfterMiss(ThreadLocal, int , Entry) 的源码：\n// if (e == null || e.get() != key) private Entry getEntryAfterMiss(ThreadLocal\u0026lt;?\u0026gt; key, int i, Entry e) { Entry[] tab = table; int len = tab.length; //从洗标为i开始遍历，直到遇到下一空节点或或是满足需求的节点 while (e != null) { ThreadLocal\u0026lt;?\u0026gt; k = e.get(); if (k == key) return e; if (k == null) //节点不为空，键为空，则清理该节点 expungeStaleEntry(i); else // i后移 i = nextIndex(i, len); e = tab[i]; } //否则返回空值 return null; } 以上就是ThreadLocalMap 几个比较关键的源码分析。\n3、总结 综上所述可知，ThreadLocal 只是访问Thread本地变量的一个入口，正真存储本地变量的其实是在Thread本地，同时ThreadLocal也作为一个键去Hash找到变量所在的位置。也许你会想，为什么不把ThreadLocalMap设置为\u0026lt; Thread,Variable\u0026gt;类型，把Thread作为主键，而要增加一个中间模块ThreadLocal？我的想法是，一来，这样确实可以满足需求，但是这样无法进行hash查找，如果一个Thread的本地变量过多，通过线性查找会花费大量时间，使用ThreadLocal作为中间键，可以进行Hash查找；二来，其实本地变量的添加、查找和删除需要进行大量的操作，设计者的思路是把这些操作封装在一个ThreadLocal类里，而只暴露了三个常用的接口，如果把ThreadLocal去掉，这些操作可能要写在Thread类里，违背了设计类的“单一性”原则；三来，我们这样相当于为每个本地变量取了个“名字”（即，一个ThreadLocal对应一个本地变量），使用方便。\n","date":"2017-11-20T14:09:22+08:00","permalink":"https://luky116.github.io/post/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%AD%A6%E4%B9%A0%E4%B9%8Bthreadlocal%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","tags":["ThreadLocal","源码"],"title":"Java多线程学习之ThreadLocal源码分析"},{"categories":["Java多线程"],"contents":"0、概述 synchronized是Java提供的内置的锁机制，来实现代对码块的同步访问，称为内置锁（Intrinsic Lock） 。内置锁包括两部分：一个是作为锁的对象的引用，另一个是由这个锁保护的代码块。需要理解的是，synchronized的锁都是对象的引用，同一个对象只有一个内置锁，不同的对象有不同的内置锁。\nJava 的内置锁是一种互斥锁，即一个对象的锁只能同时被一个线程持有。假设线程A尝试获取线程B持有的锁，线程A会被阻塞，知道B释放该锁，A才能持有该锁。如果线程B永远不是释放该锁，线程A也将永远等待下去，形成死锁。 由于线程在等待内置锁的过程中无法被中断，这是synchronized内置锁的一个弊端，该需求可以被显示锁ReentranLock解决，可以参考这篇博客：http://www.cnblogs.com/moongeek/p/7857794.html。\n获得一个对象内置锁的唯一途径就是进入由该对象锁保护的代码块，释放锁的唯一途径是跳出该代码块。一般synchronized使用方法如下：\nsynchronized(lock){ // 访问或修改由该锁保护的共享状态 } 1、synchronized的使用 synchronized可以修饰一般方法、static方法、代码块，但是不论synchronized修饰什么，他获取的都是一个对象的内置锁，锁的单位都是对象。\n1）synchronized 修饰一般方法，锁是持有该方法的对象的锁，访问同一个类的相同方法时候会互斥。\npublic synchronized void doSomething(){ // ... } 上代码等价于：\npublic void doSomething(){ synchronized(this){ // ... } } 2）synchronized 修饰代码块，锁是指定的对象的锁，如果是同一个对象的锁，那么会互斥访问。\n// 锁为object对象的锁 synchronized(object){ } 3）synchronized 修饰静态方法，锁是该类Class对象的锁，该类的所有对象访问该类时都会互斥。\npublic class Demo{ public synchronized static void doSomething(){ // ... } } 上代码等价于：\npublic class Demo{ public static void doSomething(){ synchronized(Demo.class){ // ... } } } 2、可重入性 当某个线程请求一个已经被其他线程持有的锁时，该线程会被阻塞。但是内置锁是可重入的，因此，如果一个内置锁尝试获得已经由他自己持有的锁，那这个请求会立即成功。“重入”意味着获取锁的操作粒度是“线程”而不是”调用“。\n重入的实现方法是，为每个所关联一个锁和一个计数值。当计数值为0时，这个锁就被认为是没有被任何线程持有。当线程请求一个未被持有的线程时，JVM记下这个持有者，并且将计数值增1.如果同一个线程再次获得这个锁，计数值将增加，而当线程退出同步代码块时，计数器相应的递减。当计数值为0，这个锁将被释放。\npublic class Test { private Object lock; public synchronized void saySomething(){ } public synchronized void doSomething(){ // 两个函数都是同一个对象锁，可重入 saySomething(); } public void goSomewhere(){ // 对象锁不一致，不能重入 synchronized (lock){ saySomething(); } } } ","date":"2017-11-19T14:14:42+08:00","permalink":"https://luky116.github.io/post/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%AD%A6%E4%B9%A0%E4%B9%8Bsynchronized%E6%80%BB%E7%BB%93/","tags":["synchronized","源码"],"title":"Java多线程学习之synchronized总结"},{"categories":["Java多线程"],"contents":"　任务和线程的启动很容易。在大多数情况下我们都会让他们运行直到结束，或是让他们自行停止。但是，有时我们希望提前结束任务或是线程，可能是因为用户请求取消，或是线程在规定时间内没有结束，或是出现了一些问题迫使线程要提前结束。\n强制一个线程或是服务立即停止，可能会造成共享数据状态不一致的问题，比如，两个线程正对一个共享数据进行操作，然后被突然杀死，这样会对数据造成不确定性的影响。Java中没有提供任何机制来安全的终止线程，但它提供了中断，这种协作机制，“提醒”线程可以自己结束自己线程。这种机制提供了更好的灵活性，因为任务本身的代码比发出取消请求的代码更清楚如何执行停止工作。\n1、使用“标志”变量取消任务 public class PrimeGenerator implements Runnable { private final List\u0026lt;BigInteger\u0026gt; primes = new ArrayList\u0026lt;\u0026gt;(); // 标志变量，设置为volatile，保证可见性 private volatile boolean canceled = false; @Override public void run() { BigInteger p = BigInteger.ONE; // 依靠标志位判断是否结束线程 while(!canceled){ p = p.nextProbablePrime(); synchronized (this){ primes.add(p); } } } // 取消 public void cancel(){canceled = true;} //返回结果 public synchronized List\u0026lt;BigInteger\u0026gt; get(){ return primes; } } 上述代码设置一个volatile “已请求取消”标志，而任务将定期查看该标志。 PrimeGenerator 将持续的枚举素数，直到标志位被设置为取消结束。PrimeGenerator 每次枚举素数时候都会检查canceled标志位是否被改变。\npublic List\u0026lt;BigInteger\u0026gt; aPrimes() throws InterruptedException { PrimeGenerator generator = new PrimeGenerator(); new Thread(generator).start(); try{ // 睡眠1秒 TimeUnit.SECONDS.sleep(1); }finally { // 1秒后取消 generator.cancel(); } return generator.get(); } 调用素数生成器运行1秒后取消，值得注意的是，素数生成器可能不会在1秒后“准时”停止，因为他可能此时刚好在while内执行。取消语句放在finally语句执行，保证该语句一定会被执行。\n2、取消策略 在设计良好的程序中，一个可取消的任务必须拥有取消策略，这个策略详细定义取消操作的“How”、“When”、“What”，即代码如何（How）请求取消该任务，任务在何时（When）检查是否已经请求了取消，以及在响应时执行那些（What）操作。\n在上述代码中，PrimeGenerator采用了简单的取消策略：客户代码通过canceled来请求取消，PrimeGenerator在每次执行搜索前首先检查是否存在取消请求，如果存在则退出。\n3、中断线程 PrimeGenerator 中取消机制之所以能成功，是因为程序会不间断定期的检查标志位的状态是否被改变。但是，如果程序调用了一个阻塞方法，例如，BlockingQueu.put()那么可能会出现问题，即任务可能永远不会检查取消标志。【阻塞队列不了解的看看这篇博客：http://www.cnblogs.com/moongeek/p/7832855.html#_label3】\n// 不推荐的写法 public class BrokenPrimeProducer extends Thread { // 阻塞队列 private final BlockingQueue\u0026lt;BigInteger\u0026gt; queue; // 中断位 private volatile boolean canceled = false; public BrokenPrimeProducer(BlockingQueue\u0026lt;BigInteger\u0026gt; queue){ this.queue = queue; } @Override public void run(){ try { BigInteger p = BigInteger.ONE; while (!canceled) { // PUT操作可能会被阻塞，将无法检查 canceled 是否变化，因而无法响应退出 queue.put(p = p.nextProbablePrime()); } }catch (InterruptedException ex){} } public void cancel(){ canceled = true; } } 如果阻塞队列在 put() 操作被阻塞，此时，即使我们调用cancel() 方法将状态变量改变，进程也无法检查到改变，因为会一直阻塞下去。\n每个Thread都有一个boolean类型的中断状态。当中断线程时，改状态会被置为true。Thread中包含的中断方法如下。其中 inturrept() 会将中断状态置为true，而 isInterrupted() 方法会返回当前的中断状态，而 interrupted() 方法则会清除当前状态，并返回它之前的值。\npublic class Thread{ public void inturrept(){......} public boolean isInterrupted(){......} public static boolean interrupted(){......} } 通常情况下，如果一个阻塞方法，如：Object.wait()、Thread.sleep()和Thread.join() 时，都会去检查中断状态的值，发现中断状态变化时都会提前返回并响应中断：清除中断状态，并抛出InterruptedException异常 。\n**该注意的是，中断操作并不会真正的中断一个正在运行的线程，而只是发出中断请求，然后由程序在合适的时刻中断自己。**一般设计方法时，都需要捕获到中断异常后对中断请求进行某些操作，不能完全忽视或是屏蔽中断请求。\n对上代码进行改进，采用中断进行中断程序执行。代码中有两处可以检测中断：在阻塞的put() 方法中，以及循环开始处的查询中断状态时。其实put() 操作会检测响应异常，在循环开始时可以不进行检测，但这样可以获得更高效的响应性能。\npublic class PrimeProducer extends Thread { // 阻塞队列 private final BlockingQueue\u0026lt;BigInteger\u0026gt; queue; public PrimeProducer(BlockingQueue\u0026lt;BigInteger\u0026gt; queue){ this.queue = queue; } @Override public void run(){ try { BigInteger p = BigInteger.ONE; while (!Thread.currentThread().isInterrupted()) { queue.put(p = p.nextProbablePrime()); } }catch (InterruptedException ex){ // 允许退出线程 } } public void cancel(){ // 中断 interrupt(); } } 中断是实现取消的最合理方式，在取消之外的其他操作中使用中断，都是不合理的。\n4、中断策略 中断策略解释某个中断请求：当发现中断请求时，应该做哪些工作，以多快的速度来响应中断。任务一般不会在其自己拥有的线程中执行，而是在其他某个服务（比如说，在一个其他线程或是线程池）中执行。对于非线程所有者而言（例如，对线程池来说，任何线程池实现之外的代码），应该保存并传递中断状态，使得真正拥有线程的代码才能对中断做出响应。\n比如说，如果你书写一个库函数，一般会抛出InterruptedException作为中断响应，而不会在库函数时候把中断异常捕获并进行提前处理，而导致调用者被屏蔽中断。因为你不清楚调用者想要对异常进行何种处理，比如说，是接收中断后立即停止任务还是进行相关处理并继续执行任务。中断的处理必须由该任务自己决定，而不是由其他线程决定。\n因为在捕获InterruptException 中会同时把中断位恢复，所以，如果想捕获异常后恢复中断位，一般会调用 Thread.currentThread.interrupt() 进行中断位的恢复。\ntry { // dosomething(); } catch (InterruptedException e) { // 捕获异常后恢复中断位 Thread.currentThread().interrupt(); e.printStackTrace(); } 5、使用Future 来实现取消 关于Future 对象：ExecutorService.submit 方法将返回一个Future 来描述任务。\npublic interface Future\u0026lt;V\u0026gt; { // 是否取消线程的执行 boolean cancel(boolean mayInterruptIfRunning); // 线程是否被取消 boolean isCancelled(); //线程是否执行完毕 boolean isDone(); // 立即获得线程返回的结果 V get() throws InterruptedException, ExecutionException; // 延时时间后再获得线程返回的结果 V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; } public static void main(String[] args) { ExecutorService service = Executors.newSingleThreadExecutor(); Future future = service.submit(new TheradDemo()); try { // 可能抛出异常 future.get(); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); }finally { //终止任务的执行 future.cancel(true); } } Future 中的 cancel(boolean mayInterruptIfRunning) 接受一个布尔参数表示取消操作是否成功。如果Future.get() 抛出异常，如果你不需要得到结果时，就可以通过cancel(boolean) 来取消任务。\n对于线程池中的任务，如果想想要取消执行某任务，不宜中断线程池，因为你不知道中断请求到达时正在执行什么任务，所以只能通过cancel(boolean) 来定向取消特定的任务。\n6、关闭ExecutorService 线程池相关对象ExecutorService 提供了两种关闭的方法：使用 shutdown() 正常关闭，他先把线程池状态设置为SHUTDOWN ，禁止再向线程池提交任务，然后把线程池中的任务全部执行完毕，就关闭线程池。这种方法速度较慢，但是更安全。以及使用shutdownNow() 首先关闭正在执行的任务，然后返回所有尚未启动的任务清单。这种方法速度快，但风险也大，因为有的任务可能执行了一般被关闭。\n","date":"2017-11-18T14:16:39+08:00","permalink":"https://luky116.github.io/post/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%8F%96%E6%B6%88%E4%B8%8E%E4%B8%AD%E6%96%AD%E6%9C%BA%E5%88%B6/","tags":["线程中断","源码"],"title":"Java多线程学习之线程的取消与中断机制"},{"categories":["Java多线程"],"contents":"　synchronized 是内置锁，而Lock 接口定义的是显示锁，Lock 提供了一种可重入的、可轮询的、定时的以及可中断的锁获取操作。\nReenTranLock实现了Lock接口，并提供了与synchronized 相同的互斥性和内存可见性。在获取ReentranLock时，有着与进入同步代码块相同的内存语义，在释放ReentranLock时，有着与退出同步代码块相同的语义。\n1、Lock 方法分析 public interface Lock { void lock(); void lockInterruptibly() throws InterruptedException; Condition newCondition(); boolean tryLock(); boolean tryLock(long time, TimeUnit unit) throws InterruptedException; void unlock(); } lock()：获得Lock锁 lockInterruptibly()：获得锁，可被中断 newCondition()：返回一个条件Condition对象 tryLock()：尝试获得锁 tryLock(long time, TimeUnit unit)：尝试在一定时间内获得锁，期间被阻塞 unlock()：释放锁 Lock 接口使用的标准形式：\n// 创建锁 Lock lock = new ReentranLock(); ... lock.lock(); try{ // 进行必要操作 // 捕获异常，并在必要时恢复不变性条件 }finally{ //释放锁 lock.unlock(); } 注意，使用Lock时一定要在finally语句里面释放锁，否则发生异常时可能会导致锁无法被释放，导致程序奔溃。\n2、轮询锁和定时锁 相比于synchronized内置锁的无条件锁获取模式，Lock提供了tryLock() 实现可定时和可轮询的锁获取模式，这也使Lock具有更完善的错误恢复机制。在内置锁中，死锁是一个很严重的问题，造成死锁的原因之一可能是，锁获取顺序不一致导致程序死锁。比如说，线程1持有A对象锁，正在等待获取B对象锁；线程2持有B对象锁，正在等待获取A对象锁。这样，两个线程都会由于获取不到想要的锁而陷入死锁的境地。解决办法可以是，两个线程要么同时获取两个锁，要么一个锁都不获取。Lock 的可定时和可轮询锁就可以很好的满足该条件，从而避免死锁的发生（即操作系统中著名的哲学家进餐问题）。\n下面代码要实现统计两个资源的数量总和操作：使用tryLock尝试同时获取两个资源的锁，如果不能同时获取两个资源的锁，则退出重试。如果在规定时间内不能同时获取两对象的锁并完成操作，则返回-1作为失败的标识。\n// 资源类 public class Resource { //资源总和 private int resourceNum; // 显示锁 public Lock lock = new ReentrantLock(); public Resource(int resourceNum){ this.resourceNum = resourceNum; } //返回此资源的总量 public int getResourceNum(){ return resourceNum; } } public class LockTest1 { //传入两个资源类和预期操作时间，在此期间内返回两个资源的数量总和 public int getResource(Resource resourceA, Resource resourceB, long timeout, TimeUnit unit) throws InterruptedException { // 获取当前时间，算出操作截止时间 long stopTime = System.nanoTime() \u0026#43; unit.toNanos(timeout); while(true){ try { // 尝试获得资源A的锁 if (resourceA.lock.tryLock()) { try{ // 如果获得资源A的锁，尝试获得资源B的锁 if(resourceB.lock.tryLock()){ //同时获得两资源的锁，进行相关操作后返回 return getSum(resourceA, resourceB); } }finally { resourceB.lock.unlock(); } } }finally { resourceA.lock.unlock(); } // 判断当前是否超时，规定-1为错误标识 if(System.nanoTime() \u0026gt; stopTime) return -1; //睡眠1秒，继续尝试获得锁 TimeUnit.SECONDS.sleep(1); } } // 获得资源总和 public int getSum(Resource resourceA,Resource resourceB){ return resourceA.getResourceNum()\u0026#43;resourceB.getResourceNum(); } } 对于内置锁，在开始请求后，这个操作将无法在规定时间内取消或是中途中断 ，因此内置锁很难实现带时间限制的操作。\n3、响应速度和性能的权衡 在上代码中，每次尝试获取两个锁失败，都会调用 TimeUnit.SECONDS.sleep(1); 让线程休眠一秒后，再去尝试获得两个资源锁。这里涉及到一个性能和响应时间的问题：\n如果每次尝试后都让线程休眠，可能会造成响应迟延的问题。比如，在这次失败进入休眠的瞬间，两个锁的状态刚好变为可用，但线程必须要休眠完成后才能再次尝试。但是，休眠的同时可以不占用CPU时钟周期，可以让其他线程有时间来占用CPU。 如果不休眠，让线程在一次获取锁失败后立即进行下一轮获取尝试，可以获得很好的响应速度，但是这也会让线程长时间占用CPU时钟周期直到成功获得两个锁。如果该锁在很长时间后才都可用，这会造成CPU资源浪费，服务器性能降低。 因此，需要在响应速度和服务器性能之间做出权衡。\n4、可中断的锁获取操作 Lock中的lockInterruptibly() 可以在获得锁的同时保持对中断的响应，但是内置锁synchronized却很难实现这个功能。\n如下程序，创建一任务，假设该任务需要执行很长时间才能结束（使用死循环来模拟时长）。现在有两个线程竞争该资源的内置锁，在等待一段时间后，想要终止线程t2的锁获取等待操作，使用t2.interrupt(); 尝试中断线程t2。遗憾的是，此时t2根本不会响应这个中断操作，它会继续等待直到获得资源锁。\npublic class InterruptedLockTest implements Runnable{ public synchronized void doCount(){ //使用死循环表示此操作要进行很长的一段时间才能结束 while(true){} } @Override public void run() { doCount(); } } public static void main(String[] args) throws InterruptedException { InterruptedLockTest test = new InterruptedLockTest(); Thread t1 = new Thread(test); Thread t2 = new Thread(test); t1.start(); t2.start(); //等待两秒，尝试中断线程t2的等待 TimeUnit.SECONDS.sleep(2); t2.interrupt(); //等待1秒，让 t2.interrupt(); 执行生效 TimeUnit.SECONDS.sleep(1); System.out.println(\u0026#34;线程t1是否存活：\u0026#34; \u0026#43; t1.isAlive()); System.out.println(\u0026#34;线程t2是否存活：\u0026#34; \u0026#43; t2.isAlive()); } 使用Lock的lockInterruptibly() 能够在获取锁请求的同时能保持对中断的响应。\npublic class InterruptedLockTest2 implements Runnable{ Lock lock = new ReentrantLock(); public void doCount() throws InterruptedException { //可中断的锁等待机制，会抛出中断异常 lock.lockInterruptibly(); try { while (true) {} }finally { lock.unlock(); } } @Override public void run() { try { doCount(); } catch (InterruptedException e) { System.out.println(\u0026#34;被中断....\u0026#34;); } } } public static void main(String[] args) throws InterruptedException { InterruptedLockTest2 test = new InterruptedLockTest2(); Thread t1 = new Thread(test); Thread t2 = new Thread(test); t1.start(); t2.start(); TimeUnit.SECONDS.sleep(2); t2.interrupt(); //等待1秒，让 t2.interrupt(); 执行生效 TimeUnit.SECONDS.sleep(1); System.out.println(\u0026#34;线程t1是否存活：\u0026#34; \u0026#43; t1.isAlive()); System.out.println(\u0026#34;线程t2是否存活：\u0026#34; \u0026#43; t2.isAlive()); } 5、公平性 ReentranLock 提供了两种公平性的悬着：创建一个非公平锁（默认）或者创建一个非公平锁。在公平锁中，线程将按照他们发出请求的顺序来获得锁，非公平锁上则允许“插队”；如果一个线程在请求非公平锁时，如果此时该状态刚好变为可用，则该线程可能会直接获得该锁。\n// 也可以指定公平性 public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync(); } //默认创建非公平锁 public ReentrantLock() { sync = new NonfairSync(); } 在公平性的ReentranLock中，如果有一个线程在持有这个锁或是有线程在阻塞队列中等待这个锁，那么新请求的线程会被放入队列中等待。非公平性锁中，只当锁被某个线程占领时，才会把新请求的线程放入阻塞队列中。\n在竞争激烈的环境中，公平性锁的性能会比非公平性锁差很多。如果没有特殊的需求，不推荐使用公平锁，因为在公平锁中，恢复一个被挂起的线程与该线程真正开始执行之间存在严重的迟延。假如线程A持有一个锁，线程B请求这个锁，由于这个锁已经被持有，所以B会放入阻塞对类中。如果A释放该锁，B将被唤醒，一次会尝试再次请求该锁。与此同时，如果线程C也请求该锁，那么C很可能在B被完全唤醒之前持有、使用和释放该锁。这样，B既没有延迟使用该锁，C还利用其中间隙完成自己的操作，这是一个双赢的局面。\n6、如何选择synchronized和ReentranLock 在Java6中，ReentranLock性能略有胜出synchronized。但是，使用ReentranLock需要在finally语句中手动释放锁，可能会造成一定的编码失误。并且，synchronized使用JVM的内置属性，可提升优化的空间较大。\n因此，只有在内置锁无法满足需求的情况下，比如，需要使用：可定时的、可轮询的和可中断的锁获取机制，公平队列。才会考虑使用ReentranLock。否则，优先使用synchronized内置锁。\n","date":"2017-11-18T14:09:22+08:00","permalink":"https://luky116.github.io/post/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%AD%A6%E4%B9%A0%E4%B9%8Block%E4%B8%8Ereentranlock%E8%AF%A6%E8%A7%A3/","tags":["ReenTranLock","源码"],"title":"Java多线程学习之Lock与ReentranLock详解"},{"categories":["Java多线程","Java源码"],"contents":"0、使用线程池的必要性 在生产环境中，如果为每个任务分配一个线程，会造成许多问题：\n**线程生命周期的开销非常高。**线程的创建和销毁都要付出代价。比如，线程的创建需要时间，延迟处理请求。如果请求的到达率非常高并且请求的处理过程都是轻量级的，那么为每个请求创建线程会消耗大量计算机资源。 资源消耗。 活跃的线程会消耗系统资源，尤其是内存。如果可运行的线程数量多于处理器数量，那么有些线程会闲置。闲置的线程会占用内存，给垃圾回收器带来压力，大量线程在竞争CPU时，还会产生其他的性能开销。 稳定性。 如果线程数量过大，可能会造成OutOfMemory异常。 1、 Java中的ThreadPoolExecutor类 java.uitl.concurrent.ThreadPoolExecutor类是线程池中最核心的类，因此如果要深入理解Java中的线程池，必须深入理解这个类。我们来看一下ThreadPoolExecutor类的源码。ThreadPoolExecutor类中提供了四个构造方法：\npublic ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); } public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, ThreadFactory threadFactory) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, defaultHandler); } public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, RejectedExecutionHandler handler) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), handler); } public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { if (corePoolSize \u0026lt; 0 || maximumPoolSize \u0026lt;= 0 || maximumPoolSize \u0026lt; corePoolSize || keepAliveTime \u0026lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; } 参数介绍：\ncorePoolSize：核心池大小。在创建线程池后，默认情况下，线程池中没有任何线程，而是等待任务到来材创建线程去执行任务。也可以提前调用prestartAllCoreT hreads()或者prestartCoreThread()方法提前创建corePoolSize个线程或是一个线程。默认情况下，线程池在创建后线程数量为0，当有任务提交时，会创建线程，当线程达到corePoolSize个后，新提交的的任务会放到缓存队列中存放。 maximumPoolSize：线程池的最大线程数量，表示在线程池中最多可以创建多少个线程。当缓存队列已满时候，新提交的任务会创建新的线程执行，直到线程池中达到maximumPoolSize个线程。 keepAliveTime：表示线程没有任务执行时最多存活时间。默认情况下，只有当线程池的线程数量大于corePoolSize个时才会生效，就是说多余corePoolSize个的其他线程存活时间会受限，也可以调用allowCoreThreadTimeOut(true)方法设置线程池中所有的线程存活时间限制。 unit：存活时间的单位，有如下单位： TimeUnit.DAYS; //天 TimeUnit.HOURS; //小时 TimeUnit.MINUTES; //分钟 TimeUnit.SECONDS; //秒 TimeUnit.MILLISECONDS; //毫秒 TimeUnit.MICROSECONDS; //微妙 TimeUnit.NANOSECONDS; //纳秒 workQueue：阻塞队列，用于暂时存放任务，有如下几种： ArrayBlockingQueue; LinkedBlockingQueue; SynchronousQueue; threadFactory：线程工厂，指定创建线程的策略。 handler：当任务无法被及时处理和存放时候，进行处理的策略。比如说，线程池已满并且阻塞队列已满，新提交的任务需要被进行其他处理。有如下的处理方案： “终止(Abort)” 策略\nThreadPoolExecutor.AbortPolicy ：默认的饱和策略，该策略抛出未检查的RejectedExecutionException 异常，调用者需要处理此异常。 ThreadPoolExecutor.DiscardPolicy ：也是丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃下一个即将被执行的任务，然后尝试重新提交此任务。如果工作队列设一个优先队列，那么将会抛弃(Discard) 优先级最高的任务，显然，这是很不合理的。 **“调用者运行(Caller-Runs)”**策略\nThreadPoolExecutor.CallerRunsPolicy ：该策略既不会抛弃任务，也不会抛出异常，而是将任务回退到调用者，有调用者线程来执行此线程。由于调用者线程执行该任务需要一定的时间，所以在该期间内，调用者线程无法接受其他的任务，为线程池中的线程争取执行时间。在WEB 服务器中，此期间到达的请求会被保存在TCP层的队列中而不是在应用程序的队列中。如果持续过载，TCP层队列被堆满，他会开始抛弃请求。这样，如果服务器过载，压力会向外蔓延：从线程池的消息队列到应用程序再到TCP层，最终到达客户端，导致服务器在高负载情况下性能的缓慢降低。 2、线程池的状态 在ThreadPoolExecutor 中定义了一组变量，表示线程池的状态：\n// 29 private static final int COUNT_BITS = Integer.SIZE - 3; // 由28个1二进制组成的数字 private static final int CAPACITY = (1 \u0026lt;\u0026lt; COUNT_BITS) - 1; // runState is stored in the high-order bits private static final int RUNNING = -1 \u0026lt;\u0026lt; COUNT_BITS; private static final int SHUTDOWN = 0 \u0026lt;\u0026lt; COUNT_BITS; private static final int STOP = 1 \u0026lt;\u0026lt; COUNT_BITS; private static final int TIDYING = 2 \u0026lt;\u0026lt; COUNT_BITS; private static final int TERMINATED = 3 \u0026lt;\u0026lt; COUNT_BITS; // Packing and unpacking ctl private static int runStateOf(int c) { return c \u0026amp; ~CAPACITY; } 当线程池被创建后，线程池处于 RUNNING 状态； 如果调用了shutdown()方法，则线程池处于SHUTDOWN状态，此时线程池不能够接受新的任务，它会等待所有任务执行完毕； 如果调用了shutdownNow()方法，则线程池处于STOP状态，此时线程池不能接受新的任务，并且会去尝试终止正在执行的任务； 当线程池处于SHUTDOWN或STOP状态，并且所有工作线程已经销毁，任务缓存队列已经清空或执行结束后，线程池被设置为TERMINATED状态。 3、任务缓存之阻塞队列 如果新请求的到达速率超过了线程池的处理速率，则新到达的请求会暂存在线程池管理的Runnable等待队列workQueue中，工作队列为BlockingQueue 类型的阻塞队列。\n阻塞队列的操作可分为如下：\n抛异常响应 特值响应 阻塞响应 超时响应 插入 add(o) offer(o) put(o) offer(o,timeout,timeunit) 移除 remove(o) poll(o) take(o) poll(timeout,timeunit) 检查 element(o) peek(o) 抛异常响应：如果该操作不能立即满足，则抛出异常。 特值响应：如果该操作不能立即执行，则返回一个特值，如 false或null响应。 阻塞响应：如果该操作不能立即执行，则会阻塞等待直到满足执行条件。 超时响应：如果该操作不能立即执行，则等待一定时间，在该时间内满足条件则执行，否则返回一个特值相应是否执行成功。 BlockingQueue 的实现类：\nArrayBlockingQueue ：是一个有界队列，内部存储结构是数组。在开始使用时需要指定队列大小，且在使用过程中不能对大小进行修改。 LinkedBlockingQueue ：内部使用链表作为存储结构，可以指定大小作为有界队列，如果没指定大小，则默认为 Integer.MAX_VALUE 大小的“无界”队列。 PriorityBlockingQueue ：是一个无界的并发队列，对队列中的元素按照一定的规则进行排序，在线程池中按照线程的优先级进行排序。 SynchronousQueue ：其实不是一个真正的队列，而是一种在线程之间进行移交的机制。要将一个元素放入synchronousQueue 队列中，必须有另一个线程正在等待接受这个元素。如果没有线程等待，并且线程池当前大小小于线程池的最大值，那么ThreadPoolExecutror将创建一个新线程来执行此任务。 DelayQueue ：对元素进行持有直到一个特定的延迟到期。注入其中的元素必须实现 java.util.concurrent.Delayed 接口。 阻塞同步的方式：\n阻塞队列实现阻塞同步的方式很简单，使用了ReentranLock 的多条件进行阻塞控制，如ArrayBlockingQueue 源码中：\n// 构造函数 public ArrayBlockingQueue(int capacity, boolean fair) { if (capacity \u0026lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; lock = new ReentrantLock(fair); // 空条件、满条件 notEmpty = lock.newCondition(); notFull = lock.newCondition(); } //插入函数 public void put(E e) throws InterruptedException { checkNotNull(e); final ReentrantLock lock = this.lock; // 可中断的锁 lock.lockInterruptibly(); try { while (count == items.length) notFull.await(); enqueue(e); } finally { // 解锁 lock.unlock(); } } 阻塞队列的选择策略：\n只有当任务相互独立时，为线程池或工作队列设置界线才是合理的。如果任务之间存在依赖性，那么有界的线程池或队列可能会导致“饥饿”死锁问题。可以选择newCachedThreadPool。\n4、四大线程池详解 Java类库提供了灵活的线程池及一些配置，可以通过Executors 中的静态工厂方法进行创建：\n1.newFixedThreadPool\n简介 newFixedThreadPool将创建一个固定长度的线程池，每当提交一个任务，创建一个线程，直到达到线程池的最大数量，这时线程池的规模不再变化，如果某个线程中途应为Exception 异常结束，线程池会再补一个线程加入线程池。\n源码分析 public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;()); } public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory){ return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;(), threadFactory); } 可以看到，newFixedThreadPool 的 核心池大小和线程池最大大小一致，就是说，该线程池大小在接受任务时，就逐步创建线程到最大值。\n线程的存活时间设置为为0毫秒，说明核心池的线程池不会超时而终止，所以核心池的线程数量一旦创建，除非异常终止，不会因为超时等问题而自动停止。看allowCoreThreadTimeOut(boolean) 源码：\npublic void allowCoreThreadTimeOut(boolean value) { // 如果keepAliveTime 为0或小于0，则不能设置核心池自动死亡 if (value \u0026amp;\u0026amp; keepAliveTime \u0026lt;= 0) throw new IllegalArgumentException(\u0026#34;Core threads must have nonzero keep alive times\u0026#34;); if (value != allowCoreThreadTimeOut) { allowCoreThreadTimeOut = value; if (value) interruptIdleWorkers(); } } 分析 使用了无界的LinkedBlockingQueue 阻塞队列，如果任务请求速度大于线程处理速度，可能会导致阻塞队列中堆积了大量待处理的任务，占用大量内存，导致性能下降或是奔溃。\n2. newCachedThreadPool\n简介 newCachedThreadPool 将创建一个可缓存的线程池，如果线程池的当前规模超过了处理需求时，将回收空闲线程，而当需求增加时，则可以添加新的线程，线程池的规模没有限制。\n源码分析 public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue\u0026lt;Runnable\u0026gt;()); } public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue\u0026lt;Runnable\u0026gt;(), threadFactory); } 核心池大小设置为0，线程池的最大大小设置为“无穷大”，说明该线程池没有处于核心池的线程，即，所有线程池的所有线程都是会超时死亡的。线程空闲存活时间为60秒，意味着如果线程空闲60秒就会被杀死。阻塞队列使用了SynchronousQueue队列 ，提交的任务不会暂存到队列中，而是又改队移交到线程直接执行。\n分析 它提供比固定大小的线程池更好的排队性能、如果任务请求过于频繁，导致任务提交速度大于线程请求速度，可能会使应用程序创建大量的线程导致性能下降甚至奔溃。所以，如果限制当前任务的数量足以满足资源管理的需求，优先选择有界队列。\n3. newSingleThreadExecutor\n简介 newSingleThreadExecutor 是一个单线程的 Executor，它创建单个工作者线程来执行任务，如果该线程异常结束，将创建一个新的线程来代替它。newSingleThreadExecutor 能确保任务依照队列中的顺序来串行执行（例如，FIFO，LIFO，优先级等）。\n源码分析 public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;())); } public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory){ return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;(), threadFactory)); } 核心池和线程池最大大小皆为1，说明该线程池只能容纳一个线程，0毫秒的存活时间，说明该线程不会自动死亡。使用无边界的LinkedBlockingQueue阻塞队列，无法及时处理的任务可能会无限制的堆积在该阻塞队列中，可能造成内存泄漏。\n4. newScheduledThreadPool\n简介 newScheduledThreadPool 创建一个固定长度的线程池，而且以延迟或定时的方式来执行任务，类似Timmer。\n源码分析 public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) { return new ScheduledThreadPoolExecutor(corePoolSize); } public static ScheduledExecutorService newScheduledThreadPool( int corePoolSize, ThreadFactory threadFactory) { return new ScheduledThreadPoolExecutor(corePoolSize, threadFactory); } // 使用了 DelayedWorkQueue 阻塞队列 public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory) { super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory); } 可以看到 newScheduledThreadPool 返回了一个 ScheduledExecutorService 对象，和之前三个返回的 ExecutorService 不一样。使用了DelayedWorkQueue作为阻塞队列，定时执行。ScheduledThreadPoolExecutor 方法：\n// 延迟执行，只会执行一次 public ScheduledFuture\u0026lt;?\u0026gt; schedule(Runnable command, long delay, TimeUnit unit); // 延期定时执行，重复执行多次 public ScheduledFuture\u0026lt;?\u0026gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit); ","date":"2017-11-14T14:09:22+08:00","permalink":"https://luky116.github.io/post/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3/","tags":["Java线程池","源码"],"title":"Java多线程学习之线程池源码详解"},{"categories":["MyBatis"],"contents":"1、一级缓存 MyBatis **默认开启了一级缓存**，一级缓存是在SqlSession 层面进行缓存的。即，同一个SqlSession ，多次调用同一个Mapper和同一个方法的同一个参数，只会进行一次数据库查询，然后把数据缓存到缓冲中，以后直接先从缓存中取出数据，不会直接去查数据库。 但是不同的SqlSession对象，因为不用的SqlSession都是相互隔离的，所以相同的Mapper、参数和方法，他还是会再次发送到SQL到数据库去执行，返回结果。 public static void main(String[] args) { // 自定义的单例SqlSessionFactory模式 SqlSessionFactory factory = SqlSessionFactoryUtil.openSqlSession(); // 获得SqlSession对象 SqlSession sqlSession = factory.openSession(); // 获得dao实体 UserMapper userMapper = sqlSession.getMapper(UserMapper.class); // 进行两次相同的查询操作 userMapper.selectByPrimaryKey(1); userMapper.selectByPrimaryKey(1); // 注意，当我们使用二级缓存时候，sqlSession需要使用commit时候才会生效 sqlSession.commit(); System.out.println(\u0026#34;\\n\\n=============================================================\u0026#34;); // 获得一个新的SqlSession 对象 SqlSession sqlSession1 = factory.openSession(); // 进行相同的查询操作 sqlSession1.getMapper(UserMapper.class).selectByPrimaryKey(1); // 注意，当我们使用二级缓存时候，sqlSession需要使用commit时候才会生效 sqlSession.commit(); } 日志输出\nDEBUG [main] - ooo Using Connection [com.mysql.jdbc.JDBC4Connection@77caeb3e] DEBUG [main] - ==\u0026gt; Preparing: select user_ID, login_name,user_name, user_code, user_type, user_active, organization_ID,user_position,password from user where user_ID = ? DEBUG [main] - ==\u0026gt; Parameters: 1(Integer) TRACE [main] - \u0026lt;== Columns: user_ID, login_name, user_name, user_code, user_type, user_active, organization_ID, user_position, password TRACE [main] - \u0026lt;== Row: 1, ASH-001, 小明, JIKF-001, ADMIN, 1, 0, 销售员, 1212121212121 DEBUG [main] - \u0026lt;== Total: 1 ============================================================= DEBUG [main] - ooo Using Connection [com.mysql.jdbc.JDBC4Connection@553f17c] DEBUG [main] - ==\u0026gt; Preparing: select user_ID, login_name,user_name, user_code, user_type, user_active, organization_ID,user_position,password from user where user_ID = ? DEBUG [main] - ==\u0026gt; Parameters: 1(Integer) TRACE [main] - \u0026lt;== Columns: user_ID, login_name, user_name, user_code, user_type, user_active, organization_ID, user_position, password TRACE [main] - \u0026lt;== Row: 1, ASH-001, 小明, JIKF-001, ADMIN, 1, 0, 销售员, 1212121212121 DEBUG [main] - \u0026lt;== Total: 1 可以发现，第一次的两个相同操作，只执行了一次数据库。后来的那个操作又进行了数据库查询。 2、二级缓存 为了克服这个问题，需要开启二级缓存，是的缓存zaiSqlSessionFactory层面给各个SqlSession 对象共享。默认二级缓存是不开启的，需要手动进行配置。 \u0026lt;cache/\u0026gt; 如果这样配置的话，很多其他的配置就会被默认进行，如： 映射文件所有的select 语句会被缓存 映射文件的所有的insert、update和delete语句会刷新缓存 缓存会使用默认的Least Recently Used（LRU，最近最少使用原则）的算法来回收缓存空间 根据时间表，比如No Flush Interval，（CNFI，没有刷新间隔），缓存不会以任何时间顺序来刷新 缓存会存储列表集合或对象（无论查询方法返回什么）的1024个引用 缓存会被视为是read/write（可读/可写）的缓存，意味着对象检索不是共享的，而且可以很安全的被调用者修改，不干扰其他调用者或县城所作的潜在修改 添加后日志打印如下，可以发现所有过程只使用了一次数据库查询\nEBUG [main] - ooo Using Connection [com.mysql.jdbc.JDBC4Connection@5622fdf] DEBUG [main] - ==\u0026gt; Preparing: select user_ID, login_name,user_name, user_code, user_type, user_active, organization_ID,user_position,password from user where user_ID = ? DEBUG [main] - ==\u0026gt; Parameters: 1(Integer) TRACE [main] - \u0026lt;== Columns: user_ID, login_name, user_name, user_code, user_type, user_active, organization_ID, user_position, password TRACE [main] - \u0026lt;== Row: 1, AS-01, 小明, HJ-009, ADMIN, 1, 0, 销售员, dasfasdfasdfsdf DEBUG [main] - \u0026lt;== Total: 1 ============================================================= 可以在开启二级缓存时候，手动配置一些属性\n\u0026lt;cache eviction=\u0026#34;LRU\u0026#34; flushInterval=\u0026#34;100000\u0026#34; size=\u0026#34;1024\u0026#34; readOnly=\u0026#34;true\u0026#34;/\u0026gt; 各个属性意义如下：\neviction：缓存回收策略 - LRU：最少使用原则，移除最长时间不使用的对象 - FIFO：先进先出原则，按照对象进入缓存顺序进行回收 - SOFT：软引用，移除基于垃圾回收器状态和软引用规则的对象 - WEAK：弱引用，更积极的移除移除基于垃圾回收器状态和弱引用规则的对象 flushInterval：刷新时间间隔，单位为毫秒，这里配置的100毫秒。如果不配置，那么只有在进行数据库修改操作才会被动刷新缓存区 size：引用额数目，代表缓存最多可以存储的对象个数 readOnly：是否只读，如果为true，则所有相同的sql语句返回的是同一个对象（有助于提高性能，但并发操作同一条数据时，可能不安全），如果设置为false，则相同的sql，后面访问的是cache的clone副本。 可以在Mapper的具体方法下设置对二级缓存的访问意愿：\nuseCache配置\n如果一条语句每次都需要最新的数据，就意味着每次都需要从数据库中查询数据，可以把这个属性设置为false，如：\n\u0026lt;select id=\u0026#34;selectAll\u0026#34; resultMap=\u0026#34;BaseResultMap\u0026#34; useCache=\u0026#34;false\u0026#34;\u0026gt; 刷新缓存（就是清空缓存）\n二级缓存默认会在insert、update、delete操作后刷新缓存，可以手动配置不更新缓存，如下：\n\u0026lt;update id=\u0026#34;updateById\u0026#34; parameterType=\u0026#34;User\u0026#34; flushCache=\u0026#34;false\u0026#34; /\u0026gt; 3、自定义缓存 自定义缓存对象，该对象必须实现 org.apache.ibatis.cache.Cache 接口，如下： import org.apache.ibatis.cache.Cache; import java.util.concurrent.ConcurrentHashMap; import java.util.concurrent.locks.ReadWriteLock; import java.util.concurrent.locks.ReentrantReadWriteLock; /** * Created by Luky on 2017/10/14. */ public class BatisCache implements Cache { private ReadWriteLock lock = new ReentrantReadWriteLock(); private ConcurrentHashMap\u0026lt;Object,Object\u0026gt; cache = new ConcurrentHashMap\u0026lt;Object, Object\u0026gt;(); private String id; public BatisCache(){ System.out.println(\u0026#34;初始化-1！\u0026#34;); } //必须有该构造函数 public BatisCache(String id){ System.out.println(\u0026#34;初始化-2！\u0026#34;); this.id = id; } // 获取缓存编号 public String getId() { System.out.println(\u0026#34;得到ID：\u0026#34; \u0026#43; id); return id; } //获取缓存对象的大小 public int getSize() { System.out.println(\u0026#34;获取缓存大小！\u0026#34;); return 0; } // 保存key值缓存对象 public void putObject(Object key, Object value) { System.out.println(\u0026#34;往缓存中添加元素：key=\u0026#34; \u0026#43; key\u0026#43;\u0026#34;,value=\u0026#34; \u0026#43; value); cache.put(key,value); } //通过KEY public Object getObject(Object key) { System.out.println(\u0026#34;通过kEY获取值：\u0026#34; \u0026#43; key); System.out.println(\u0026#34;OVER\u0026#34;); System.out.println(\u0026#34;=======================================================\u0026#34;); System.out.println(\u0026#34;值为：\u0026#34; \u0026#43; cache.get(key)); System.out.println(\u0026#34;=====================OVER==============================\u0026#34;); return cache.get(key); } // 通过key删除缓存对象 public Object removeObject(Object key) { System.out.println(\u0026#34;移除缓存对象：\u0026#34; \u0026#43; key); return null; } // 清空缓存 public void clear() { System.out.println(\u0026#34;清除缓存！\u0026#34;); cache.clear(); } // 获取缓存的读写锁 public ReadWriteLock getReadWriteLock() { System.out.println(\u0026#34;获取锁对象！！！\u0026#34;); return lock; } } 在Mapper文件里配置使用该自定义的缓存对象，如： \u0026lt;cache type=\u0026#34;com.sanyue.utils.BatisCache\u0026#34;/\u0026gt; 测试如下： public static void main(String[] args) { SqlSessionFactory factory = SqlSessionFactoryUtil.openSqlSession(); // 获得SqlSession对象 SqlSession sqlSession = factory.openSession(); // 获得dao实体 UserMapper userMapper = sqlSession.getMapper(UserMapper.class); // 进行两次相同的查询操作 userMapper.selectByPrimaryKey(1); userMapper.selectByPrimaryKey(1); // 注意，当我们使用二级缓存时候，sqlSession需要使用commit时候才会生效 sqlSession.commit(); System.out.println(\u0026#34;\\n\\n=============================================================\u0026#34;); // 获得一个新的SqlSession 对象 SqlSession sqlSession1 = factory.openSession(); // 进行相同的查询操作 sqlSession1.getMapper(UserMapper.class).selectByPrimaryKey(1); sqlSession1.commit(); } 日志输出如下： 初始化-2！ 得到ID：com.sanyue.dao.UserMapper 获取锁对象！！！ 通过kEY获取值：151355725:1423317450:com.sanyue.dao.UserMapper.selectByPrimaryKey:0:2147483647: select user_ID, login_name,user_name, user_code, user_type, user_active, organization_ID,user_position,password from user where user_ID = ? :1 OVER ======================================================= 值为：null =====================OVER============================== 获取锁对象！！！ 获取锁对象！！！ 通过kEY获取值：151355725:1423317450:com.sanyue.dao.UserMapper.selectByPrimaryKey:0:2147483647: select user_ID, login_name,user_name, user_code, user_type, user_active, organization_ID,user_position,password from user where user_ID = ? :1 OVER ======================================================= 值为：null =====================OVER============================== 获取锁对象！！！ 获取锁对象！！！ 往缓存中添加元素：key=151355725:1423317450:com.sanyue.dao.UserMapper.selectByPrimaryKey:0:2147483647: select user_ID, login_name,user_name, user_code, user_type, user_active, organization_ID,user_position,password from user where user_ID = ? :1,value=[User{userId=1, loginName=\u0026#39;AS-01\u0026#39;, password=\u0026#39;12121212121\u0026#39;, userName=\u0026#39;小明\u0026#39;, userCode=\u0026#39;JSD-009\u0026#39;, userType=\u0026#39;ADMIN\u0026#39;, userActive=true, userPosition=\u0026#39;销售员\u0026#39;}] 获取锁对象！！！ ============================================================= 获取锁对象！！！ 通过kEY获取值：151355725:1423317450:com.sanyue.dao.UserMapper.selectByPrimaryKey:0:2147483647: select user_ID, login_name,user_name, user_code, user_type, user_active, organization_ID,user_position,password from user where user_ID = ? :1 OVER ======================================================= 值为：[User{userId=1, loginName=\u0026#39;AS-01\u0026#39;, password=\u0026#39;12121212121\u0026#39;, userName=\u0026#39;小明\u0026#39;, userCode=\u0026#39;JSD-009\u0026#39;, userType=\u0026#39;ADMIN\u0026#39;, userActive=true, userPosition=\u0026#39;销售员\u0026#39;}] =====================OVER============================== 获取锁对象！！！ 可以看出，每次查询数据库前，MyBatis都会先在缓存中查找是否有该缓存对象。只有当调用了commit() 方法，MyBatis才会往缓存中写入数据，数据记录的键为 `数字编号+Mapper名+方法名+SQL语句+参数` 格式，值为返回的对象值。 ","date":"2017-10-18T14:29:03+08:00","permalink":"https://luky116.github.io/post/mybatis%E4%B8%80%E4%BA%8C%E7%BA%A7%E7%BC%93%E5%AD%98%E5%92%8C%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BC%93%E5%AD%98/","tags":["MyBatis缓存"],"title":"MyBatis一、二级缓存和自定义缓存"},{"categories":["Spring"],"contents":"1、处理自动装配的歧义性 1.1 标记首选的bean 使用@Primary 来说明一个bean是首选的。 @Component @Primary public class GuoRongCD implements CompactDisc {} 或是\n@Bean @Primary public MediaPlayer getAnotherCDplay(CompactDisc aa){ CDPlayer k = new CDPlayer(); k.setCompactDisc(aa); return k; } 或是\n\u0026lt;bean id=\u0026#34;glCD\u0026#34; class=\u0026#34;com.di.book.GuoRongCD\u0026#34; primary=\u0026#34;true\u0026#34;/\u0026gt; 但是，一个类型的bean只能有一个首选标志，如果多个，就失去意义了。 1.2 限定自动装配的bean 如果被注入的bean类型不是唯一的，需要设置限定符，来确定哪个bean是被需要的。@Qualifier注解是使用限定符的主要方式。 @Autowired @Qualifier(\u0026#34;guoRongCD\u0026#34;) public void setCompactDisc(CompactDisc compactDisc) { this.compactDisc = compactDisc; } @Qualifier 设置的参数就是想要注入的bean的ID。所有使用@Component 注解声明的bean，默认的ID是首字母变小写的类名。 更精确的说，@Qualifier(\u0026quot;guoRongCD\u0026quot;) 所要引用的bean是具有String类型的“guoRongCD”作为限定符。如果没有指定限定符，bea一般会有一个默认的限定符，这个限定符和bean 的ID相同。 给bean指定限定符 @Component @Qualifier(\u0026#34;kkd\u0026#34;) public class GuoRongCD implements CompactDisc {} 或是\n@Bean @Qualifier(\u0026#34;kkd\u0026#34;) public CompactDisc getCompactDisc(){ return new GuoRongCD(); } 2、作用域 。。。。。。\n3、运行时值注入 为了避免硬编码，可以是程序在运行时候再给属性复制。有如下两种方式： 属性占位符 Spring 表达式语言 3.1 注入外部值 @Configuration @PropertySource(\u0026#34;classpath:test.properties\u0026#34;)//引入配置文件 public class ExpressiveConfig { @Autowired Environment env;//自动检索属性 @Bean public BlankDisk disc(){ return new BlankDisk( //寻找键值，进行注入 env.getProperty(\u0026#34;disc.title\u0026#34;), env.getProperty(\u0026#34;disc.artist\u0026#34;)); } } test.properties\ndisc.title = vae disc.artist = vae Son 3.2 深入研究 关于getProperty()的重载形式：\n//只有key String getProperty(String key) //含有默认值，如果找不到改善属性值，就会适应默认值 String getProperty(String key, String defaultValue) //可以类型转换，比如字符串转整型， //getProperty(\u0026#34;port\u0026#34;, Integer.class) \u0026lt;T\u0026gt; T getProperty(String key, Class\u0026lt;T\u0026gt; targetType); //带有默认值 \u0026lt;T\u0026gt; T getProperty(String key, Class\u0026lt;T\u0026gt; targetType, T defaultValue); 当使用getProperty()时候，如果是空值，结果适null，不会包异常。如果希望该结果不存在的时候抛异常，就可以使用 getRequiredProperty() 方法，所有使用方法和前者一致，若是值不存在，会抛出异常。 3.3 属性占位符 XML中，可以使用“${}”来占位。 \u0026lt;bean id=\u0026#34;dataSource\u0026#34; class=\u0026#34;org.springframework.jdbc.datasource.DriverManagerDataSource\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;${mysql.url}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;${mysql.username}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;driverClassName\u0026#34; value=\u0026#34;${mysql.driverClassName}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;${mysql.password}\u0026#34;/\u0026gt;\t\u0026lt;/bean\u0026gt; 在JavaConfig中，使用@Value来占位 @Bean public BlankDisk disc(@Value(\u0026#34;${disc.title}\u0026#34;)String title, @Value(\u0026#34;${disc.artist}\u0026#34;)String artist)\t{ return new BlankDisk(title,artist); } 但是，为了使用占位符，需要含有PropertySourcesPlaceholderConfigurer 类型的bean：\n@Bean public static PropertySourcesPlaceholderConfigurer placeholderConfigurer(){ return new PropertySourcesPlaceholderConfigurer(); } 在XML中，需要使用命名空间\n\u0026lt;context:property-placeholder/\u0026gt; 这个命名空间会给你自动创建这个bean。\n","date":"2017-10-11T14:29:03+08:00","permalink":"https://luky116.github.io/post/spring%E9%AB%98%E7%BA%A7%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5%E6%96%B9%E5%BC%8F/","tags":["依赖注入"],"title":"Spring高级依赖注入方式"},{"categories":["Spring"],"contents":"1、依赖注入（DI） 的重要性 如果直接在代码里面实例化一个对象，会使代码的耦合度大，使代码难以测试，难以复用，难以理解。通过DI，对象的依赖关系将由系统中负责协调各对象的第三方组件在创建对象的时候进行设定。 在DI中，面接口编程，而不是面向实例对象编程。所以，只要是实现了该接口的对象，都可以被传进来，进行注入，使代码的耦合性降低。 2、装配 创建应用组件之间的协作关系的行为通常称为装配（wiring）。\n3、装配方式 在XML中显示的进行\n在Java中进行显示的配置（JavaConfig）\n隐式的bean发现机制和自动装配\n建议尽可能使用自动配置的机制来装配bean，显示的配置越少越好。尽量使用第二 中转配方式。\n4、自动化装配bean Spring从两方面实现自动化装配。 组件扫描（component scanning）：Spring会自动发现应用上下文中所创建的bean。 自动装配（autowiring）：Spring自动满足bean之间的依赖。 4.1 创建可被发现的bean @Component：为该类创建bean\n@Named：bean注解，和上一样，但是不常用\n@CompontScan ：在Java中启动扫描，默认会扫描与配置类相同的包\n在xml文件中 此注解，启动组件扫描\n\u0026lt;context:component-scan base-package=\u0026#34;com.di\u0026#34;/\u0026gt; applicationContext.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34;\txmlns:context=\u0026#34;http://www.springframework.org/schema/context\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\u0026#34;\u0026gt; \u0026lt;context:component-scan base-package=\u0026#34;com.di\u0026#34; /\u0026gt; \u0026lt;/beans\u0026gt; 注解：\nxmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34;\t//一定要存在 xmlns:context=\u0026#34;http://www.springframework.org/schema/context\u0026#34;\t//启动扫描注解一定需要的 4.2 通过SpringTest单元测试 @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(classes=Car.class) public class RunBySpringTest { @Autowired private Car car; @Test public void test_2(){ car.show(); } } 添加JUnit 4.11版本的包，还有spring-test 依赖包。 JUnit 最好用这个版本的依赖包，其他的版本不能保证不出问题。 SpringJUnit4ClassRunner：可以在测试开始的时候创建Spring的应用上下文。 @ContextConfiguration 告诉它在Car中加载配置，由于Car中使用了@Component注解。 4.3 设置组件扫描基础包 - @Component 当我们没有为@Component 设置任何属性时候，他会以配置类所在的基础包（base package）来扫描组件。如果我们想要扫描其他的包，有如下用法： 扫描一个包 @Configurable @ComponentScan(\u0026#34;com.di\u0026#34;) public class ClassCongfig {} 扫描多个包 @Configurable @ComponentScan(basePackages={\u0026#34;com.di\u0026#34;,\u0026#34;com.sanyue\u0026#34;}) public class ClassCongfig {} 扫描该类所在的包，将会扫描该类所在的包，所以可以在包中设置特定的空标记接口 @Configurable @ComponentScan(basePackageClasses={Car.class,Cat.class}) public class ClassCongfig {} 4.4 通过为bean添加注解实现自动装配 当一个bean要依赖另一个bean才能正常工作时候，就需要将bean和他们的依赖装配在一起。常用依赖注入注解如下： @Autowired\n用于构造器上 @Component public class CDPlayer implements MediaPlayer { private CompactDisc compactDisc; @Autowired public CDPlayer(CompactDisc compactDisc){ this.compactDisc = compactDisc; } @Override public void play() { // TODO Auto-generated method stub compactDisc.play(); } } 用与Setter() @Autowired public void setCompactDisc(CompactDisc compactDisc) { this.compactDisc = compactDisc; } 好吧，其实Setter方法并无特别之处，@Autowired 可以用于任何方法之上，用于依赖注入。 如果有多个bean满足依赖关系的话，Spring将会抛出异常。 这是Spring特有的注解。比如，Java依赖注入规范为我们提供了@Inject注解，可以和@Autowired交替使用。 5、通过Java代码装配bean 5.1 创建配置类 创建JavaConfig配置类的关键是为其添加 @Configuration 注释, @Configuration 说明这个类是配置类，该类应该包含在Spring 应用上下文中创建bean得到细节。 5.2 声明简单的bean 要在JavaConfig中创建Bean，需要编写一个方法，加上@Bean注解，说明这个方法会返回这个类型的实例。 @Configurable public class CDConfig { @Bean public MediaPlayer CDplay(){ return new CDPlayer(); } } 如上，默认情况下将创建的bean的ID和方法名字相同，如上，bean的ID将会是CDplay。也可以认为指定的name属性指定一个ID。 @Bean(name=\u0026#34;getCDplay\u0026#34;) public MediaPlayer getCDplay(){ return new CDPlayer(); } 5.3 借助JavaConfig 实现注入 @Configurable public class CDConfig {\t@Bean(name=\u0026#34;getCDplay\u0026#34;) public MediaPlayer getCDplay(){ return new CDPlayer(getCompactDisc()); }\t@Bean public CompactDisc getCompactDisc(){ return new GuoRongCD(); } } 如上，可以通过方法，来为另一个Bean注入。当getCompactDisc()被调用时，因为他被加上了@Bean注解，Spring将会拦截所有对他的调用，并确保返回该方法所创建的bean，而不是每次都对其实际调用。 @Bean() public MediaPlayer getAnotherCDplay(CompactDisc aa){ return new CDPlayer(aa); } getAnotherCDplay() 创建MediaPlayer bean时候，会自动装配CompactDisc 到配置方法中，这也是注入bean的最佳方式。 @Bean() public MediaPlayer getAnotherCDplay(CompactDisc aa){ CDPlayer k = new CDPlayer(); k.setCompactDisc(aa); return k; } 或是通过setter方法进行DI，都可以哒！！！！ 6、通过XML装配bean 6.1 创建简单的bean \u0026lt;bean class=\u0026#34;com.di.Car\u0026#34; id=\u0026#34;car\u0026#34;/\u0026gt; id声明了该bean的名字，默认名字是clss名加上#加上数字，如，“com.di.Car#0”，类以此推。当Spring发现这个bean时候，就会调用该类的【默认构造器】进行初始化。若是该类无默认构造器，将无法进行编译。 6.2 借助构造器注入初始化bean 用构造器注入有两种基本的可供方案： \u0026lt; constructor-arg \u0026gt;\n使用Spring3.0 所引入的c- 命名空间\n前者的长度会更大，导致XML不好阅读。前者的功能更全面。后者比较简洁，推荐。\n构造器注入bean引用 \u0026lt;bean id=\u0026#34;cdPlayer\u0026#34; class=\u0026#34;com.di.book.CDPlayer\u0026#34;\u0026gt; \u0026lt;constructor-arg ref=\u0026#34;glCD\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;glCD\u0026#34; class=\u0026#34;com.di.book.GuoRongCD\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; \u0026lt;constructor-arg\u0026gt;将会告诉Spring 要把一个ID为glCD的bean引用传递到该构造器中。 关于c-命名空间 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:c=\u0026#34;http://www.springframework.org/schema/c\u0026#34;\t//添加标记 xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; ....... \u0026lt;bean id=\u0026#34;cdPlayer\u0026#34; class=\u0026#34;com.di.book.CDPlayer\u0026#34; c:compactDisc-ref=\u0026#34;glCD\u0026#34;/\u0026gt; \u0026lt;bean id=\u0026#34;glCD\u0026#34; class=\u0026#34;com.di.book.GuoRongCD\u0026#34;/\u0026gt; 这里使用了c-命名空间。c: 是c-命名空间的前缀，compactDisc表示构造器参数的名字，ref表示接了下来是一个引用，而不是一个字符串。 使用参数位置来注入 \u0026lt;bean id=\u0026#34;cdPlayer\u0026#34; class=\u0026#34;com.di.book.CDPlayer\u0026#34; c:_0-ref=\u0026#34;glCD\u0026#34;/\u0026gt; _0表示构造函数第一个参数。\n如果只有一个参数，也可以这样写 \u0026lt;bean id=\u0026#34;cdPlayer\u0026#34; class=\u0026#34;com.di.book.CDPlayer\u0026#34; c:_-ref=\u0026#34;glCD\u0026#34;/\u0026gt; 将字面量注入到构造器中 使用进行注入 public BlankDisk(String title,String artist){ this.title = title; this.artist = artist; } \u0026lt;bean id=\u0026#34;cdPlayer\u0026#34; class=\u0026#34;com.di.book.BlankDisk\u0026#34;\u0026gt; \u0026lt;constructor-arg value=\u0026#34;《我是许嵩》\u0026#34;/\u0026gt; \u0026lt;constructor-arg value=\u0026#34;许嵩-VAE\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; value表示该参数是字面量，而不是ref的引用。 使用c-命名空间进行 \u0026lt;bean id=\u0026#34;cdPlayer\u0026#34; class=\u0026#34;com.di.book.BlankDisk\u0026#34; c:_0=\u0026#34;《我是许嵩》\u0026#34; c:_1=\u0026#34;许嵩-VAE\u0026#34;\t/\u0026gt; 或是 \u0026lt;bean id=\u0026#34;cdPlayer\u0026#34; class=\u0026#34;com.di.book.BlankDisk\u0026#34; c:_title=\u0026#34;《我是许嵩》\u0026#34; c:_artist=\u0026#34;许嵩-VAE\u0026#34;/\u0026gt; 装配集合 public BlankDisk(String title,String artist,List\u0026lt;String\u0026gt; songs){ this.title = title; this.artist = artist; this.songs = songs; } \u0026lt;bean id=\u0026#34;cdPlayer\u0026#34; class=\u0026#34;com.di.book.BlankDisk\u0026#34;\u0026gt; \u0026lt;constructor-arg value=\u0026#34;《我是许嵩》\u0026#34; /\u0026gt; \u0026lt;constructor-arg value=\u0026#34;许嵩-VAE\u0026#34; /\u0026gt; \u0026lt;constructor-arg\u0026gt; \u0026lt;list\u0026gt; \u0026lt;value\u0026gt;河山大好\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;有何不可\u0026lt;/value\u0026gt; \u0026lt;ref bean=\u0026#34;\u0026#34;\u0026gt;\u0026lt;/ref\u0026gt; \u0026lt;/list\u0026gt; \u0026lt;/constructor-arg\u0026gt; \u0026lt;/bean\u0026gt; value表示字面量，ref表示bean的引用。list对应于java.utilList，同理，set等等都可以使用。 6.3 设置属性（非构造器注入） \u0026lt;bean id=\u0026#34;cdPlayer\u0026#34; class=\u0026#34;com.di.book.CDPlayer\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;compactDisc\u0026#34; ref=\u0026#34;glCD\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;glCD\u0026#34; class=\u0026#34;com.di.book.GuoRongCD\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; \u0026lt;property\u0026gt; 元素为属性的setter方法提供注入方法，ref为bean引用，value为字面量，前提是，该属性含有setter方法。\tSpring为\u0026lt;/constructor-arg\u0026gt;提供了等价的c-命名空间作为替代方案，也为\u0026lt;property\u0026gt;提供了等价的p-命名空间。但是，这个也需要在XML中实现声明。 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:p=\u0026#34;http://www.springframework.org/schema/p\u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;cdPlayer\u0026#34; class=\u0026#34;com.di.book.CDPlayer\u0026#34; p:compactDisc-ref=\u0026#34;glCD\u0026#34;/\u0026gt; 如上，添加P命名空间的声明，p:表示P命名空间，-ref表示bean引用，后者表示bean ID。 6.4导入和混合配置 可以有多个配置类，一个配置类可以应用另一个配置类 @Configurable public class CDConfig {} @Configurable @Import(CDConfig.class) public class CDPlayerConfig {} //也可以引入多个配置类 //@Import({CDConfig.class,CDConfig.class}) //引入一个配置文件 @Configurable @Import(CDConfig.class) @ImportResource(\u0026#34;classpath:cd-config.xml\u0026#34;) public class CDPlayerConfig {} 配置文件也可以导入另一个配置文件 \u0026lt;import resource=\u0026#34;classpath:cd-config.xml\u0026#34;/\u0026gt; 配置文件可以导入一个配置类 \u0026lt;bean class=\u0026#34;com.sanyue.CDConfig\u0026#34;/\u0026gt; ","date":"2017-10-11T14:29:03+08:00","permalink":"https://luky116.github.io/post/spring%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5%E7%9A%84%E6%96%B9%E5%BC%8F/","tags":["依赖注入"],"title":"Spring依赖注入的方式"},{"categories":["Java多线程"],"contents":"1、wait()、notify/notifyAll() 方法是Object的本地final方法，无法被重写。\n2、wait()使当前线程阻塞，前提是 必须先获得锁，一般配合synchronized 关键字使用，即，一般在synchronized 同步代码块里使用 wait()、notify/notifyAll() 方法。\n3、 由于 wait()、notify/notifyAll() 在synchronized 代码块执行，说明当前线程一定是获取了锁的。\n当线程执行wait()方法时候，会释放当前的锁，然后让出CPU，进入等待状态。\n只有当 notify/notifyAll() 被执行时候，才会唤醒一个或多个正处于等待状态的线程，然后继续往下执行，直到执行完synchronized 代码块的代码或是中途遇到wait() ，再次释放锁。\n也就是说，notify/notifyAll() 的执行只是唤醒沉睡的线程，而不会立即释放锁，锁的释放要看代码块的具体执行情况。所以在编程中，尽量在使用了notify/notifyAll() 后立即退出临界区，以唤醒其他线程让其获得锁\n4、wait() 需要被try catch包围，以便发生异常中断也可以使wait等待的线程唤醒。\n5、notify 和wait 的顺序不能错，如果A线程先执行notify方法，B线程在执行wait方法，那么B线程是无法被唤醒的。\n6、notify 和 notifyAll的区别\nnotify方法只唤醒一个等待（对象的）线程并使该线程开始执行。所以如果有多个线程等待一个对象，这个方法只会唤醒其中一个线程，选择哪个线程取决于操作系统对多线程管理的实现。notifyAll 会唤醒所有等待(对象的)线程，尽管哪一个线程将会第一个处理取决于操作系统的实现。如果当前情况下有多个线程需要被唤醒，推荐使用notifyAll 方法。比如在生产者-消费者里面的使用，每次都需要唤醒所有的消费者或是生产者，以判断程序是否可以继续往下执行。\n7、在多线程中要测试某个条件的变化，使用if 还是while？\n要注意，notify唤醒沉睡的线程后，线程会接着上次的执行继续往下执行。所以在进行条件判断时候，可以先把 wait 语句忽略不计来进行考虑；显然，要确保程序一定要执行，并且要保证程序直到满足一定的条件再执行，要使用while进行等待，直到满足条件才继续往下执行。如下代码：\npublic class K { //状态锁 private Object lock; //条件变量 private int now,need; public void produce(int num){ //同步 synchronized (lock){ //当前有的不满足需要，进行等待，直到满足条件 while(now \u0026lt; need){ try { //等待阻塞 lock.wait(); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\u0026#34;我被唤醒了！\u0026#34;); } // 做其他的事情 } } } 显然，只有当前值满足需要值的时候，线程才可以往下执行，所以，必须使用while 循环阻塞。注意，wait() 当被唤醒时候，只是让while循环继续往下走.如果此处用if的话，意味着if继续往下走，会跳出if语句块。\n8、实现生产者和消费者问题\n什么是生产者-消费者问题呢？\n如上图，假设有一个公共的容量有限的池子，有两种人，一种是生产者，另一种是消费者。需要满足如下条件：\n1、生产者产生资源往池子里添加，前提是池子没有满，如果池子满了，则生产者暂停生产，直到自己的生成能放下池子。\n2、消费者消耗池子里的资源，前提是池子的资源不为空，否则消费者暂停消耗，进入等待直到池子里有资源数满足自己的需求。\n- 仓库类\nimport java.util.LinkedList; /** * 生产者和消费者的问题 * wait、notify/notifyAll() 实现 */ public class Storage1 implements AbstractStorage { //仓库最大容量 private final int MAX_SIZE = 100; //仓库存储的载体 private LinkedList list = new LinkedList(); //生产产品 public void produce(int num){ //同步 synchronized (list){ //仓库剩余的容量不足以存放即将要生产的数量，暂停生产 while(list.size()\u0026#43;num \u0026gt; MAX_SIZE){ System.out.println(\u0026#34;【要生产的产品数量】:\u0026#34; \u0026#43; num \u0026#43; \u0026#34;\\t【库存量】:\u0026#34; \u0026#43; list.size() \u0026#43; \u0026#34;\\t暂时不能执行生产任务!\u0026#34;); try { //条件不满足，生产阻塞 list.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } for(int i=0;i\u0026lt;num;i\u0026#43;\u0026#43;){ list.add(new Object()); } System.out.println(\u0026#34;【已经生产产品数】:\u0026#34; \u0026#43; num \u0026#43; \u0026#34;\\t【现仓储量为】:\u0026#34; \u0026#43; list.size()); list.notifyAll(); } } //消费产品 public void consume(int num){ synchronized (list){ //不满足消费条件 while(num \u0026gt; list.size()){ System.out.println(\u0026#34;【要消费的产品数量】:\u0026#34; \u0026#43; num \u0026#43; \u0026#34;\\t【库存量】:\u0026#34; \u0026#43; list.size() \u0026#43; \u0026#34;\\t暂时不能执行生产任务!\u0026#34;); try { list.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } //消费条件满足，开始消费 for(int i=0;i\u0026lt;num;i\u0026#43;\u0026#43;){ list.remove(); } System.out.println(\u0026#34;【已经消费产品数】:\u0026#34; \u0026#43; num \u0026#43; \u0026#34;\\t【现仓储量为】:\u0026#34; \u0026#43; list.size()); list.notifyAll(); } } } - 抽象仓库类\npublic interface AbstractStorage { void consume(int num); void produce(int num); } - 生产者\npublic class Producer extends Thread{ //每次生产的数量 private int num ; //所属的仓库 public AbstractStorage abstractStorage; public Producer(AbstractStorage abstractStorage){ this.abstractStorage = abstractStorage; } public void setNum(int num){ this.num = num; } // 线程run函数 @Override public void run() { produce(num); } // 调用仓库Storage的生产函数 public void produce(int num) { abstractStorage.produce(num); } } - 消费者\npublic class Consumer extends Thread{ // 每次消费的产品数量 private int num; // 所在放置的仓库 private AbstractStorage abstractStorage1; // 构造函数，设置仓库 public Consumer(AbstractStorage abstractStorage1) { this.abstractStorage1 = abstractStorage1; } // 线程run函数 public void run() { consume(num); } // 调用仓库Storage的生产函数 public void consume(int num) { abstractStorage1.consume(num); } public void setNum(int num){ this.num = num; } } - 测试\npublic class Test{ public static void main(String[] args) { // 仓库对象 AbstractStorage abstractStorage = new Storage1(); // 生产者对象 Producer p1 = new Producer(abstractStorage); Producer p2 = new Producer(abstractStorage); Producer p3 = new Producer(abstractStorage); Producer p4 = new Producer(abstractStorage); Producer p5 = new Producer(abstractStorage); Producer p6 = new Producer(abstractStorage); Producer p7 = new Producer(abstractStorage); // 消费者对象 Consumer c1 = new Consumer(abstractStorage); Consumer c2 = new Consumer(abstractStorage); Consumer c3 = new Consumer(abstractStorage); // 设置生产者产品生产数量 p1.setNum(10); p2.setNum(10); p3.setNum(10); p4.setNum(10); p5.setNum(10); p6.setNum(10); p7.setNum(80); // 设置消费者产品消费数量 c1.setNum(50); c2.setNum(20); c3.setNum(30); // 线程开始执行 c1.start(); c2.start(); c3.start(); p1.start(); p2.start(); p3.start(); p4.start(); p5.start(); p6.start(); p7.start(); } } - 输出\n【要消费的产品数量】:50 【库存量】:0 暂时不能执行生产任务! 【要消费的产品数量】:20 【库存量】:0 暂时不能执行生产任务! 【要消费的产品数量】:30 【库存量】:0 暂时不能执行生产任务! 【已经生产产品数】:10 【现仓储量为】:10 【要消费的产品数量】:30 【库存量】:10 暂时不能执行生产任务! 【要消费的产品数量】:20 【库存量】:10 暂时不能执行生产任务! 【要消费的产品数量】:50 【库存量】:10 暂时不能执行生产任务! 【已经生产产品数】:10 【现仓储量为】:20 【已经生产产品数】:10 【现仓储量为】:30 【要消费的产品数量】:50 【库存量】:30 暂时不能执行生产任务! 【已经消费产品数】:20 【现仓储量为】:10 【要消费的产品数量】:30 【库存量】:10 暂时不能执行生产任务! 【已经生产产品数】:10 【现仓储量为】:20 【要消费的产品数量】:50 【库存量】:20 暂时不能执行生产任务! 【要消费的产品数量】:30 【库存量】:20 暂时不能执行生产任务! 【已经生产产品数】:10 【现仓储量为】:30 【已经消费产品数】:30 【现仓储量为】:0 【要消费的产品数量】:50 【库存量】:0 暂时不能执行生产任务! 【已经生产产品数】:10 【现仓储量为】:10 【要消费的产品数量】:50 【库存量】:10 暂时不能执行生产任务! 【已经生产产品数】:80 【现仓储量为】:90 【已经消费产品数】:50 【现仓储量为】:40 ","date":"2017-10-06T14:29:03+08:00","permalink":"https://luky116.github.io/post/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%AD%A6%E4%B9%A0%E4%B9%8Bwaitnotify%E5%92%8Cnotifyall%E8%AF%A6%E8%A7%A3/","tags":["notify","源码"],"title":"Java多线程学习之wait、notify和notifyAll详解"},{"categories":["Java源码"],"contents":"1、Comparable 介绍 Comparable 是一个排序接口，如果一个类实现了该接口，说明该类本身是可以进行排序的。注意，除了基本数据类型（八大基本数据类型） 的数组或是List，其余类型的对象，Collections.sort或Arrays.sort 是不支持直接进行排序的，因为对象本身是没有“顺序”的，除非你实现了Comparable 接口或是自定义了Comparable 对象，指定了排序规则，才可以进行排序。\nComparable 源码就一个方法,\npublic interface Comparable\u0026lt;T\u0026gt; { public int compareTo(T o); } 泛型T表示要进行比较的对象所属的类型，compareTo 比较对象之间的值的大小关系，如果该对象小于、等于或大于指定对象，则分别返回负整数、零或正整数。\n定义一个对象：\npublic class Person implements Comparable\u0026lt;Person\u0026gt;{ public int age; public Person(int age){ this.age = age; } public String toString() { return \u0026#34;{\u0026#34; \u0026#43; \u0026#34;age=\u0026#34; \u0026#43; age \u0026#43; \u0026#39;}\u0026#39;; } @Override public int compareTo(Person o) { //Person 对象之间根据名字排序 return this.age - o.age; } } 排序测试：\npublic static void main(String[] args) { Person[] ps =new Person[]{new Person(1),new Person(4), new Person(2),new Person(7),new Person(9),new Person(8), new Person(3),new Person(0),new Person(1)}; System.out.println(\u0026#34;排序前：\u0026#34;\u0026#43;Arrays.toString(ps)); //进行排序 Arrays.sort(ps); System.out.println(\u0026#34;排序后：\u0026#34;\u0026#43;Arrays.toString(ps)); } 排序前：[{age=1}, {age=4}, {age=2}, {age=7}, {age=9}, {age=8}, {age=3}, {age=0}, {age=1}] 排序后：[{age=0}, {age=1}, {age=1}, {age=2}, {age=3}, {age=4}, {age=7}, {age=8}, {age=9}] 2、Comparator 介绍 如果一个类本身并没有实现 Comparable 接口，我们想要对他进行排序，就要自定义 Comparator 比较器进行比较，在这个比较器里面自定义排序的依据。\nComparator 源码中主要的两个接口方法：\npublic interface Comparator\u0026lt;T\u0026gt; { int compare(T o1, T o2); boolean equals(Object obj); } compare 是主要方法，必须要实现，equals 方法可以不实现。compare 中返回比较结果，如果该对象小于、等于或大于指定对象，则分别返回负整数、零或正整数。\n定义一个用来排序类，该类并为实现 Comparable 接口：\nprivate static class Man{ public int age; public Man(int age){ this.age = age; } public String toString() { return \u0026#34;{\u0026#34; \u0026#43; \u0026#34;age=\u0026#34; \u0026#43; age \u0026#43; \u0026#39;}\u0026#39;; } } 进行排序：\n@Test public void test_1(){ Man[] ps =new Man[]{new Man(1),new Man(4),new Man(2), new Man(7),new Man(9),new Man(8),new Man(3),new Man(0),new Man(1)}; //数组转List ArrayList\u0026lt;Man\u0026gt; ap = new ArrayList\u0026lt;Man\u0026gt;(Arrays.asList(ps)); System.out.println(\u0026#34;排序前：\u0026#34;\u0026#43;ap); //自定义排序器 Collections.sort(ap,new Comparator\u0026lt;Man\u0026gt;() { @Override public int compare(Man o1, Man o2) { //根据年龄进行排序 return o1.age - o2.age; } }); System.out.println(\u0026#34;排序后：\u0026#34;\u0026#43; ap); } 排序前：[{age=1}, {age=4}, {age=2}, {age=7}, {age=9}, {age=8}, {age=3}, {age=0}, {age=1}] 排序后：[{age=0}, {age=1}, {age=1}, {age=2}, {age=3}, {age=4}, {age=7}, {age=8}, {age=9}] 3、总结比较 Comparable 在类的内部定义排序规则，Comparator 在外部定义排序规则，Comparable 相当于“内部排序器”，Comparator 相当于“外部排序器”，前者一次定义即可，后者可以在不修改源码的情况下进行排序，各有所长。\n","date":"2017-10-02T14:29:03+08:00","permalink":"https://luky116.github.io/post/java%E4%B8%ADcomparable%E5%92%8Ccomparator%E6%AF%94%E8%BE%83/","tags":["Comparable","源码"],"title":"Java中Comparable和Comparator比较"},{"categories":["Java源码"],"contents":"中断线程\n在 run() 方法中，如果语句执行到了最会一句，或是遇到 return 方法，或是方法中出现了没有被捕获的异常，run() 方法将会执行结束。在java中，Thread中的interrupt() 方法被调用时，线程中断状态将被置位，由于线程在运行期间，会不断的检测这个状态位，以判断程序是否被中断。\n检测线程是否被中断\n在实际开发中，要判断中断状态位是否被置位，首先使用静态方法 Thread.currentThread() 方法来获取当前线程，在调用 interrupted() 方法来判断中断位的状态。如下：\nwhile (!Thread.currentThread().interrupted() \u0026amp;\u0026amp; more work to do) {} interrupted 和 isInterrupted 区别\ninterrupted 是一个静态方法，他检测当前线程是否中断，并且会清除当前线程的中断位。isInterrupted 是一个实例方法，检测线程中断位，不会清除状态位。\n如何中断线程\n如果线程被Object.wait, Thread.join和Thread.sleep三种方法之一阻塞，那么，它将接收到一个中断异常（InterruptedException），从而提早地终结被阻塞状态。interrupt 不会中断一个正在运行的线程。\n要注意的是，中断线程不等于终止线程，interrupt 只是只是改变了线程的状态位，来引起线程的注意或是唤醒沉睡的线程。但是当线程注意到（捕获到InterruptedException异常或是检测到状态位的改变），可以自行决定如何处理该线程，比如，可以让线程捕获异常后继续执行，或是中断线程。\n在实际操作中，一般会把线程中断当做线程结束的条件，格式如下：\n@Override public void run() { while(!Thread.currentThread().isInterrupted() ){ try{ //处理正常的逻辑 Thread.sleep(100); }catch (InterruptedException e){ //被中断后的进入 //由于抛出异常后会把状态位改变，所以这里应该手动改变状态位 Thread.currentThread().interrupt(); }finally{ // 线程结束前的后续操作 } } } 一般不会在捕获的异常中不进行任何操作，这样可能会处理不当中断，比如：\n@Override public void run() { try{ Thread.sleep(100); }catch (InterruptedException e){ } } 选择抛出异常，也是很好的选择：\nvoid mySubTask() throws InterruptedException { ... sleep(delay); ... } 如何中断一个线程\n实例一：\npublic class Example1 implements Runnable{ private float d; @Override public void run() { while(true){ for(int i=0;i\u0026lt;10000000;i\u0026#43;\u0026#43;){ d = (float) (d \u0026#43; (Math.PI \u0026#43; Math.E) / d); } System.out.println(\u0026#34;I\u0026#39;m counting......\u0026#34;); //转让调度器使用权 Thread.yield(); } } public static void main(String[] args) throws InterruptedException { Example1 example1 = new Example1(); Thread t1 = new Thread(example1); t1.start(); Thread.sleep(100); System.out.println(\u0026#34;开始中断线程。。。。。。\u0026#34;); t1.interrupt(); } } 输出：\nI\u0026#39;m counting...... 开始中断线程。。。。。。 I\u0026#39;m counting...... I\u0026#39;m counting...... I\u0026#39;m counting...... I\u0026#39;m counting...... 可以看出来，线程被调用interrupt方法后，并没有被中断，任然在运行，所以说，interrupt 方法并不能是线程终止运行。\n要是线程中断运行，有三种方法，抛出Interrupt异常，使用 Thread.interrupted() 不断检查中断状态位，使用信号量进行控制。\n方法一：信号量法\nclass Example2 implements Runnable{ public static boolean isLive = true; float d; @Override public void run() { while(isLive){ for(int i=0;i\u0026lt;10000000;i\u0026#43;\u0026#43;){ d = (float) (d \u0026#43; (Math.PI \u0026#43; Math.E) / d); } System.out.println(\u0026#34;I\u0026#39;m counting......\u0026#34;); //转让调度器使用权 Thread.yield(); } } public static void main(String[] args) throws InterruptedException { Example2 e2 = new Example2(); Thread t1 = new Thread(e2); t1.start(); Thread.sleep(100); System.out.println(\u0026#34;开始中断线程。。。。。。\u0026#34;); //设置改变信号量 e2.isLive = false; } } 输出结果：\nI\u0026#39;m counting...... 开始中断线程。。。。。。 I\u0026#39;m counting...... 方法二：抛出异常法\npublic class Example1 implements Runnable{ private double d = 0.0; public void run() { //死循环执行打印\u0026#34;I am running!\u0026#34; 和做消耗时间的浮点计算 try { while (true) { System.out.println(\u0026#34;I am running!\u0026#34;); for (int i = 0; i \u0026lt; 900000; i\u0026#43;\u0026#43;) { d = d \u0026#43; (Math.PI \u0026#43; Math.E) / d; } //休眠一断时间,中断时会抛出InterruptedException Thread.sleep(50); } } catch (InterruptedException e) { System.out.println(\u0026#34;ATask.run() interrupted!\u0026#34;); } } public static void main(String[] args) throws InterruptedException { Example1 example1 = new Example1(); Thread t1 = new Thread(example1); t1.start(); Thread.sleep(100); System.out.println(\u0026#34;开始中断线程。。。。。。\u0026#34;); t1.interrupt(); } } 输出结果\nI am running! I am running! 开始中断线程。。。。。。 ATask.run() interrupted! 方法三：*Thread.interrupted()监听*\nclass Example3 implements Runnable { @Override public void run() { while (!Thread.currentThread().interrupted()) { try { Thread.sleep(100); System.out.println(\u0026#34;I\u0026#39;m counting......\u0026#34;); } catch (InterruptedException e) { //设置状态位 Thread.currentThread().interrupt(); } } } public static void main(String[] args) throws InterruptedException { Example3 e = new Example3(); Thread t1 = new Thread(e); t1.start(); Thread.sleep(800); System.out.println(\u0026#34;开始中断线程。。。。。。\u0026#34;); t1.interrupt(); } } 输出为：\nI\u0026#39;m counting...... I\u0026#39;m counting...... I\u0026#39;m counting...... I\u0026#39;m counting...... I\u0026#39;m counting...... I\u0026#39;m counting...... 开始中断线程。。。。。。 被遗弃的stop和suspend\n早起的Java版本提供了stop方法来终止一个线程，以及suspend来阻塞一个线程直到另一个线程调用resume来唤醒线程。stop和suspend这两个方法都试图控制给定线程的想行为。\nstop 方法试图终止一个线程的执行，包括未执完的run方法，其本身是很不安全的。比如说，当一个线程试图从一个账户转账到另一个账户，一个线程已经把钱取出来了，但是此正好被stop终止了线程，但是钱却没有转到另一个账户。这样的突然终止导致银行对象出于不稳定的状态。虽然此时锁被释放了，但是他的不稳定状态却不能被其他线程看到，这是很危险的。\nsuspend 方法用来挂起一个锁，虽然不会破坏对象，但是有可能导致死锁。假设如果用suspend方法挂起一个拥有锁的线程，那么，该锁在恢复之前是不可用的。如果此时，调用suspend方法的线程试图获取同一个锁，那么，此时就会出现死锁。\n","date":"2017-09-29T14:43:00+08:00","permalink":"https://luky116.github.io/post/java%E4%B8%AD%E6%96%AD%E6%9C%BA%E5%88%B6interrupt/","tags":["Java中断"],"title":"Java中断机制(interrupt))"},{"categories":["JVM"],"contents":"由于程序计数器、虚拟机栈、本地方法栈随线程而生，随线程而灭一般的垃圾回收指Java 堆和方法区出的内存回收。\n1 如何判断对象是否已死 1.1 引用计数器 给对象添加一个引用计数器，当有一个应用引用他时，计数器加一，引用失效时减一。 无法解决对象间相互循环引用的问题，Java 未使用。 1.2 可达性分析 通过一系列称为“GC Root\u0026quot;的对象作为起点，向下搜索，搜索所走的路径称为引用链。当一个对象没有任何引用链相连时，证明此对象是不可用的。 GC Root 对象包含如下： 虚拟机栈（栈帧中的本地变量表）中引用的对象 方法区中静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI（即，native方法）引用的对象 1.3 回收过程 如 1.4 常见的垃圾回收算法 标记 - 清除 算法\n原理：\n标记所有需要回收的对象，然后统一回收 缺陷\n效率问题，标记和清除的效率都不高；标记清除后有大量的不连续内存碎片。 复制算法\n原理\n将内存划分为新生代和老年代，新生代分为 一块较大的Eden 空间和两块较小的 Survicor 空间，每次只使用Eden 空间和一块Survivor 空间，然后把已使用的那块一次清理。**新生代的收集全部采用复制算法。** 标记 - 整理 算法\n原理\n先标记需要回收的对象，然后让所有的存活的对象向一段移动，然后清理边界以外的内存。**针对存活率较高时候的情形，因为复制代价会比较大。** 分代收集\n在新生代，每次回收都会有大量对象死亡，所以使用 复制算法，老年代对象存活率较高，所以使用“标记-清理” 或 “标记-整理” 算法。\n1.5 堆里面的分区：Eden、servival to 、from to、老年代 Eden 区\n位于Java 堆的新生代。新生代中的对象寿命比较短。\n大多数情况下对象有现在的Eden 区分配，如果启动了TLAB （本地线程分配缓冲）则优先在TLAB上分配。如果 Eden 区内存也用完了，则会进行一次 Minor GC。 Servivor 区\n复制算法将内存分为Eden 、 from 、 to survivor 三个区域，使用的时候每次只使用Eden 和 from survivor 区域，当回收时将Eden 和 from survivor 区中活着的对象复制到to survivor 区上。\n老年代\n里面存放都是存活时间交久的对象：\n如果大量连续内存空间的大对象直接进入老年代、长期存活的对象将进入老年代。 当老年代容量满的时候，会触发一次full GC，回收老年代和年轻代中不再使用的对象资源。 TLAB\nJVM在内存新生代Eden Space中开辟了一小块线程私有的区域，称作TLAB（Thread-local allocation buffer）。默认设定为占用Eden Space的1%。在Java程序中很多对象都是小对象且用过即丢，它们不存在线程共享也适合被快速GC，所以对于小对象通常JVM会优先分配在TLAB上，并且TLAB上的分配由于是线程私有所以没有锁开销。因此在实践中分配多个小对象的效率通常比分配一个大对象的效率要高。 也就是说，Java中每个线程都会有自己的缓冲区称作TLAB（Thread-local allocation buffer），每个TLAB都只有一个线程可以操作，TLAB结合bump-the-pointer技术可以实现快速的对象分配，而不需要任何的锁进行同步，也就是说，在对象分配的时候不用锁住整个堆，而只需要在自己的缓冲区分配即可。 Java对象分配的过程\n编译器通过逃逸分析，确定对象是在栈上分配还是在堆上分配。如果是在堆上分配，则进入选项2.\n如果tlab_top + size \u0026lt;= tlab_end，则在在TLAB上直接分配对象并增加tlab_top 的值，如果现有的TLAB不足以存放当前对象则3.\n重新申请一个TLAB，并再次尝试存放当前对象。如果放不下，则4.\n在Eden区加锁（这个区是多线程共享的），如果eden_top + size \u0026lt;= eden_end则将对象存放在Eden区，增加eden_top 的值，如果Eden区不足以存放，则5.\n执行一次Young GC（minor collection）。\n经过Young GC之后，如果Eden区任然不足以存放当前对象，则直接分配到老年代。\n对象不在堆上分配主要的原因还是堆是共享的，在堆上分配有锁的开销。无论是TLAB还是栈都是线程私有的，私有即避免了竞争（当然也可能产生额外的问题例如可见性问题），这是典型的用空间换效率的做法。 1.6 Minor GC 和 Full GC Minor GC（新生代 GC ）：大多数情况下，对象在新生代Eden 区中分配，当Eden 区中没有足够空间时候，虚拟机触发一次Minor GC。Minor GC 非常频繁，速度快。 Full GC 在 Minor GC 之前会检查老年代中最大可用连续空间是否大于新生代中的对象，如果成立，则这次Mior GC 是安全的，否则要查看是否允许担保失败，如果不允许则改进为Full GC ，允许的话尝试一次Minor GC 老年代满时，也会触发Full GC ","date":"2017-09-24T14:43:00+08:00","permalink":"https://luky116.github.io/post/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%92%8C%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5/","tags":["JVM垃圾回收"],"title":"垃圾回收和内存分配策略"},{"categories":["JVM"],"contents":"关于类加载机制：\n​\t虚拟机把描述类的数据从Class 文件加载到内存，并对数据进行效验、转换解析和初始化，最终 形成可以被虚拟机直接使用的Java 类型，就是虚拟机的类加载机制。\n1、初始化 时机 1、遇到 new 、getstatic 、putstatic 、invokestatic 这四个字节码指令时。触发这四条指令的场景：\n使用new 实例化对象时 读取或设置一个类的静态字段（被final修饰，已在编译期把结果放入常量池的不算（即 常量不算，static final 修饰）） 调用一个类的静态方法 2、使用反射调用时，先进行初始化\n3、初始化一个类时，若其父类未被初始化，则先初始化其父类。\n4、当虚拟机启动时，用户需要指定一个要执行的主类（main() 函数所在的类），虚拟机会先初始化它。\n5、jdk 7.0 中，动态语言的支持\n以上称为主动引用，被动引用不会引起初始化：\n现有如下两个类：\nclass SuperClass{ static { System.out.println(\u0026#34;SuperClass init !!!\u0026#34;); } public static int value = 123; } class SubClass extends SuperClass{ static { System.out.println(\u0026#34;SubClass init !!!\u0026#34;); } public static final String HELLO_WORLG = \u0026#34;hello world !\u0026#34;; } 测试一： public static void main(String[] args) { System.out.println(SubClass.value); } 运行结果\nSuperClass init !!! 123 对于静态变量，只有直接定义这个变量的类才会进行初始化，如子类调用父类的静态变量，只有父类会进行初始化，子类不会自动进行初始化。\n测试二：\npublic static void main(String[] args) { System.out.println(SubClass.HELLO_WORLG); } 运行结果：\nhello world ! 常量在在编译期通过常量传播优化，将“hello world !“存储到了常量池中，也就是说，”SubClass.HELLO_WORLG“并没有通过SubClass类符号进行引用，二者并没有任何联系。所以不会导致该类初始化。 2、加载 通过类的权限定名来获取此类的二进制字节流 把字节流代表的静态数据结构转化为方法区的运行时数据结构 在方法区中生成一个代表这个类的Class 对象 3、验证 ​\t确保class文件的字节流中的信息是安全的，至少不会危害虚拟机自身的安全。只有通过了这阶段的验证，字节流才会进入内存的方法区进行存储。\n4、准备 为类变量分配内存并设置初始零值，这些变量的内存在方法区中进行分配。\n常量会设置最终值，如：\npublic static int value = 123; public static final int con = 234; 准备期过后，会把value置为0，con的值置为234。\n5、解析 ​\t将常量池中的符号引用替换为直接引用。这一阶段会根据需要发生在初始化之前或之后，包含类或接口解析、字段解析、方法解析。\n​\t符号引用是无关虚拟机实现的内存布局。直接引用是和虚拟机实现内存布局相关的，符号引用必须在运行期转换获得真正的内存入口地址。\n6、初始化 ​\t开始真正执行类中定义的 Java 代码，初始化阶段是执行类构造器() 方法的过程\n() 是编译期收集类中所有的类变量的赋值动作和静态语句块中（static{}）的语句结合而成的。静态语句块只能访问惊天语句块之前的变量，定义在其之后的变量，只能赋值，不能访问 static { i = 0; //可以给变量赋值编译通过 System.out.println(i); //使用变量编译不通过 } static int i; () 方法和构造函数不同。子类不会显示的调用父类的init() 方法，但是虚拟机会保证子类init() 方法被调用之前，父类的init() 会被先调用。 public class InitDemo_2 { public static void main(String[] args) { System.out.println(SubClass1.B); } } class SuperClass1{ public static int A = 1; static { A = 2; } } class SubClass1 extends SuperClass1{ public static int B = A; } 运行结果：\n2 接口中不会有静态语句块，但是接口中可以有赋值语句，因此接口也会生成() ，但是，执行接口的() 不需要先执行父类的() ，除非父类的变量被执行，才会调用父类的() 。 () 方法只会被执行一次 7、类加载机制 三种类加载器\n启动类加载器（Bootstrap ClassLoader） ​\t负责加载 JAVA_HOME/lib 目录下，或被-XbootclassPath 参数指定的路径下的类库。 拓展类加载器（Extension ClassLoader）\n​\t负责加载 JAVA_HOME/lib/ext 目录下或者被 java.ext.dirs 系统变量所指定的路径中的所有类库。\n应用程序类加载器（Application ClassLoader）\n​\t是ClassLoader.getSystemClassLoasder() 方法的返回值，负责加载用户类路径上所指定的类库。\n双亲委派模型\n类加载器通过组合的方式建立的父子关系，称为双亲委派模型。\n类需要有加载他的类加载器和类本身一起确定其在虚拟机中的唯一性。\n工作流程\n​\t一个类加载器收到了类加载加载的请求，他首先不会尝试自己加载这个类而是把这个请求委派给父类加载器来完成。只有父类无法完成这个请求时，子加载器才会尝试自己去加载。\n作用\n​\tJava 类随着他的类加载器一起具备了一种带优越级的层级关系，所有的加载请求都会传送到顶层的启动类加载器中，保证了Java 的稳定运行。\n","date":"2017-09-15T14:43:00+08:00","permalink":"https://luky116.github.io/post/java%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/","tags":["JVM类加载"],"title":"Java虚拟机的类加载机制"},{"categories":["MySQL"],"contents":"1、为什么会有索引\n当数据保存在磁盘介质上时，它是作为数据库存放的，每条数据是作为一个整体存储的。磁盘存放数据的数据结构类似于链表，即，每个节点除了包含本身数据，还包含一个指向下个节点的指针。相关数据逻辑相连，物理地址可以任意。\n那么问题来，如果一个表有10W个数据，如果没有索引，那么当你按某个条件查找数据时候，系统只能遍历数据，直到找到你需要的数据。\n如果你把这个字段做成了索引，系统会把这个索引字段按照一定的规则制成一个单独的数据结构，当你需要按照这个字段查找时候，系统会在这个索引数据结构二分查找，把原来复杂度为o(N)降为o(log2N)，大大提高查询速度。\n2、索引\n2.1 单列索引\n2.1.1 普通索引\n普通索引是最基本的索引。由关键字KEY或INDEX定义的索引，加快对数据的访问速度。对于那些经常的查询条件（WHERE column=）或排序条件（ORDER BY column）的字段，应该创建索引。\nCREATE INDEX 索引名 ON 表名(字段名);\nALTER TABLE 表名 ADD KEY 索引名(字段名);\nALTER TABLE 表名 ADD INDEX 索引名(字段名);\n2.1.2 唯一索引\n普通索引允许在数据列中包含重复的值，比如，名字，这个项可以重复。对于一些不能重复的值，比如，个人的身份证号，应该设置为UNIQUE INDEX 把他设置为唯一索引。\nALTER TABLE people ADD UNIQUE INDEX 索引名(字段名);\n2.1.3 主索引\n主键会被默认添加一个索引，这就是“主索引”。主索引与唯一索引的唯一区别是：前者在定义时使用的关键字是PRIMARY而不是UNIQUE。主键索引一定是唯一性索引，唯一性索引不一定是主键索引。\nALTER TABLE people ADD PRIMARY KEY 索引名(字段名);\n2.2 组合索引\n包含多个字段的索引。\nCREATE INDEX 索引名 ON 表名(字段名,字段名);\n例如：\nCREATE INDEX all_index ON people(last_name,first_name,gender);\n在使用查询的时候遵循MySQL组合索引的“最左前缀”，什么是最左前缀：where 时的条件要按照建立索引时候字段的排序方式。比如，INDEX（A,B,C）可以被当做A或（A,B）的索引来使用，但不能当做B,C或（B,C）的索引来使用。\nWhere A= ‘xxx’ and B like = ‘aa%’ and C=’sss’ 改查询只会使用索引中的前两列,因为like是范围查询。范围查询不算在索引内，因为索引使用 hash值来计算，模糊条件无法计算得到hash值。\n2.3 全文索引\n文本字段（text、blog）建立索引时候需要指明索引的长度。如果对文本字段进行模糊查询，即 where column like \u0026lsquo;%xx%\u0026rsquo;，因为是模糊查询，所以索引会失效。\n可以设置全文索引：\nALTER TABLE 表名ADD FULLTEXT(字段名1, 字段名2)\n有了全文索引，就可以利用索引来进行关键字查询了。\nELECT * FROM tablename WHERE MATCH(column1, column2) AGAINST(‘xxx′, ‘sss′, ‘ddd′)\n查询出column1 和 column2 中包含这些关键字的记录。\n","date":"2017-08-30T14:43:00+08:00","permalink":"https://luky116.github.io/post/mysql%E7%B4%A2%E5%BC%95/","tags":["MySQL索引"],"title":"MySQL索引"},{"categories":["MySQL"],"contents":"1、前言 数据库关系模式可分为第一范式（1NF），第二范式（2NF），第三范式（3NF）和Boyce-Codd范式（BCNF）。这几个规范要求越来越严格，他们之间的关系为 1NF ⊂ 2NF ⊂ 3NF ⊂ BCNF，即，如果满足第二范式一定满足第一范式，满足第三范式一定满足第二范式，以此类推。\n2、第一范式 2.1 定义 如果一关系模式r(R)的每个属性对应的域值是不可分的，则称r(R)属于第一范式，记为r(R)⊂1NF。\n2.2 案例 如下图所示的关系模式是一个非规范化的关系模式，因为address的值域是可分的。\nname sex address province city street 将上述关系模式规范化如下图，才是 1NF 关系模式：\nname sex province city street 3、第二范式 3.1 定义 首先是 2NF，另外非主键列必须直接依赖于主键，不能存在传递依赖。即不能存在：非主键列 A 依赖于非主键列 B，非主键列 B 依赖于主键的情况。\n第二范式满足两部分内容：一是表必须有一个主键；二是非主键属性必须完全依赖于主键，而不能只依赖于部分主键。\n3.2 案例 如表主键为（OrderId,ProductId）,Price（价格）和DisCount（折扣）项完全依赖于主键（OrderId,ProductId），而ProductName（产品名字）、Producter（生产商）仅仅依赖于ProductId，即部分主键，因此不符合第二范式，这样会导致数据冗余。可以拆分成如下两个表\n4、第三范式 4.1 定义 首先是 2NF，另外非主键列必须直接依赖于主键，不能存在传递依赖。即不能存在：非主键列 A 依赖于非主键列 B，非主键列 B 依赖于主键的情况。\n4.2 案例 如图，主键为 OrderId，其余所有属性都完全依赖于这个主键，但是ProductName（产品名字）、Producter（生产商）属性直接依赖于ProductId，ProductId依赖于主键，这就是 通过传递才依赖主键的，不符合3NF。拆分后，满足。\n5、第二范式和第三范式 2NF 和 3NF很容易混淆，满足3NF一定满足2NF，总结下就是：\n2NF：是否存在部分依赖主键 3NF：是否存在主键依赖传递 ","date":"2017-08-29T14:43:00+08:00","permalink":"https://luky116.github.io/post/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%89%E8%8C%83%E5%BC%8F/","tags":["MySQL范式"],"title":"数据库三范式"}]